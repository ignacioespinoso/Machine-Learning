{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROAD MAP\n",
    "# DESCONSIDERAR A PRIMEIRA COLUNA\n",
    "# SEPARA A COLUNA DE PRECO DAS DEMAIS\n",
    "# FAZER A MULTIPLICACAO DA MATRIX EM SEGUIDA DA INVERSA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from enum import Enum\n",
    "from sklearn import datasets, linear_model\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def classificationCut (data):\n",
    "    num_rows = len(data)\n",
    "    for i in range(num_rows):\n",
    "        if (data[i][1] == 'Fair'):\n",
    "            data[i][1] = -2\n",
    "        elif (data[i][1] == 'Good'):\n",
    "            data[i][1] = -1\n",
    "        elif (data[i][1] == 'Very Good'):\n",
    "            data[i][1] = 0\n",
    "        elif (data[i][1] == 'Premium'):\n",
    "            data[i][1] = 1\n",
    "        elif (data[i][1] == 'Ideal'):\n",
    "            data[i][1] = 2\n",
    "\n",
    "def classificationColor (data):\n",
    "    num_rows = len(data)\n",
    "    for i in range(num_rows):\n",
    "        if (data[i][2] == 'D'):\n",
    "            data[i][2] = -3\n",
    "        elif (data[i][2] == 'E'):\n",
    "            data[i][2] = -2\n",
    "        elif (data[i][2] == 'F'):\n",
    "            data[i][2] = -1\n",
    "        elif (data[i][2] == 'G'):\n",
    "            data[i][2] = 0\n",
    "        elif (data[i][2] == 'H'):\n",
    "            data[i][2] = 1\n",
    "        elif (data[i][2] == 'I'):\n",
    "            data[i][2] = 2\n",
    "        elif (data[i][2] == 'J'):\n",
    "            data[i][2] = 3\n",
    "\n",
    "#como fazer com numeros pares?\n",
    "def classificationClarity (data):\n",
    "    num_rows = len(data)\n",
    "    for i in range(num_rows):\n",
    "        if (data[i][3] == 'I1'):\n",
    "            data[i][3] = -4\n",
    "        elif (data[i][3] == 'SI2'):\n",
    "            data[i][3] = -3\n",
    "        elif (data[i][3] == 'SI1'):\n",
    "            data[i][3] = -2\n",
    "        elif (data[i][3] == 'VS2'):\n",
    "            data[i][3] = -1\n",
    "        elif (data[i][3] == 'VS1'):\n",
    "            data[i][3] = 1\n",
    "        elif (data[i][3] == 'VVS2'):\n",
    "            data[i][3] = 2\n",
    "        elif (data[i][3] == 'VVS1'):\n",
    "            data[i][3] = 3\n",
    "        elif (data[i][3] == 'IF'):\n",
    "            data[i][3] = 4\n",
    "\n",
    "def classificationSet (data):\n",
    "    classificationCut(data)\n",
    "    classificationColor(data)\n",
    "    classificationClarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting our data, we normalize it and filter test/train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-b11efd30833f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b11efd30833f>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    Q    reader = csv.reader(f)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "\n",
    "reader = csv.reader(f)\n",
    "    diamondsTrain = list(reader)\n",
    "with open('diamonds-dataset/diamonds-test.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    diamondsTest = list(reader)\n",
    "\n",
    "# Criar uma funcao pois repetimos as mesmas operacoes para Train e Test\n",
    "dataSetTrain = np.asarray(diamondsTrain[1:])\n",
    "priceTrain = dataSetTrain[:,9]\n",
    "dataSetTrain = np.delete(dataSetTrain,9,axis=1)\n",
    "\n",
    "dataSetTest = np.asarray(diamondsTest[1:])\n",
    "priceTest = dataSetTest[:,9]\n",
    "dataSetTest = np.delete(dataSetTest,9,axis=1)\n",
    "\n",
    "classificationSet(dataSetTrain)\n",
    "classificationSet(dataSetTest)\n",
    "\n",
    "trainDataFloat = dataSetTrain.astype(float)\n",
    "testDataFloat = dataSetTest.astype(float)\n",
    "priceTrain = priceTrain.astype(float)\n",
    "priceTest = priceTrain.astype(float)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(trainDataFloat)\n",
    "trainDataFloat = scaler.transform(trainDataFloat)\n",
    "\n",
    "print(trainDataFloat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check what results we may obtain using sklearn.linear_model.SGDRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=10000, n_iter=None, penalty='l2',\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.SGDRegressor(max_iter=10000, eta0=0.01)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(trainDataFloat, priceTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-137210.34165084 -127909.97480782 -120430.86181471 ... -149550.66076746\n",
      " -155000.72488082 -153446.94263161]\n",
      "[42073.40560883   502.09728746 -1843.54590661  3142.21109668\n",
      "  -579.99027685   645.34277695   -72.65883836 -1538.60681483\n",
      " -1302.68969824]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the validation set\n",
    "resultsObtained = regr.predict(testDataFloat)\n",
    "\n",
    "# Print predictions \n",
    "print(resultsObtained)\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean squared error using such method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10501.   574. 11649. ...  1144.  3389.  3630.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [45849, 8091]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-e91a602376e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpriceTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# testDataFloat.reshape(8091, 45849)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDataFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriceTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n\u001b[0;32m--> 387\u001b[0;31m                         multioutput='variance_weighted')\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \"\"\"\n\u001b[1;32m    529\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 530\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [45849, 8091]"
     ]
    }
   ],
   "source": [
    "print(priceTest)\n",
    "# testDataFloat.reshape(8091, 45849)\n",
    "regr.score(testDataFloat, priceTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
