{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Here, we'll run through our training data to gather information and try to achieve the best possible model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def addColumnThetaZero (array):\n",
    "    return np.c_[np.ones(array.shape[0]), array]\n",
    "\n",
    "def formatArray (dataFrame, columnToExtract) :\n",
    "    array = dataFrame.values\n",
    "    target = array[:,columnToExtract]\n",
    "    params = np.delete(array, columnToExtract, axis = 1)\n",
    "    return params, target\n",
    "\n",
    "def loadFashionTrainData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_train.csv\")\n",
    "\n",
    "def loadFashionTestData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_test.csv\")\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "#     np.random.seed(42)\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    return data[:test_set_size], data[test_set_size:]\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "def regressionLogisticCostFunction (results, model, X):\n",
    "    agaTheta = model.predict_proba(X)\n",
    "    print (agaTheta[:5])\n",
    "    print(results[:5])\n",
    "    n = X.shape[0]\n",
    "    diference = results - agaTheta\n",
    "    squareDiference = diference * diference\n",
    "    return (np.sum(squareDiference)/(2*n))\n",
    "\n",
    "def createTarget (target):\n",
    "    results = np.zeros((target.size, 10), dtype=int)\n",
    "    for i in range(0,9):\n",
    "        for j in range(target.size):\n",
    "            if (target[j] != i):\n",
    "                results[j][i] = 0\n",
    "            else:\n",
    "                results[j][i] = 1\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "\n",
    "First and foremost, we'll open train and test data. The training data is split to obtain validation items and the the target values are also separated from the original data. Also, added a column for Bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "[2 9 6 0 3]\n"
     ]
    }
   ],
   "source": [
    "fashionTrainDataset = loadFashionTrainData()\n",
    "fashionTestDataset = loadFashionTestData()\n",
    "\n",
    "trainSet, validationSet = split_train_test(fashionTrainDataset, 0.2)\n",
    "\n",
    "fashionTrainParams, fashionTrainTarget = formatArray(trainSet, 0)\n",
    "fashionValidationSetParams, fashionValidationSetTarget = formatArray(validationSet, 0)\n",
    "fashionTestParams, fashionTestTarget = formatArray (fashionTestDataset, 0)\n",
    "\n",
    "trainTarget = createTarget(fashionTrainTarget)\n",
    "print (trainTarget[:5])\n",
    "print(fashionTrainTarget[:5])\n",
    "\n",
    "\n",
    "fashionTrainParams = addColumnThetaZero(fashionTrainParams)\n",
    "fashionValidationSetParams = addColumnThetaZero(fashionValidationSetParams)\n",
    "fashionTestParams = addColumnThetaZero(fashionTestParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (fashionTrainParams[2:3][:])\n",
    "# print (fashionTrainTarget[:5])\n",
    "xToPlotMultinomial_NCG = np.array([])\n",
    "yToPlotMultinomial_NCG = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression 1\n",
    "- Multi-class choice: Multinomial\n",
    "- Solver: Newton-CG\n",
    "- Max Iteration: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.209910000000036\n",
      "Score : 0.8367291666666666\n",
      "0.8367291666666666\n",
      "(array([0.80397074, 0.9586007 , 0.71584587, 0.8614999 , 0.75569358,\n",
      "       0.88664305, 0.57178789, 0.93025706, 0.93547718, 0.94809544]), array([0.7938506 , 0.97045264, 0.74009374, 0.83111649, 0.7055867 ,\n",
      "       0.94576573, 0.62511457, 0.8982706 , 0.93373369, 0.91589163]), array([0.79887862, 0.96449026, 0.72776789, 0.84603549, 0.72978107,\n",
      "       0.91525059, 0.59726327, 0.91398406, 0.93460462, 0.93171534]), array([4846, 4772, 4694, 4962, 5173, 4499, 4364, 4915, 4829, 4946]))\n",
      "[[4.40755389e-03 1.08278897e-04 3.52336211e-01 1.22801113e-02\n",
      "  3.98984360e-01 3.06243681e-08 9.08242349e-02 6.95626017e-08\n",
      "  1.41059148e-01 1.63984943e-09]\n",
      " [3.31872195e-09 2.63850668e-08 1.97484645e-07 1.87694736e-08\n",
      "  8.29194002e-08 9.74300514e-03 7.59356207e-07 4.97498954e-01\n",
      "  1.21504544e-04 4.92635448e-01]\n",
      " [2.38927535e-04 6.19193826e-06 4.22107252e-03 8.20273598e-04\n",
      "  5.54805666e-02 1.67113564e-09 9.39093483e-01 2.86718586e-17\n",
      "  1.39483613e-04 2.45171948e-16]\n",
      " [9.95351864e-01 5.19414068e-06 1.79032381e-04 8.97570786e-05\n",
      "  4.49244266e-07 1.20242249e-13 4.37309052e-03 2.70859406e-11\n",
      "  6.12230442e-07 7.64184743e-10]\n",
      " [9.20787026e-05 7.58977361e-06 6.59216298e-05 9.98381494e-01\n",
      "  5.76692848e-04 1.18986628e-13 8.75215070e-04 2.09603988e-11\n",
      "  1.00750972e-06 1.70952363e-11]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.11735597505094031\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 10\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "logisticModel = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode, penalty = penalt)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction = regressionLogisticCostFunction(trainTarget, logisticModel, fashionTrainParams)\n",
    "print (costFunction)\n",
    "\n",
    "xToPlotMultinomial_NCG = np.append(xToPlotMultinomial_NCG,maxIter)\n",
    "yToPlotMultinomial_NCG = np.append(yToPlotMultinomial_NCG,costFunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 2\n",
    "- Multi-class choice: Multinomial\n",
    "- Solver: Newton-CG\n",
    "- Max Iteration: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-97758ae71a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlogisticModel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1289\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1291\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             w0, n_iter_i = newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 727\u001b[0;31m                                      maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36mnewton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# avoid inverting the Hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mxsupi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfhess_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtermcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0malphak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_cg\u001b[0;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mAp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfhess_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;31m# check curvature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mcurv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mhessp\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mhessProd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mhessProd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_yhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mhessProd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 100\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "logisticModel2 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel2.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel2.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction2 = regressionLogisticCostFunction(trainTarget, logisticModel2, fashionTrainParams)\n",
    "print (costFunction2)\n",
    "\n",
    "\n",
    "agaTheta = model.predict_proba(X)\n",
    "print (agaTheta[:5])\n",
    "print(results[:5])\n",
    "n = X.shape[0]\n",
    "diference = results - agaTheta\n",
    "squareDiference = diference * diference\n",
    "return (np.sum(squareDiference)/(2*n))\n",
    "\n",
    "\n",
    "\n",
    "xToPlotMultinomial_NCG = np.append(xToPlotMultinomial_NCG,maxIter)\n",
    "yToPlotMultinomial_NCG = np.append(yToPlotMultinomial_NCG,costFunction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.9478909999998\n",
      "Score : 0.789125\n",
      "0.789125\n",
      "(array([0.7354232 , 0.94390395, 0.67401607, 0.78378943, 0.66915114,\n",
      "       0.85455303, 0.52148397, 0.89570164, 0.89481328, 0.91900377]), array([0.73327777, 0.93557653, 0.65947581, 0.78790424, 0.65332525,\n",
      "       0.90429989, 0.54252072, 0.87397204, 0.91203214, 0.88814725]), array([0.73434891, 0.93972179, 0.66666667, 0.78584145, 0.6611435 ,\n",
      "       0.87872295, 0.53179438, 0.88470343, 0.90334066, 0.90331208]), array([4799, 4874, 4960, 4762, 4947, 4535, 4586, 4864, 4729, 4944]))\n",
      "[[4.24272145e-08 1.71934026e-11 7.62244360e-01 7.39133086e-03\n",
      "  1.56394887e-03 4.10035645e-32 2.26892792e-01 2.71479959e-32\n",
      "  1.90752626e-03 4.17682079e-42]\n",
      " [8.50820904e-30 4.87925802e-26 2.07565839e-21 5.55677026e-21\n",
      "  2.48790013e-24 9.84588262e-05 6.61146610e-18 7.10825223e-02\n",
      "  9.65193294e-10 9.28819018e-01]\n",
      " [3.66937207e-07 2.38607112e-13 5.02129560e-04 2.30999770e-08\n",
      "  3.91851473e-02 5.84886909e-33 9.60312333e-01 7.30116452e-72\n",
      "  3.01372340e-12 2.29377125e-68]\n",
      " [9.99999925e-01 2.76945865e-21 2.22100663e-09 9.25329310e-15\n",
      "  4.22659929e-20 6.92766436e-47 7.25358011e-08 2.37890849e-41\n",
      "  2.80363931e-16 1.02621440e-33]\n",
      " [1.83641623e-08 6.91943882e-12 4.88124241e-11 9.99999853e-01\n",
      "  7.83443170e-09 1.14873689e-40 1.20280558e-07 1.54561976e-47\n",
      "  2.18892236e-19 9.04340826e-42]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.08326686283227068\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 20\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "logisticModel2 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel2.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel2.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction2 = regressionLogisticCostFunction(trainTarget, logisticModel2, fashionTrainParams)\n",
    "print (costFunction2)\n",
    "\n",
    "\n",
    "\n",
    "xToPlotMultinomial_NCG = np.append(xToPlotMultinomial_NCG,maxIter)\n",
    "yToPlotMultinomial_NCG = np.append(yToPlotMultinomial_NCG,costFunction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.88555900000028\n",
      "Score : 0.7741666666666667\n",
      "0.7741666666666667\n",
      "(array([0.71055381, 0.93790106, 0.66165259, 0.75663255, 0.64347826,\n",
      "       0.84746822, 0.49423601, 0.8874842 , 0.88817427, 0.91460862]), array([0.70715474, 0.92620605, 0.64361596, 0.76300822, 0.63701578,\n",
      "       0.89997787, 0.5100584 , 0.87078768, 0.89598158, 0.88676948]), array([0.7088502 , 0.93201687, 0.65250965, 0.75980701, 0.64023071,\n",
      "       0.87293411, 0.50202257, 0.87905666, 0.89206085, 0.90047393]), array([4808, 4892, 4989, 4747, 4879, 4519, 4623, 4837, 4778, 4928]))\n",
      "[[1.05225224e-017 2.63815509e-023 8.89198914e-001 1.04103649e-007\n",
      "  8.28953027e-014 1.74616013e-056 1.10800982e-001 6.10902548e-055\n",
      "  1.10762834e-010 3.18393571e-074]\n",
      " [1.30104392e-071 1.11340076e-054 2.80841322e-047 6.20723356e-041\n",
      "  5.93960616e-062 4.41240674e-008 6.70743706e-040 4.35936844e-003\n",
      "  2.14651060e-021 9.95640587e-001]\n",
      " [1.47099064e-011 7.84439206e-027 2.25433780e-005 1.93952944e-018\n",
      "  7.47799616e-003 6.14261231e-062 9.92499460e-001 9.11320782e-132\n",
      "  2.73744295e-022 1.23874389e-124]\n",
      " [1.00000000e+000 1.62380239e-043 1.18631384e-016 8.40478837e-042\n",
      "  6.99771748e-035 1.64969043e-096 9.14035806e-015 1.54767748e-077\n",
      "  4.78973454e-030 1.01670547e-065]\n",
      " [3.91599993e-024 1.32163079e-028 1.80529333e-027 1.00000000e+000\n",
      "  2.23246166e-024 3.06484028e-086 8.52217027e-022 2.76225969e-094\n",
      "  7.51133280e-044 1.29602828e-084]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.07434902662965508\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 30\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "logisticModel2 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel2.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel2.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction2 = regressionLogisticCostFunction(trainTarget, logisticModel2, fashionTrainParams)\n",
    "print (costFunction2)\n",
    "\n",
    "xToPlotMultinomial_NCG = np.append(xToPlotMultinomial_NCG,maxIter)\n",
    "yToPlotMultinomial_NCG = np.append(yToPlotMultinomial_NCG,costFunction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.037520000000313\n",
      "Score : 0.8367291666666666\n",
      "0.8367291666666666\n",
      "(array([0.80397074, 0.9586007 , 0.71584587, 0.8614999 , 0.75569358,\n",
      "       0.88664305, 0.57178789, 0.93025706, 0.93547718, 0.94809544]), array([0.7938506 , 0.97045264, 0.74009374, 0.83111649, 0.7055867 ,\n",
      "       0.94576573, 0.62511457, 0.8982706 , 0.93373369, 0.91589163]), array([0.79887862, 0.96449026, 0.72776789, 0.84603549, 0.72978107,\n",
      "       0.91525059, 0.59726327, 0.91398406, 0.93460462, 0.93171534]), array([4846, 4772, 4694, 4962, 5173, 4499, 4364, 4915, 4829, 4946]))\n",
      "[[4.40755389e-03 1.08278897e-04 3.52336211e-01 1.22801113e-02\n",
      "  3.98984360e-01 3.06243681e-08 9.08242349e-02 6.95626017e-08\n",
      "  1.41059148e-01 1.63984943e-09]\n",
      " [3.31872195e-09 2.63850668e-08 1.97484645e-07 1.87694736e-08\n",
      "  8.29194002e-08 9.74300514e-03 7.59356207e-07 4.97498954e-01\n",
      "  1.21504544e-04 4.92635448e-01]\n",
      " [2.38927535e-04 6.19193826e-06 4.22107252e-03 8.20273598e-04\n",
      "  5.54805666e-02 1.67113564e-09 9.39093483e-01 2.86718586e-17\n",
      "  1.39483613e-04 2.45171948e-16]\n",
      " [9.95351864e-01 5.19414068e-06 1.79032381e-04 8.97570786e-05\n",
      "  4.49244266e-07 1.20242249e-13 4.37309052e-03 2.70859406e-11\n",
      "  6.12230442e-07 7.64184743e-10]\n",
      " [9.20787026e-05 7.58977361e-06 6.59216298e-05 9.98381494e-01\n",
      "  5.76692848e-04 1.18986628e-13 8.75215070e-04 2.09603988e-11\n",
      "  1.00750972e-06 1.70952363e-11]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.11735597505094031\n",
      "==== FINISHED =====\n",
      "10\n",
      "PARTIUU\n",
      "41.769608999999946\n",
      "Score : 0.789125\n",
      "0.789125\n",
      "(array([0.7354232 , 0.94390395, 0.67401607, 0.78378943, 0.66915114,\n",
      "       0.85455303, 0.52148397, 0.89570164, 0.89481328, 0.91900377]), array([0.73327777, 0.93557653, 0.65947581, 0.78790424, 0.65332525,\n",
      "       0.90429989, 0.54252072, 0.87397204, 0.91203214, 0.88814725]), array([0.73434891, 0.93972179, 0.66666667, 0.78584145, 0.6611435 ,\n",
      "       0.87872295, 0.53179438, 0.88470343, 0.90334066, 0.90331208]), array([4799, 4874, 4960, 4762, 4947, 4535, 4586, 4864, 4729, 4944]))\n",
      "[[4.24272145e-08 1.71934026e-11 7.62244360e-01 7.39133086e-03\n",
      "  1.56394887e-03 4.10035645e-32 2.26892792e-01 2.71479959e-32\n",
      "  1.90752626e-03 4.17682079e-42]\n",
      " [8.50820904e-30 4.87925802e-26 2.07565839e-21 5.55677026e-21\n",
      "  2.48790013e-24 9.84588262e-05 6.61146610e-18 7.10825223e-02\n",
      "  9.65193294e-10 9.28819018e-01]\n",
      " [3.66937207e-07 2.38607112e-13 5.02129560e-04 2.30999770e-08\n",
      "  3.91851473e-02 5.84886909e-33 9.60312333e-01 7.30116452e-72\n",
      "  3.01372340e-12 2.29377125e-68]\n",
      " [9.99999925e-01 2.76945865e-21 2.22100663e-09 9.25329310e-15\n",
      "  4.22659929e-20 6.92766436e-47 7.25358011e-08 2.37890849e-41\n",
      "  2.80363931e-16 1.02621440e-33]\n",
      " [1.83641623e-08 6.91943882e-12 4.88124241e-11 9.99999853e-01\n",
      "  7.83443170e-09 1.14873689e-40 1.20280558e-07 1.54561976e-47\n",
      "  2.18892236e-19 9.04340826e-42]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.08326686283227068\n",
      "==== FINISHED =====\n",
      "20\n",
      "PARTIUU\n",
      "88.18179499999997\n",
      "Score : 0.7741666666666667\n",
      "0.7741666666666667\n",
      "(array([0.71055381, 0.93790106, 0.66165259, 0.75663255, 0.64347826,\n",
      "       0.84746822, 0.49423601, 0.8874842 , 0.88817427, 0.91460862]), array([0.70715474, 0.92620605, 0.64361596, 0.76300822, 0.63701578,\n",
      "       0.89997787, 0.5100584 , 0.87078768, 0.89598158, 0.88676948]), array([0.7088502 , 0.93201687, 0.65250965, 0.75980701, 0.64023071,\n",
      "       0.87293411, 0.50202257, 0.87905666, 0.89206085, 0.90047393]), array([4808, 4892, 4989, 4747, 4879, 4519, 4623, 4837, 4778, 4928]))\n",
      "[[1.05225224e-017 2.63815509e-023 8.89198914e-001 1.04103649e-007\n",
      "  8.28953027e-014 1.74616013e-056 1.10800982e-001 6.10902548e-055\n",
      "  1.10762834e-010 3.18393571e-074]\n",
      " [1.30104392e-071 1.11340076e-054 2.80841322e-047 6.20723356e-041\n",
      "  5.93960616e-062 4.41240674e-008 6.70743706e-040 4.35936844e-003\n",
      "  2.14651060e-021 9.95640587e-001]\n",
      " [1.47099064e-011 7.84439206e-027 2.25433780e-005 1.93952944e-018\n",
      "  7.47799616e-003 6.14261231e-062 9.92499460e-001 9.11320782e-132\n",
      "  2.73744295e-022 1.23874389e-124]\n",
      " [1.00000000e+000 1.62380239e-043 1.18631384e-016 8.40478837e-042\n",
      "  6.99771748e-035 1.64969043e-096 9.14035806e-015 1.54767748e-077\n",
      "  4.78973454e-030 1.01670547e-065]\n",
      " [3.91599993e-024 1.32163079e-028 1.80529333e-027 1.00000000e+000\n",
      "  2.23246166e-024 3.06484028e-086 8.52217027e-022 2.76225969e-094\n",
      "  7.51133280e-044 1.29602828e-084]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.07434902662965508\n",
      "==== FINISHED =====\n",
      "30\n",
      "PARTIUU\n",
      "139.73796700000003\n",
      "Score : 0.7697916666666667\n",
      "0.7697916666666667\n",
      "(array([0.7015674 , 0.93852205, 0.65753142, 0.74827658, 0.63871636,\n",
      "       0.84413419, 0.48186963, 0.88706279, 0.88609959, 0.91460862]), array([0.69145211, 0.92568395, 0.64192315, 0.75188917, 0.63386069,\n",
      "       0.89922309, 0.50317356, 0.87145519, 0.88720399, 0.88712952]), array([0.69647303, 0.93205879, 0.64963355, 0.75007853, 0.63627926,\n",
      "       0.87080825, 0.49229122, 0.87918973, 0.88665144, 0.90065952]), array([4855, 4898, 4971, 4764, 4867, 4505, 4569, 4831, 4814, 4926]))\n",
      "[[1.65932556e-024 1.87937115e-033 9.47073200e-001 9.69057004e-011\n",
      "  2.65390307e-018 3.51074741e-068 5.29267999e-002 5.04283781e-064\n",
      "  7.41370413e-016 1.27908186e-086]\n",
      " [5.47389018e-107 3.24867987e-078 4.05924063e-070 5.64545871e-059\n",
      "  8.25648375e-095 2.45745744e-010 1.74318443e-058 1.77663624e-003\n",
      "  4.79094706e-030 9.98223364e-001]\n",
      " [1.36590899e-014 9.70717569e-036 3.00266184e-006 4.96877071e-027\n",
      "  2.20178033e-003 2.30808759e-079 9.97795217e-001 1.11286949e-158\n",
      "  3.13169529e-029 6.08178818e-151]\n",
      " [1.00000000e+000 1.71130036e-059 3.33314611e-022 1.22882370e-071\n",
      "  2.54723820e-043 5.37233956e-128 1.00479626e-020 1.53457418e-100\n",
      "  4.60511407e-044 1.55377241e-089]\n",
      " [9.69862352e-038 1.66996139e-041 2.14262378e-041 1.00000000e+000\n",
      "  3.05675901e-038 4.45638341e-114 1.34591859e-034 2.99074346e-121\n",
      "  1.59199576e-064 1.14813697e-111]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.0711543270356935\n",
      "==== FINISHED =====\n",
      "40\n",
      "PARTIUU\n",
      "183.2867540000002\n",
      "Score : 0.7673541666666667\n",
      "0.7673541666666667\n",
      "(array([0.69822362, 0.93831505, 0.65382238, 0.74806768, 0.63374741,\n",
      "       0.8414253 , 0.47746804, 0.88685209, 0.88443983, 0.91167853]), array([0.68702447, 0.92359413, 0.63894482, 0.75089117, 0.63074387,\n",
      "       0.89455029, 0.50043937, 0.87016746, 0.88096714, 0.88916105]), array([0.69257877, 0.9308964 , 0.64629799, 0.74947677, 0.63224207,\n",
      "       0.86717492, 0.4886839 , 0.87843055, 0.88270007, 0.90027901]), array([4863, 4908, 4966, 4769, 4853, 4514, 4552, 4837, 4839, 4899]))\n",
      "[[1.43417139e-027 2.17834299e-039 9.60038645e-001 1.21062994e-010\n",
      "  5.31285719e-019 3.02646058e-075 3.99613546e-002 1.11481117e-066\n",
      "  2.53776726e-017 6.60603666e-092]\n",
      " [1.12093469e-130 7.27054861e-092 5.76360341e-084 1.94367793e-069\n",
      "  2.03996276e-113 6.55575775e-011 5.48575548e-069 8.67408938e-004\n",
      "  1.10256086e-036 9.99132591e-001]\n",
      " [4.95322338e-017 6.20027518e-041 1.17034364e-006 2.12911322e-032\n",
      "  1.21935596e-003 3.68523761e-091 9.98779474e-001 7.00209179e-171\n",
      "  1.24790668e-033 4.45995969e-165]\n",
      " [1.00000000e+000 2.24211145e-068 5.21047398e-026 2.76126205e-090\n",
      "  7.13713322e-048 6.74353663e-149 3.10036346e-024 7.17862620e-113\n",
      "  8.32950678e-053 5.32212965e-103]\n",
      " [6.20110551e-046 2.13064487e-049 8.42677566e-050 1.00000000e+000\n",
      "  8.94285323e-047 1.11329788e-131 1.12098863e-042 4.51263749e-135\n",
      "  7.64062200e-077 6.45864366e-126]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.06972768944601598\n",
      "==== FINISHED =====\n",
      "50\n",
      "PARTIUU\n",
      "233.76309600000013\n",
      "Score : 0.7651875\n",
      "0.7651875\n",
      "(array([0.692372  , 0.93790106, 0.65155574, 0.74618759, 0.62939959,\n",
      "       0.8360075 , 0.47474324, 0.88558786, 0.88651452, 0.91209711]), array([0.67958974, 0.9222471 , 0.63878788, 0.74728033, 0.63096721,\n",
      "       0.89493643, 0.49357158, 0.87108808, 0.87777321, 0.8895693 ]), array([0.68592133, 0.93000821, 0.64510864, 0.74673356, 0.63018242,\n",
      "       0.86446886, 0.48397436, 0.87827813, 0.88212221, 0.90069236]), array([4875, 4913, 4950, 4780, 4818, 4483, 4589, 4825, 4868, 4899]))\n",
      "[[6.55032640e-033 6.52014259e-048 9.80590431e-001 2.42721472e-009\n",
      "  7.95209103e-019 2.45900249e-086 1.94095661e-002 4.21136424e-073\n",
      "  5.08726188e-019 5.67757394e-100]\n",
      " [5.58950101e-166 2.00981797e-111 8.36223368e-104 4.56779861e-084\n",
      "  6.29879335e-138 4.04365048e-012 2.81195534e-083 1.06751297e-003\n",
      "  1.04525932e-045 9.98932487e-001]\n",
      " [3.39439007e-021 1.87387849e-049 4.55275249e-007 1.10996744e-040\n",
      "  5.44665703e-004 2.82005556e-109 9.99454879e-001 5.89120089e-191\n",
      "  3.56799191e-041 8.01600139e-186]\n",
      " [1.00000000e+000 1.32167451e-081 2.31839861e-031 1.58433106e-118\n",
      "  4.64259975e-055 6.00408489e-181 3.13731658e-029 1.66879025e-133\n",
      "  9.17354672e-066 7.88911943e-125]\n",
      " [5.10744500e-058 7.71427163e-062 1.20390851e-062 1.00000000e+000\n",
      "  8.53490974e-060 1.09723880e-160 7.14789309e-055 6.83217231e-157\n",
      "  3.19273043e-095 3.35622198e-149]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.06791844137925186\n",
      "==== FINISHED =====\n",
      "60\n",
      "PARTIUU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278.63318700000036\n",
      "Score : 0.7634166666666666\n",
      "0.7634166666666666\n",
      "(array([0.6907001 , 0.93686607, 0.64867093, 0.74639649, 0.62505176,\n",
      "       0.83538237, 0.47118005, 0.88516646, 0.88506224, 0.91021348]), array([0.67380224, 0.91973176, 0.63776337, 0.74592902, 0.6294829 ,\n",
      "       0.89546571, 0.49072255, 0.87031282, 0.87579552, 0.88827614]), array([0.68214654, 0.92821985, 0.64317091, 0.74616268, 0.62725951,\n",
      "       0.8643812 , 0.48075278, 0.8776768 , 0.8804045 , 0.89911102]), array([4905, 4921, 4936, 4790, 4796, 4477, 4581, 4827, 4871, 4896]))\n",
      "[[1.15244035e-037 1.86500807e-054 9.90021181e-001 1.88498079e-007\n",
      "  7.66286073e-017 2.68217991e-097 9.97863029e-003 2.10851951e-077\n",
      "  1.26242191e-019 1.41519244e-108]\n",
      " [2.33173137e-198 1.89754519e-128 5.62753479e-124 2.47169829e-099\n",
      "  9.94904930e-158 3.12126034e-014 1.89572852e-098 4.51379933e-005\n",
      "  3.58134649e-055 9.99954862e-001]\n",
      " [1.30989705e-024 1.09209877e-056 2.47535701e-007 9.12236951e-048\n",
      "  3.08904677e-004 3.10256143e-126 9.99690848e-001 1.36093464e-206\n",
      "  1.51371489e-047 4.15598956e-206]\n",
      " [1.00000000e+000 9.59358539e-093 1.22119102e-035 6.54173719e-142\n",
      "  8.44734211e-061 1.11310424e-205 6.45298413e-033 2.22447883e-150\n",
      "  2.62581884e-079 6.74816645e-145]\n",
      " [1.42646418e-068 8.92774382e-073 8.56184403e-074 1.00000000e+000\n",
      "  3.43981306e-071 3.07618376e-184 1.30873039e-065 3.42474954e-176\n",
      "  6.20465525e-112 9.14834205e-171]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.06666615502099954\n",
      "==== FINISHED =====\n",
      "70\n",
      "PARTIUU\n",
      "328.93330699999933\n",
      "Score : 0.7624791666666667\n",
      "0.7624791666666667\n",
      "(array([0.68819227, 0.93624508, 0.64722852, 0.74639649, 0.62173913,\n",
      "       0.83475724, 0.47013205, 0.88579857, 0.8846473 , 0.91021348]), array([0.6709454 , 0.92005696, 0.6359587 , 0.7451512 , 0.62890052,\n",
      "       0.89379741, 0.48792691, 0.87039337, 0.87466667, 0.890641  ]), array([0.6794594 , 0.92808044, 0.64154412, 0.74577332, 0.62529932,\n",
      "       0.86326904, 0.47886422, 0.8780284 , 0.87962867, 0.90032088]), array([4908, 4916, 4939, 4795, 4775, 4482, 4597, 4830, 4875, 4883]))\n",
      "[[3.32873286e-040 4.33683531e-057 9.95450276e-001 3.28038122e-006\n",
      "  1.96110223e-015 1.20035131e-102 4.54644348e-003 6.74227429e-079\n",
      "  1.43785646e-018 1.04151799e-111]\n",
      " [1.08421249e-214 2.36493788e-137 4.08816615e-134 3.55176830e-106\n",
      "  1.61306085e-167 2.51468602e-014 1.38178090e-105 2.28800757e-004\n",
      "  1.17770006e-060 9.99771199e-001]\n",
      " [1.04441733e-026 1.88681353e-060 1.78579440e-007 6.39789118e-052\n",
      "  2.41215559e-004 5.06780837e-136 9.99758606e-001 1.26468591e-214\n",
      "  4.70371905e-051 2.31200855e-215]\n",
      " [1.00000000e+000 3.19405685e-098 4.83122846e-038 3.30579824e-155\n",
      "  5.37830221e-064 2.98661335e-220 5.49536434e-035 3.58885458e-160\n",
      "  1.27691396e-084 3.31910921e-154]\n",
      " [2.18811478e-074 5.61973617e-080 4.56599673e-080 1.00000000e+000\n",
      "  1.26521700e-077 6.84496751e-199 9.64107353e-072 1.28507368e-186\n",
      "  1.75361822e-121 6.63986499e-182]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.06603599460772037\n",
      "==== FINISHED =====\n",
      "80\n",
      "PARTIUU\n",
      "380.38855800000056\n",
      "Score : 0.762125\n",
      "0.762125\n",
      "(array([0.68902821, 0.93583109, 0.6468164 , 0.74535199, 0.62215321,\n",
      "       0.83496562, 0.46950325, 0.88453434, 0.88423237, 0.90937631]), array([0.67135003, 0.91890244, 0.63581122, 0.74333333, 0.62945119,\n",
      "       0.89422004, 0.48844309, 0.86879139, 0.87407711, 0.88982183]), array([0.68007426, 0.92728951, 0.6412666 , 0.7443413 , 0.62578092,\n",
      "       0.86357759, 0.47878594, 0.87659219, 0.87912541, 0.89949281]), array([4911, 4920, 4937, 4800, 4774, 4481, 4586, 4832, 4876, 4883]))\n",
      "[[4.70841861e-043 1.38993887e-059 9.97851981e-001 6.17514218e-005\n",
      "  4.95177406e-014 4.25907292e-109 2.08626766e-003 9.24792655e-082\n",
      "  2.08129678e-019 7.45883119e-117]\n",
      " [5.37398515e-234 5.62120301e-148 1.46022844e-146 5.78824255e-115\n",
      "  1.56302440e-179 4.01435917e-015 5.07885508e-115 1.69171315e-004\n",
      "  2.84777018e-067 9.99830829e-001]\n",
      " [5.53784687e-029 1.79793578e-064 1.28022128e-007 1.88873693e-056\n",
      "  1.84060995e-004 3.91277718e-146 9.99815811e-001 6.67208804e-225\n",
      "  1.09650319e-054 4.45062988e-226]\n",
      " [1.00000000e+000 1.00598262e-103 7.10421848e-041 4.90610775e-169\n",
      "  6.23396125e-068 3.42356410e-235 1.67963157e-037 1.18203403e-171\n",
      "  1.97014267e-091 1.37535494e-165]\n",
      " [8.83563463e-081 1.06361766e-086 7.40738096e-087 1.00000000e+000\n",
      "  1.68895947e-084 5.51543059e-214 2.92153700e-078 2.45753294e-199\n",
      "  1.70772485e-131 9.31801761e-195]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.06542337372075778\n",
      "==== FINISHED =====\n",
      "90\n",
      "PARTIUU\n",
      "444.99534200000016\n",
      "Score : 0.7615833333333333\n",
      "0.7615833333333333\n",
      "(array([0.68881923, 0.93562409, 0.645374  , 0.7451431 , 0.6194617 ,\n",
      "       0.83621588, 0.46761685, 0.88411294, 0.88319502, 0.91084136]), array([0.67087319, 0.91869919, 0.63298302, 0.74266084, 0.62685942,\n",
      "       0.89535921, 0.48690528, 0.86873706, 0.87466612, 0.89143794]), array([0.67972778, 0.9270844 , 0.63911846, 0.7438999 , 0.6231386 ,\n",
      "       0.8647775 , 0.47706618, 0.87635756, 0.87890988, 0.9010352 ]), array([4913, 4920, 4948, 4803, 4773, 4482, 4582, 4830, 4867, 4882]))\n",
      "[[2.64343584e-046 1.04536013e-063 9.99650133e-001 1.45287083e-004\n",
      "  1.96394249e-012 8.43663636e-116 2.04580070e-004 3.81148356e-086\n",
      "  7.79147431e-020 1.03916309e-122]\n",
      " [5.80011666e-252 1.00041312e-157 3.51795004e-158 2.90186807e-122\n",
      "  7.06699386e-191 5.94216188e-016 1.46611493e-123 1.00782167e-004\n",
      "  3.94287065e-073 9.99899218e-001]\n",
      " [2.85256690e-031 7.45893454e-069 7.62149083e-008 5.95576204e-061\n",
      "  1.27859194e-004 2.42250854e-157 9.99872065e-001 2.71493346e-235\n",
      "  4.06456111e-059 6.52284333e-238]\n",
      " [1.00000000e+000 8.58809049e-110 1.28454865e-043 2.10956417e-182\n",
      "  9.26384151e-072 9.12818571e-251 5.96101667e-040 3.44647860e-182\n",
      "  3.80101726e-098 4.99623253e-177]\n",
      " [1.17683398e-086 1.28567493e-093 2.97626840e-093 1.00000000e+000\n",
      "  5.38820361e-091 2.49923956e-228 1.97616087e-084 9.91041920e-211\n",
      "  3.01937213e-141 6.77476417e-207]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.06487477973956444\n",
      "==== FINISHED =====\n",
      "100\n",
      "PARTIUU\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 10\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "\n",
    "for i in range (10, 101, 10):\n",
    "    maxIter = i\n",
    "    logisticModel2 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "    start = time.clock()\n",
    "    logisticModel2.fit(fashionTrainParams, fashionTrainTarget)\n",
    "    print (time.clock() - start)\n",
    "\n",
    "    print(\"Score : \"+ str(logisticModel2.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "    print(metrics.accuracy_score(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "    print(metrics.precision_recall_fscore_support(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "    costFunction2 = regressionLogisticCostFunction(trainTarget, logisticModel2, fashionTrainParams)\n",
    "    print (costFunction2)\n",
    "\n",
    "    xToPlotMultinomial_NCG = np.append(xToPlotMultinomial_NCG,maxIter)\n",
    "    yToPlotMultinomial_NCG = np.append(yToPlotMultinomial_NCG,costFunction2)\n",
    "    print (\"==== FINISHED =====\")\n",
    "    print (i)\n",
    "    print (\"PARTIUU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for i in range (10, 101, 10):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8cb05f1080>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEYBJREFUeJzt3W2spGV9x/Hvz7MuLRgfoMcG2ZVdIy1uaoo6rtg2xEhRSAz7Bip0a9HQbuMpqfUhDdYmpjS+ILXFNmUJJ6KlBgWktt3QRGLAF6a2hLM+IOuKbJGHI1aO4cFGkuLu/vtiZrtnj4eee3Znzwzn+n6Sycx13dfM+c+d+/zmnuu+ZyZVhSSpDS8YdwGSpNVj6EtSQwx9SWqIoS9JDTH0Jakhhr4kNaRT6Cc5P8n9SfYluXKZ5eck+VqS/UkuWtR/VpJ/T7Inyb1J3jnK4iVJw8lK5+knmQK+C5wHzAP3AJdW1bcXjdkEvBj4ELCrqm4b9P8SUFX1QJJXALuB11TVU6N/KpKklazrMGYrsK+qHgRIcjOwDfi/0K+qhwbLDi6+Y1V9d9Htx5I8DkwDhr4kjUGX0D8NeHRRex5407B/KMlWYD3wn8ss2wHsADjppJPecOaZZw778JLUtN27d/+oqqZXGtcl9LNM31Df3ZDkVOAzwGVVdXDp8qqaBWYBer1ezc3NDfPwktS8JA93GdflQO48sHFRewPw2BCFvBj4V+DPquo/ut5PkjR6XUL/HuCMJJuTrAcuAXZ1efDB+H8C/qGqPn/0ZUqSRmHF0K+q/cAVwB3AXuDWqtqT5KokFwIkeWOSeeBi4PokewZ3/y3gHODdSb4xuJx1XJ6JJGlFK56yudqc05ek4SXZXVW9lcb5iVxJasjaCf2ZGVi3DpL+9czMuCuSpInT5ZTNyTczA9ddd7h94MDh9s6d46lJkibQ2tjTn50drl+SGrU2Qv/AgeH6JalRayP0p6aG65ekRq2N0N+xY7h+SWrU2jiQe+hg7exsf0pnaqof+B7ElaQjrI3Qh37AG/KS9P9aG9M7kqRODH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIZ1CP8n5Se5Psi/JlcssPyfJ15LsT3LRkmVfTPJUkttHVbQk6eisGPpJpoBrgQuALcClSbYsGfYI8G7gs8s8xF8C7zq2MiVJo9BlT38rsK+qHqyqZ4GbgW2LB1TVQ1V1L3Bw6Z2r6k7gv0dRrCTp2HQJ/dOARxe15wd9I5NkR5K5JHMLCwujfGhJ0iJdQj/L9NUoi6iq2arqVVVvenp6lA8tSVqkS+jPAxsXtTcAjx2fciRJx1OX0L8HOCPJ5iTrgUuAXce3LEnS8bBi6FfVfuAK4A5gL3BrVe1JclWSCwGSvDHJPHAxcH2SPYfun+QrwOeBc5PMJ3n78XgikqSVpWqk0/PHrNfr1dzc3LjLkKTnlSS7q6q30jg/kStJDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JBOoZ/k/CT3J9mX5Mpllp+T5GtJ9ie5aMmyy5I8MLhcNqrCJUnDWzH0k0wB1wIXAFuAS5NsWTLsEeDdwGeX3Pdk4KPAm4CtwEeTvOzYy5YkHY0ue/pbgX1V9WBVPQvcDGxbPKCqHqqqe4GDS+77duBLVfVEVT0JfAk4fwR1S5KOQpfQPw14dFF7ftDXRaf7JtmRZC7J3MLCQseHliQNq0voZ5m+6vj4ne5bVbNV1auq3vT0dMeHliQNq0vozwMbF7U3AI91fPxjua8kacS6hP49wBlJNidZD1wC7Or4+HcAb0vyssEB3LcN+iRJY7Bi6FfVfuAK+mG9F7i1qvYkuSrJhQBJ3phkHrgYuD7JnsF9nwD+gv4Lxz3AVYM+SdIYpKrr9Pzq6PV6NTc3N+4yJOl5JcnuquqtNM5P5EpSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0JakhnUI/yflJ7k+yL8mVyyw/Icktg+V3J9k06F+f5NNJvpXkm0neMtLqJUlDWTH0k0wB1wIXAFuAS5NsWTLscuDJqno1cA1w9aD/9wGq6rXAecBfJfHdhSSNSZcA3grsq6oHq+pZ4GZg25Ix24AbB7dvA85NEvovEncCVNXjwFNAbxSFS5KG1yX0TwMeXdSeH/QtO6aq9gNPA6cA3wS2JVmXZDPwBmDj0j+QZEeSuSRzCwsLwz8LSVInXUI/y/RVxzGfov8iMQd8AvgqsP9nBlbNVlWvqnrT09MdSpIkHY11HcbMc+Te+QbgsecYM59kHfAS4ImqKuD9hwYl+SrwwDFVLEk6al329O8BzkiyOcl64BJg15Ixu4DLBrcvAu6qqkpyYpKTAJKcB+yvqm+PqHZJ0pBW3NOvqv1JrgDuAKaAT1XVniRXAXNVtQu4AfhMkn3AE/RfGABeDtyR5CDwfeBdx+NJSJK6SX8GZnL0er2am5sbdxmS9LySZHdVrXh2pOfMS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMM/VGamYF16yDpX8/MjLsiSTrCir+Rq45mZuC66w63Dxw43N65czw1SdIS7umPyuzscP2SNAaG/qgcODBcvySNgaE/KlNTw/VL0hgY+qOyY8dw/ZI0Bh7IHZVDB2tnZ/tTOlNT/cD3IK6kCWLoj9LOnYa8pInm9I4kNcTQl6SGGPqS1BBDX5Ia0in0k5yf5P4k+5JcuczyE5LcMlh+d5JNg/4XJrkxybeS7E3y4dGWL0kaxoqhn2QKuBa4ANgCXJpky5JhlwNPVtWrgWuAqwf9FwMnVNVrgTcAf3DoBUGStPq67OlvBfZV1YNV9SxwM7BtyZhtwI2D27cB5yYJUMBJSdYBPw88C/x4JJVLkobWJfRPAx5d1J4f9C07pqr2A08Dp9B/AfgJ8APgEeDjVfXE0j+QZEeSuSRzCwsLQz8JSVI3XUI/y/RVxzFbgQPAK4DNwAeTvOpnBlbNVlWvqnrT09MdSpIkHY0uoT8PbFzU3gA89lxjBlM5LwGeAH4b+GJV/bSqHgf+Degda9GSpKPTJfTvAc5IsjnJeuASYNeSMbuAywa3LwLuqqqiP6Xz1vSdBJwNfGc0pUuShrVi6A/m6K8A7gD2ArdW1Z4kVyW5cDDsBuCUJPuADwCHTuu8FngRcB/9F49PV9W9I34OkqSO0t8hnxy9Xq/m5ubGXYYkPa8k2V1VK06f+4lcSWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0F+LZmZg3TpI+tczM+OuSNKEWDfuAjRiMzNw3XWH2wcOHG7v3DmemiRNDPf015rZ2eH6JTXF0F9rDhwYrl9SUwz9tWZqarh+SU0x9NeaHTuG65fUFA/krjWHDtbOzvandKam+oHvQVxJGPpr086dhrykZTm9I0kNMfQlqSGGviQ1xNCXpIYY+jp+/A4gaeJ49o6OD78DSJpI7unr+PA7gKSJZOjr+PA7gKSJZOjr+PA7gKSJ1Cn0k5yf5P4k+5JcuczyE5LcMlh+d5JNg/7tSb6x6HIwyVmjfQqaSH4HkDSRVgz9JFPAtcAFwBbg0iRblgy7HHiyql4NXANcDVBVN1XVWVV1FvAu4KGq+sYon4Am1M6d8N73Ht6zn5rqt8dxEPemm2DTJnjBC/rXN920+jVIE6LLnv5WYF9VPVhVzwI3A9uWjNkG3Di4fRtwbpIsGXMp8LljKVbPMzt3wv79UNW/Hlfg79gBDz/cr+Phh/ttg1+N6hL6pwGPLmrPD/qWHVNV+4GngVOWjHknzxH6SXYkmUsyt7Cw0KVuqZuPfASeeebIvmee6fdLDeoS+kv32AFqmDFJ3gQ8U1X3LfcHqmq2qnpV1Zuenu5QktTRI48M1y+tcV1Cfx7YuKi9AXjsucYkWQe8BHhi0fJLcGpH4/DKVw7XL61xXUL/HuCMJJuTrKcf4LuWjNkFXDa4fRFwV1UVQJIXABfTPxYgra6PfQxOPPHIvhNP7PdLDVox9Adz9FcAdwB7gVurak+Sq5JcOBh2A3BKkn3AB4DFp3WeA8xX1YOjLV3qYPv2/qeATz+9/x1Ap5/eb2/fvvq1eBaRJkAGO+QTo9fr1dzc3LjLkEbr0FlEiw8qn3ji+F6AtOYk2V1VvZXG+YlcaTV4FpEmhKEvrQbPItKEMPSl1eBZRJoQhr60GibpLCIPKDfN0JdWw6ScReTXUjTPs3eklmza1A/6pU4/HR56aLWr0Qh59o6knzUpB5SdYhobQ19qySQcUHaKaawMfaklk3BAeZI+s9DgOw5DX2rJJBxQnqQppgbfcRj6Umu2b+8ftD14sH+92mcQTcIUEzT7jsPQl7S6JmGKCZp9x2HoS1pdkzDFBM2+4zD0Ja2+cU8xQbPvOAx9SW1q9B2HoS+pXQ2+4zD0JWmcVvkdx7rj8qiSpO62b1+1dxnu6UtSQwx9SWqIoS9JDTH0Jakhhr4kNWTifjkryQKwzE/7PK/8AvCjcRcxQVwfR3J9HOa6ONKxrI/Tq2p6pUETF/prQZK5Lj9b1grXx5FcH4e5Lo60GuvD6R1JaoihL0kNMfSPj9lxFzBhXB9Hcn0c5ro40nFfH87pS1JD3NOXpIYY+pLUEEP/GCXZmOTLSfYm2ZPkfYP+k5N8KckDg+uXjbvW1ZJkKsnXk9w+aG9OcvdgXdySZP24a1wtSV6a5LYk3xlsI29ufNt4/+D/5L4kn0vycy1tH0k+leTxJPct6lt2e0jf3ybZl+TeJK8fRQ2G/rHbD3ywql4DnA38YZItwJXAnVV1BnDnoN2K9wF7F7WvBq4ZrIsngcvHUtV4/A3wxao6E/hV+uulyW0jyWnAHwG9qvoVYAq4hLa2j78Hzl/S91zbwwXAGYPLDuC6kVRQVV5GeAH+BTgPuB84ddB3KnD/uGtbpee/YbDhvhW4HQj9TxiuGyx/M3DHuOtcpXXxYuB7DE6YWNTf6rZxGvAocDL93/K4HXh7a9sHsAm4b6XtAbgeuHS5ccdycU9/hJJsAl4H3A38YlX9AGBw/fLxVbaqPgH8CXBw0D4FeKqq9g/a8/T/+VvwKmAB+PRguuuTSU6i0W2jqr4PfBx4BPgB8DSwm3a3j0Oea3s49CJ5yEjWjaE/IkleBPwj8MdV9eNx1zMOSd4BPF5Vuxd3LzO0lfOE1wGvB66rqtcBP6GRqZzlDOaqtwGbgVcAJ9Gfwliqle1jJcflf8fQH4EkL6Qf+DdV1RcG3T9Mcupg+anA4+OqbxX9OnBhkoeAm+lP8XwCeGmSQz/NuQF4bDzlrbp5YL6q7h60b6P/ItDitgHwm8D3qmqhqn4KfAH4NdrdPg55ru1hHti4aNxI1o2hf4ySBLgB2FtVf71o0S7gssHty+jP9a9pVfXhqtpQVZvoH6C7q6q2A18GLhoMa2JdAFTVfwGPJvnlQde5wLdpcNsYeAQ4O8mJg/+bQ+ujye1jkefaHnYBvzs4i+ds4OlD00DHwk/kHqMkvwF8BfgWh+ex/5T+vP6twCvpb+wXV9UTYylyDJK8BfhQVb0jyavo7/mfDHwd+J2q+p9x1rdakpwFfBJYDzwIvIf+zlaT20aSPwfeSf+st68Dv0d/nrqJ7SPJ54C30P8K5R8CHwX+mWW2h8EL49/RP9vnGeA9VTV3zDUY+pLUDqd3JKkhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqyP8CxAIrupHwu+IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(xToPlotMultinomial_NCG, yToPlotMultinomial_NCG, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702.2434599999997\n",
      "Score : 0.7601458333333333\n",
      "0.7601458333333333\n",
      "(array([0.68735632, 0.93438212, 0.6443437 , 0.74785878, 0.61635611,\n",
      "       0.83559075, 0.46510166, 0.88305942, 0.87946058, 0.90853914]), array([0.66808856, 0.91692058, 0.62690457, 0.74273859, 0.62752951,\n",
      "       0.89488953, 0.48640947, 0.86968251, 0.87168415, 0.89009637]), array([0.6775855 , 0.925569  , 0.63550452, 0.74528989, 0.62189263,\n",
      "       0.86422414, 0.47551698, 0.87631992, 0.8755551 , 0.8992232 ]), array([4923, 4923, 4988, 4820, 4744, 4481, 4562, 4819, 4863, 4877]))\n",
      "[[5.26098522e-057 2.88538297e-074 9.99788039e-001 2.11911628e-004\n",
      "  1.77613266e-008 1.85848370e-138 3.19808612e-008 9.58846527e-098\n",
      "  1.52446418e-020 1.74744338e-138]\n",
      " [3.01226042e-315 4.81517824e-191 2.23297516e-199 3.25619484e-148\n",
      "  1.03073425e-232 2.33145611e-017 2.54145412e-153 8.15342577e-005\n",
      "  1.54063459e-091 9.99918466e-001]\n",
      " [9.17354959e-040 5.68551913e-083 1.65900483e-008 4.65503020e-076\n",
      "  5.61739702e-005 5.57196710e-192 9.99943809e-001 2.73025288e-267\n",
      "  1.37625421e-072 7.30491879e-274]\n",
      " [1.00000000e+000 2.83300349e-129 3.38603539e-054 3.21642609e-226\n",
      "  4.06728905e-087 1.81771205e-300 2.82340448e-049 2.84443723e-217\n",
      "  1.20580695e-121 6.13244692e-214]\n",
      " [1.71270106e-106 3.05161123e-116 1.06109590e-114 1.00000000e+000\n",
      "  1.00062075e-112 2.80127325e-275 5.60183685e-105 3.73137527e-248\n",
      "  4.32278464e-174 1.19609717e-247]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.06328893614630433\n",
      "==== FINISHED =====\n",
      "150\n",
      "PARTIUU\n",
      "913.3690130000005\n",
      "Score : 0.7585833333333334\n",
      "0.7585833333333334\n",
      "(array([0.68422153, 0.93355413, 0.64269524, 0.74597869, 0.61138716,\n",
      "       0.83496562, 0.46531126, 0.88390223, 0.87738589, 0.90707409]), array([0.66409736, 0.91815961, 0.62218233, 0.73995027, 0.62776361,\n",
      "       0.89622008, 0.48344948, 0.86979059, 0.87106076, 0.88920804]), array([0.67400926, 0.92579288, 0.63227245, 0.74295225, 0.61946717,\n",
      "       0.86450917, 0.47420698, 0.87678963, 0.87421189, 0.89805222]), array([4930, 4912, 5013, 4826, 4704, 4471, 4592, 4823, 4855, 4874]))\n",
      "[[7.47881778e-064 7.73277250e-082 9.99765488e-001 2.28981624e-004\n",
      "  5.52955662e-006 1.15125100e-155 7.61041173e-010 6.80789864e-108\n",
      "  4.16478304e-020 1.23643513e-150]\n",
      " [0.00000000e+000 4.45211204e-218 4.99439801e-231 2.66179270e-169\n",
      "  1.50648202e-268 1.08053666e-017 1.93276435e-174 9.16674704e-005\n",
      "  1.26220219e-104 9.99908333e-001]\n",
      " [1.24042600e-046 3.14932565e-094 4.04913550e-009 1.02612734e-087\n",
      "  3.10036442e-005 1.70146465e-219 9.99968992e-001 1.93199883e-292\n",
      "  4.01999561e-084 3.22719894e-299]\n",
      " [1.00000000e+000 4.82446795e-143 3.50856597e-062 1.61780322e-257\n",
      "  1.75856787e-099 0.00000000e+000 1.57434986e-056 5.07679915e-244\n",
      "  8.85366076e-140 7.46974722e-241]\n",
      " [1.95512350e-121 8.78475723e-134 6.69211904e-131 1.00000000e+000\n",
      "  4.27803989e-129 7.85798700e-311 2.41833500e-120 1.69505527e-277\n",
      "  1.26474450e-199 9.54557350e-278]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.062249923596971846\n",
      "==== FINISHED =====\n",
      "200\n",
      "PARTIUU\n",
      "1198.8838349999996\n",
      "Score : 0.7575208333333333\n",
      "0.7575208333333333\n",
      "(array([0.68401254, 0.93251915, 0.63939831, 0.74556089, 0.6068323 ,\n",
      "       0.83225672, 0.46510166, 0.88369153, 0.87780083, 0.90874843]), array([0.66322188, 0.91863785, 0.61849711, 0.73984245, 0.6249467 ,\n",
      "       0.8955157 , 0.48061512, 0.869944  , 0.87147271, 0.89030141]), array([0.67345679, 0.92552645, 0.62877406, 0.74269067, 0.6157563 ,\n",
      "       0.86272816, 0.47273115, 0.87676388, 0.87462532, 0.89943035]), array([4935, 4904, 5017, 4824, 4690, 4460, 4617, 4821, 4855, 4877]))\n",
      "[[5.23333522e-067 3.18342865e-086 9.99775249e-001 2.00341260e-004\n",
      "  2.44083629e-005 1.12342816e-168 1.04576544e-009 1.85129599e-116\n",
      "  2.05957065e-018 6.61984707e-161]\n",
      " [0.00000000e+000 7.88089831e-238 2.39765657e-254 3.74342727e-185\n",
      "  5.88808431e-298 3.05432536e-018 3.07031935e-188 5.56219308e-005\n",
      "  2.62645206e-113 9.99944378e-001]\n",
      " [1.93475670e-051 2.27826930e-101 1.09327244e-009 5.00129096e-096\n",
      "  1.85110582e-005 6.71671696e-239 9.99981488e-001 5.94230942e-310\n",
      "  1.39547600e-091 8.72760244e-317]\n",
      " [1.00000000e+000 7.26584355e-152 2.51509166e-067 9.85492765e-277\n",
      "  6.42999000e-108 0.00000000e+000 5.58409327e-061 6.77957453e-262\n",
      "  1.32349669e-150 5.30087220e-259]\n",
      " [4.46064153e-132 5.27626586e-147 3.28422249e-142 1.00000000e+000\n",
      "  1.72971120e-140 0.00000000e+000 5.88755637e-131 3.16087513e-299\n",
      "  4.13612843e-217 3.10099209e-300]]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]]\n",
      "0.061567171285219664\n",
      "==== FINISHED =====\n",
      "250\n",
      "PARTIUU\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 10\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "\n",
    "for i in range (150, 251, 50):\n",
    "    maxIter = i\n",
    "    logisticModel3 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "    start = time.clock()\n",
    "    logisticModel3.fit(fashionTrainParams, fashionTrainTarget)\n",
    "    print (time.clock() - start)\n",
    "\n",
    "    print(\"Score : \"+ str(logisticModel3.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "    print(metrics.accuracy_score(logisticModel3.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "    print(metrics.precision_recall_fscore_support(logisticModel3.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "    costFunction2 = regressionLogisticCostFunction(trainTarget, logisticModel3, fashionTrainParams)\n",
    "    print (costFunction2)\n",
    "\n",
    "    xToPlotMultinomial_NCG = np.append(xToPlotMultinomial_NCG,maxIter)\n",
    "    yToPlotMultinomial_NCG = np.append(yToPlotMultinomial_NCG,costFunction2)\n",
    "    print (\"==== FINISHED =====\")\n",
    "    print (i)\n",
    "    print (\"PARTIUU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8cb036fb00>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(xToPlotMultinomial_NCG, yToPlotMultinomial_NCG, 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 3\n",
    "- Multi-class choice: Multinomial\n",
    "- Solver: Newton-CG\n",
    "- Max Iteration: 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10228.087957999998\n",
      "Score : 0.831\n",
      "0.831\n",
      "(array([0.80357143, 0.9548552 , 0.75      , 0.85185185, 0.75864979,\n",
      "       0.90184049, 0.56637168, 0.91584967, 0.90078329, 0.9214876 ]), array([0.78014184, 0.92263374, 0.7569386 , 0.82591725, 0.73447712,\n",
      "       0.90660793, 0.63082437, 0.90330379, 0.91189427, 0.93305439]), array([0.79168333, 0.93846798, 0.75345333, 0.83868411, 0.74636779,\n",
      "       0.90421793, 0.59686308, 0.90953347, 0.90630473, 0.92723493]), array([1269, 1215, 1189, 1281, 1224, 1135, 1116, 1241, 1135, 1195]))\n",
      "0.9124753200224804\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 500\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "logisticModel3 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel3.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel3.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel3.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel3.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction3 = regressionLogisticCostFunction(trainTarget, logisticModel3, fashionTrainParams)\n",
    "print (costFunction3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 4\n",
    "- Multi-class choice: Multinomial\n",
    "- Solver: SAG\n",
    "- Max Iteration: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.864325999998982\n",
      "Score : 0.8505833333333334\n",
      "0.8505833333333334\n",
      "(array([0.81006494, 0.95826235, 0.75333333, 0.88244767, 0.77130802,\n",
      "       0.89921122, 0.59372486, 0.94771242, 0.95300261, 0.95123967]), array([0.81336593, 0.96566524, 0.77463582, 0.83984674, 0.72367379,\n",
      "       0.94388224, 0.64736842, 0.91772152, 0.94315245, 0.94266994]), array([0.81171208, 0.96194955, 0.76383608, 0.86062034, 0.74673203,\n",
      "       0.92100539, 0.61938733, 0.93247588, 0.94805195, 0.94693542]), array([1227, 1165, 1167, 1305, 1263, 1087, 1140, 1264, 1161, 1221]))\n",
      "0.8863134533946874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'sag'\n",
    "maxIter = 10\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "logisticModel4 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel4.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel4.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel4.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel4.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction4 = regressionLogisticCostFunction(trainTarget, logisticModel4, fashionTrainParams)\n",
    "print (costFunction4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 5\n",
    "- Multi-class choice: Multinomial\n",
    "- Solver: SAG\n",
    "- Max Iteration: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.39351199999874\n",
      "Score : 0.8459166666666667\n",
      "0.8459166666666667\n",
      "(array([0.81168831, 0.95741056, 0.7625    , 0.86312399, 0.77299578,\n",
      "       0.89833479, 0.57683025, 0.94281046, 0.9408181 , 0.94793388]), array([0.79617834, 0.9533503 , 0.76441103, 0.85079365, 0.71956009,\n",
      "       0.93266606, 0.65063521, 0.92098962, 0.93431288, 0.9370915 ]), array([0.80385852, 0.95537612, 0.76345432, 0.85691447, 0.7453214 ,\n",
      "       0.91517857, 0.61151386, 0.93177231, 0.93755421, 0.94248151]), array([1256, 1179, 1197, 1260, 1273, 1099, 1102, 1253, 1157, 1224]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'costFunction6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c3bb29b4500d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcostFunction5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressionLogisticCostFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogisticModel5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcostFunction6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'costFunction6' is not defined"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'sag'\n",
    "maxIter = 100\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "logisticModel5 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel5.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel5.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel5.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel5.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction5 = regressionLogisticCostFunction(trainTarget, logisticModel5, fashionTrainParams)\n",
    "print (costFunction6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8968388211767799\n"
     ]
    }
   ],
   "source": [
    "print(costFunction5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 6\n",
    "- Multi-class choice: Multinomial\n",
    "- Solver: SAG\n",
    "- Max Iteration: 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.67084700000123\n",
      "Score : 0.84775\n",
      "0.84775\n",
      "(array([0.81168831, 0.95741056, 0.76      , 0.86876006, 0.77383966,\n",
      "       0.89745837, 0.57924377, 0.94526144, 0.94952132, 0.94958678]), array([0.7980846 , 0.95822677, 0.76190476, 0.85094637, 0.72091195,\n",
      "       0.936871  , 0.65158371, 0.92044551, 0.94132873, 0.93949305]), array([0.80482897, 0.95781849, 0.76095119, 0.85976096, 0.74643875,\n",
      "       0.91674127, 0.6132879 , 0.93268843, 0.94540728, 0.94451295]), array([1253, 1173, 1197, 1268, 1272, 1093, 1105, 1257, 1159, 1223]))\n",
      "0.8940388645172304\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'sag'\n",
    "maxIter = 50\n",
    "multiClass = 'multinomial'\n",
    "\n",
    "logisticModel6 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel6.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel6.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel6.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel6.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction6 = regressionLogisticCostFunction(trainTarget, logisticModel6, fashionTrainParams)\n",
    "print (costFunction6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 7\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: Newton-CG\n",
    "- Max Iteration: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.77993699999934\n",
      "Score : 0.8326666666666667\n",
      "0.8326666666666667\n",
      "(array([0.83198052, 0.95655877, 0.74083333, 0.88244767, 0.77130802,\n",
      "       0.8694128 , 0.45615447, 0.92647059, 0.95387293, 0.9553719 ]), array([0.79334365, 0.96643718, 0.72809173, 0.80410858, 0.66715328,\n",
      "       0.94207028, 0.67741935, 0.8957346 , 0.92333614, 0.92554043]), array([0.81220285, 0.9614726 , 0.73440727, 0.84145873, 0.71545988,\n",
      "       0.90428441, 0.54519231, 0.91084337, 0.93835616, 0.9402196 ]), array([1292, 1162, 1221, 1363, 1370, 1053,  837, 1266, 1187, 1249]))\n",
      "0.8110325407044473\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 10\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel7 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel7.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel7.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel7.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel7.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction7 = regressionLogisticCostFunction(trainTarget, logisticModel7, fashionTrainParams)\n",
    "print (costFunction7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 8\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: Newton-CG\n",
    "- Max Iteration: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4425.843585999999\n",
      "Score : 0.8423333333333334\n",
      "0.8423333333333334\n",
      "(array([0.81331169, 0.95144804, 0.77083333, 0.85748792, 0.76371308,\n",
      "       0.91411043, 0.56556718, 0.92892157, 0.9329852 , 0.94132231]), array([0.78959811, 0.93944491, 0.76006574, 0.82049307, 0.73577236,\n",
      "       0.9173263 , 0.66258247, 0.91619662, 0.93055556, 0.94444444]), array([0.80127949, 0.94540838, 0.76541167, 0.83858268, 0.7494824 ,\n",
      "       0.91571554, 0.61024306, 0.92251521, 0.9317688 , 0.94288079]), array([1269, 1189, 1217, 1298, 1230, 1137, 1061, 1241, 1152, 1206]))\n",
      "0.8752517877395458\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 100\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel8 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel8.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel8.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel8.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel8.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction8 = regressionLogisticCostFunction(trainTarget, logisticModel8, fashionTrainParams)\n",
    "print (costFunction8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 9\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: Newton-CG\n",
    "- Max Iteration: 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353.9010419999977\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ee8cf4ac6a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score : \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogisticModel9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashionValidationSetParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionValidationSetTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogisticModel9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashionValidationSetParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionValidationSetTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogisticModel9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashionValidationSetParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionValidationSetTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coef_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             raise NotFittedError(\"This %(name)s instance is not fitted \"\n\u001b[0;32m--> 298\u001b[0;31m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'newton-cg'\n",
    "maxIter = 50\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel9 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel11.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel9.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel9.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel9.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction9 = regressionLogisticCostFunction(trainTarget, logisticModel9, fashionTrainParams)\n",
    "print (costFunction9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 10\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: SAG\n",
    "- Max Iteration: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.99657700000171\n",
      "Score : 0.84725\n",
      "0.84725\n",
      "(array([0.81168831, 0.95315162, 0.75833333, 0.88566828, 0.79578059,\n",
      "       0.88343558, 0.55189059, 0.94281046, 0.95213229, 0.95289256]), array([0.80906149, 0.96465517, 0.77315208, 0.83523159, 0.70268256,\n",
      "       0.94293732, 0.67920792, 0.90937746, 0.92010093, 0.93663688]), array([0.81037277, 0.95886889, 0.76567101, 0.85971082, 0.74633953,\n",
      "       0.91221719, 0.60896582, 0.92579222, 0.9358426 , 0.9446948 ]), array([1236, 1160, 1177, 1317, 1342, 1069, 1010, 1269, 1189, 1231]))\n",
      "0.8492781420674929\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'sag'\n",
    "maxIter = 10\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel10 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel10.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel10.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel10.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel10.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction10 = regressionLogisticCostFunction(trainTarget, logisticModel10, fashionTrainParams)\n",
    "print (costFunction10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 11\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: SAG\n",
    "- Max Iteration: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igoromote/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334.1710090000015\n",
      "Score : 0.8461666666666666\n",
      "0.8461666666666666\n",
      "(array([0.8125    , 0.95144804, 0.76916667, 0.87439614, 0.77299578,\n",
      "       0.88869413, 0.56154465, 0.94607843, 0.95474326, 0.94545455]), array([0.8079096 , 0.95797599, 0.76280992, 0.83602771, 0.71062839,\n",
      "       0.93715342, 0.67179981, 0.91397001, 0.92184874, 0.93847416]), array([0.8101983 , 0.95470085, 0.7659751 , 0.85478158, 0.74050121,\n",
      "       0.9122807 , 0.61174408, 0.92974709, 0.9380077 , 0.94195142]), array([1239, 1166, 1210, 1299, 1289, 1082, 1039, 1267, 1190, 1219]))\n",
      "0.8589159318000038\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'sag'\n",
    "maxIter = 100\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel11 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel11.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel11.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel11.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel11.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction11 = regressionLogisticCostFunction(trainTarget, logisticModel11, fashionTrainParams)\n",
    "print (costFunction11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 12\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: SAG\n",
    "- Max Iteration: 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalt = 'l2'\n",
    "solverMode = 'sag'\n",
    "maxIter = 50\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel12 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel12.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel12.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel12.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel12.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction12 = regressionLogisticCostFunction(trainTarget, logisticModel12, fashionTrainParams)\n",
    "print (costFunction12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 13\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: Liblinear\n",
    "- Max Iteration: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.138403999997536\n",
      "Score : 0.8474166666666667\n",
      "0.8474166666666667\n",
      "(array([0.8125    , 0.95400341, 0.7675    , 0.87520129, 0.78481013,\n",
      "       0.88869413, 0.55913113, 0.94689542, 0.95474326, 0.94628099]), array([0.80272654, 0.95890411, 0.7675    , 0.83873457, 0.71155318,\n",
      "       0.94413408, 0.67344961, 0.91044776, 0.92652027, 0.9392945 ]), array([0.8075837 , 0.95644748, 0.7675    , 0.85657998, 0.74638844,\n",
      "       0.91557562, 0.61098901, 0.92831398, 0.94042006, 0.9427748 ]), array([1247, 1168, 1200, 1296, 1307, 1074, 1032, 1273, 1184, 1219]))\n",
      "0.8464084053660424\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l1'\n",
    "solverMode = 'liblinear'\n",
    "maxIter = 10\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel13 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel13.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel13.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel13.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel13.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction13 = regressionLogisticCostFunction(trainTarget, logisticModel13, fashionTrainParams)\n",
    "print (costFunction13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 14\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: Liblinear\n",
    "- Max Iteration: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3341.3040580000015\n",
      "Score : 0.8421666666666666\n",
      "0.8421666666666666\n",
      "(array([0.80925325, 0.95229983, 0.76833333, 0.86070853, 0.76455696,\n",
      "       0.91586328, 0.56395817, 0.93055556, 0.93124456, 0.94132231]), array([0.79569034, 0.93478261, 0.7557377 , 0.82167563, 0.72829582,\n",
      "       0.92559787, 0.66319773, 0.91706924, 0.93124456, 0.94210091]), array([0.80241449, 0.94345992, 0.76198347, 0.84073928, 0.745986  ,\n",
      "       0.92070485, 0.60956522, 0.92376318, 0.93124456, 0.94171145]), array([1253, 1196, 1220, 1301, 1244, 1129, 1057, 1242, 1149, 1209]))\n",
      "0.8731074577744629\n"
     ]
    }
   ],
   "source": [
    "penalt = 'l1'\n",
    "solverMode = 'liblinear'\n",
    "maxIter = 100\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel14 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel14.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel14.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel14.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel14.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction14 = regressionLogisticCostFunction(trainTarget, logisticModel14, fashionTrainParams)\n",
    "print (costFunction14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression 15\n",
    "- Multi-class choice: One vs All\n",
    "- Solver: Liblinear\n",
    "- Max Iteration: 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalt = 'l1'\n",
    "solverMode = 'liblinear'\n",
    "maxIter = 50\n",
    "multiClass = 'ovr'\n",
    "\n",
    "logisticModel15 = LogisticRegression(max_iter = maxIter, multi_class = multiClass, solver = solverMode)\n",
    "\n",
    "start = time.clock()\n",
    "logisticModel15.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)\n",
    "\n",
    "print(\"Score : \"+ str(logisticModel15.score(fashionValidationSetParams, fashionValidationSetTarget)))\n",
    "print(metrics.accuracy_score(logisticModel15.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel15.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "\n",
    "costFunction15 = regressionLogisticCostFunction(trainTarget, logisticModel15, fashionTrainParams)\n",
    "print (costFunction15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo e acurcia 1:\n",
      "0.8856784461175559\n",
      "0.8518\n",
      "(array([0.80844156, 0.95741056, 0.76583333, 0.8784219 , 0.77552743,\n",
      "       0.90184049, 0.59292035, 0.94689542, 0.95213229, 0.95289256]), array([0.81639344, 0.96315338, 0.76328904, 0.84639255, 0.72476341,\n",
      "       0.9440367 , 0.65921288, 0.91838352, 0.94391717, 0.9427637 ]), array([0.81239804, 0.96027339, 0.76455907, 0.86210984, 0.74928659,\n",
      "       0.9224563 , 0.62431173, 0.93242156, 0.94800693, 0.94780107]), array([1220, 1167, 1204, 1289, 1268, 1090, 1118, 1262, 1159, 1223]))\n",
      "Custo e acurcia 2:\n",
      "0.9095479120806638\n",
      "0.8323\n",
      "(array([0.79788961, 0.95655877, 0.75166667, 0.84782609, 0.76371308,\n",
      "       0.89833479, 0.5695897 , 0.91666667, 0.91122715, 0.92066116]), array([0.78202068, 0.92276089, 0.75734677, 0.83704293, 0.73160873,\n",
      "       0.90788308, 0.63554758, 0.90048154, 0.90727903, 0.93065998]), array([0.78987545, 0.93935592, 0.75449603, 0.8424    , 0.74731627,\n",
      "       0.9030837 , 0.60076368, 0.90850202, 0.90924881, 0.92563357]), array([1257, 1217, 1191, 1258, 1237, 1129, 1114, 1246, 1154, 1197]))\n",
      "Custo e acurcia 3:\n",
      "0.9120908310807101\n",
      "0.8318\n",
      "(array([0.80357143, 0.9548552 , 0.75      , 0.85185185, 0.75864979,\n",
      "       0.90184049, 0.56637168, 0.91584967, 0.90078329, 0.9214876 ]), array([0.78014184, 0.92263374, 0.7569386 , 0.82591725, 0.73447712,\n",
      "       0.90660793, 0.63082437, 0.90330379, 0.91189427, 0.93305439]), array([0.79168333, 0.93846798, 0.75345333, 0.83868411, 0.74636779,\n",
      "       0.90421793, 0.59686308, 0.90953347, 0.90630473, 0.92723493]), array([1269, 1215, 1189, 1281, 1224, 1135, 1116, 1241, 1135, 1195]))\n",
      "Custo e acurcia 4:\n",
      "0.8862584360808184\n",
      "0.8518\n",
      "(array([0.81006494, 0.95826235, 0.75333333, 0.88244767, 0.77130802,\n",
      "       0.89921122, 0.59372486, 0.94771242, 0.95300261, 0.95123967]), array([0.81336593, 0.96566524, 0.77463582, 0.83984674, 0.72367379,\n",
      "       0.94388224, 0.64736842, 0.91772152, 0.94315245, 0.94266994]), array([0.81171208, 0.96194955, 0.76383608, 0.86062034, 0.74673203,\n",
      "       0.92100539, 0.61938733, 0.93247588, 0.94805195, 0.94693542]), array([1227, 1165, 1167, 1305, 1263, 1087, 1140, 1264, 1161, 1221]))\n",
      "Custo e acurcia 5:\n",
      "0.8968488283413206\n",
      "0.8437\n",
      "(array([0.81168831, 0.95741056, 0.7625    , 0.86312399, 0.77299578,\n",
      "       0.89833479, 0.57683025, 0.94281046, 0.9408181 , 0.94793388]), array([0.79617834, 0.9533503 , 0.76441103, 0.85079365, 0.71956009,\n",
      "       0.93266606, 0.65063521, 0.92098962, 0.93431288, 0.9370915 ]), array([0.80385852, 0.95537612, 0.76345432, 0.85691447, 0.7453214 ,\n",
      "       0.91517857, 0.61151386, 0.93177231, 0.93755421, 0.94248151]), array([1256, 1179, 1197, 1260, 1273, 1099, 1102, 1253, 1157, 1224]))\n",
      "Custo e acurcia 7:\n",
      "0.8121206399509928\n",
      "0.8403\n",
      "(array([0.83198052, 0.95655877, 0.74083333, 0.88244767, 0.77130802,\n",
      "       0.8694128 , 0.45615447, 0.92647059, 0.95387293, 0.9553719 ]), array([0.79334365, 0.96643718, 0.72809173, 0.80410858, 0.66715328,\n",
      "       0.94207028, 0.67741935, 0.8957346 , 0.92333614, 0.92554043]), array([0.81220285, 0.9614726 , 0.73440727, 0.84145873, 0.71545988,\n",
      "       0.90428441, 0.54519231, 0.91084337, 0.93835616, 0.9402196 ]), array([1292, 1162, 1221, 1363, 1370, 1053,  837, 1266, 1187, 1249]))\n",
      "Custo e acurcia 8:\n",
      "0.8708589992752604\n",
      "0.8419\n",
      "(array([0.81331169, 0.95144804, 0.77083333, 0.85748792, 0.76371308,\n",
      "       0.91411043, 0.56556718, 0.92892157, 0.9329852 , 0.94132231]), array([0.78959811, 0.93944491, 0.76006574, 0.82049307, 0.73577236,\n",
      "       0.9173263 , 0.66258247, 0.91619662, 0.93055556, 0.94444444]), array([0.80127949, 0.94540838, 0.76541167, 0.83858268, 0.7494824 ,\n",
      "       0.91571554, 0.61024306, 0.92251521, 0.9317688 , 0.94288079]), array([1269, 1189, 1217, 1298, 1230, 1137, 1061, 1241, 1152, 1206]))\n",
      "Custo e acurcia 10:\n",
      "0.8493361765353084\n",
      "0.851\n",
      "(array([0.81168831, 0.95315162, 0.75833333, 0.88566828, 0.79578059,\n",
      "       0.88343558, 0.55189059, 0.94281046, 0.95213229, 0.95289256]), array([0.80906149, 0.96465517, 0.77315208, 0.83523159, 0.70268256,\n",
      "       0.94293732, 0.67920792, 0.90937746, 0.92010093, 0.93663688]), array([0.81037277, 0.95886889, 0.76567101, 0.85971082, 0.74633953,\n",
      "       0.91221719, 0.60896582, 0.92579222, 0.9358426 , 0.9446948 ]), array([1236, 1160, 1177, 1317, 1342, 1069, 1010, 1269, 1189, 1231]))\n",
      "Custo e acurcia 11:\n",
      "0.8575927407099929\n",
      "0.8482\n",
      "(array([0.8125    , 0.95144804, 0.76916667, 0.87439614, 0.77299578,\n",
      "       0.88869413, 0.56154465, 0.94607843, 0.95474326, 0.94545455]), array([0.8079096 , 0.95797599, 0.76280992, 0.83602771, 0.71062839,\n",
      "       0.93715342, 0.67179981, 0.91397001, 0.92184874, 0.93847416]), array([0.8101983 , 0.95470085, 0.7659751 , 0.85478158, 0.74050121,\n",
      "       0.9122807 , 0.61174408, 0.92974709, 0.9380077 , 0.94195142]), array([1239, 1166, 1210, 1299, 1289, 1082, 1039, 1267, 1190, 1219]))\n",
      "Custo e acurcia 13:\n",
      "0.8462425552578922\n",
      "0.849\n",
      "(array([0.8125    , 0.95400341, 0.7675    , 0.87520129, 0.78481013,\n",
      "       0.88869413, 0.55913113, 0.94689542, 0.95474326, 0.94628099]), array([0.80272654, 0.95890411, 0.7675    , 0.83873457, 0.71155318,\n",
      "       0.94413408, 0.67344961, 0.91044776, 0.92652027, 0.9392945 ]), array([0.8075837 , 0.95644748, 0.7675    , 0.85657998, 0.74638844,\n",
      "       0.91557562, 0.61098901, 0.92831398, 0.94042006, 0.9427748 ]), array([1247, 1168, 1200, 1296, 1307, 1074, 1032, 1273, 1184, 1219]))\n",
      "Custo e acurcia 14:\n",
      "0.8688466224387561\n",
      "0.8425\n",
      "(array([0.80925325, 0.95229983, 0.76833333, 0.86070853, 0.76455696,\n",
      "       0.91586328, 0.56395817, 0.93055556, 0.93124456, 0.94132231]), array([0.79569034, 0.93478261, 0.7557377 , 0.82167563, 0.72829582,\n",
      "       0.92559787, 0.66319773, 0.91706924, 0.93124456, 0.94210091]), array([0.80241449, 0.94345992, 0.76198347, 0.84073928, 0.745986  ,\n",
      "       0.92070485, 0.60956522, 0.92376318, 0.93124456, 0.94171145]), array([1253, 1196, 1220, 1301, 1244, 1129, 1057, 1242, 1149, 1209]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fashionTestParams, fashionTestTarget = formatArray (fashionTestDataset, 0)\n",
    "fashtionTestTargetFormated = createTarget(fashionTestTarget)\n",
    "fashionTestParams = addColumnThetaZero(fashionTestParams)\n",
    "\n",
    "testCostFunction1 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel, fashionTestParams)\n",
    "testCostFunction2 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel2, fashionTestParams)\n",
    "testCostFunction3 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel3, fashionTestParams)\n",
    "testCostFunction4 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel4, fashionTestParams)\n",
    "testCostFunction5 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel5, fashionTestParams)\n",
    "testCostFunction7 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel7, fashionTestParams)\n",
    "testCostFunction8 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel8, fashionTestParams)\n",
    "testCostFunction10 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel10, fashionTestParams)\n",
    "testCostFunction11 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel11, fashionTestParams)\n",
    "testCostFunction13 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel13, fashionTestParams)\n",
    "testCostFunction14 = regressionLogisticCostFunction(fashtionTestTargetFormated, logisticModel14, fashionTestParams)\n",
    "print (\"Custo e acurcia 1:\")\n",
    "print (testCostFunction1)\n",
    "print(metrics.accuracy_score(logisticModel.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 2:\")\n",
    "print (testCostFunction2)\n",
    "print(metrics.accuracy_score(logisticModel2.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel2.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 3:\")\n",
    "print (testCostFunction3)\n",
    "print(metrics.accuracy_score(logisticModel3.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel3.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 4:\")\n",
    "print (testCostFunction4)\n",
    "print(metrics.accuracy_score(logisticModel4.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel4.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 5:\")\n",
    "print (testCostFunction5)\n",
    "print(metrics.accuracy_score(logisticModel5.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel5.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 7:\")\n",
    "print (testCostFunction7)\n",
    "print(metrics.accuracy_score(logisticModel7.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel7.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 8:\")\n",
    "print (testCostFunction8)\n",
    "print(metrics.accuracy_score(logisticModel8.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel8.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 10:\")\n",
    "print (testCostFunction10)\n",
    "print(metrics.accuracy_score(logisticModel10.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel10.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 11:\")\n",
    "print (testCostFunction11)\n",
    "print(metrics.accuracy_score(logisticModel11.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel11.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 13:\")\n",
    "print (testCostFunction13)\n",
    "print(metrics.accuracy_score(logisticModel13.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel13.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print (\"Custo e acurcia 14:\")\n",
    "print (testCostFunction14)\n",
    "print(metrics.accuracy_score(logisticModel14.predict(fashionTestParams), fashionTestTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel14.predict(fashionValidationSetParams), fashionValidationSetTarget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
