{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Here, we'll run through our training data to gather information and try to achieve the best possible model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003269999999999662\n"
     ]
    }
   ],
   "source": [
    "# Functions\n",
    "\n",
    "start = time.clock()\n",
    "def addColumnThetaZero (array):\n",
    "    return np.c_[np.ones(array.shape[0]), array]\n",
    "\n",
    "def formatArray (dataFrame, columnToExtract) :\n",
    "    array = dataFrame.values\n",
    "    target = array[:,columnToExtract]\n",
    "    params = np.delete(array, columnToExtract, axis = 1)\n",
    "    return params, target\n",
    "\n",
    "def loadFashionTrainData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_train.csv\")\n",
    "\n",
    "def loadFashionTestData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_test.csv\")\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "print (time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "fashionTrainDataset = loadFashionTrainData()\n",
    "fashionTestDataset = loadFashionTestData()\n",
    "\n",
    "trainSet, validationSet = split_train_test(fashionTrainDataset, 0.2)\n",
    "\n",
    "fashionTrainParams, fashionTrainTarget = formatArray(trainSet, 0)\n",
    "fashionValidationSetParams, fashionValidationSetTarget = formatArray(validationSet, 0)\n",
    "\n",
    "fashionTrainParams = addColumnThetaZero(fashionTrainParams)\n",
    "fashionValidationSetParams = addColumnThetaZero(fashionValidationSetParams)\n",
    "print (fashionTrainParams[:5])\n",
    "print (type(fashionTrainParams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# C = 1.0\n",
    "# penalt = 'l1'\n",
    "# stopFit = 0.0001\n",
    "# solverMode = 'liblinear'\n",
    "maxIter = 1000\n",
    "multiClass = 'ovr'\n",
    "# talk = True\n",
    "# reuse = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logisticModel = LogisticRegression(C=C, penalty=penalt, tol = stopFit, solver = solverMode, max_iter = maxIter, multi_class = multiClass, verbose = talk, warm_start = reuse)\n",
    "logisticModel = LogisticRegression(max_iter = maxIter, multi_class = multiClass, verbose = talk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "logisticModel.fit(fashionTrainParams, fashionTrainTarget)\n",
    "print (time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.8421666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Score : \"+ str(logisticModel.score(fashionValidationSetParams, fashionValidationSetTarget)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8421666666666666\n",
      "(array([0.80925325, 0.95229983, 0.76833333, 0.86070853, 0.76455696,\n",
      "       0.91586328, 0.56395817, 0.93055556, 0.93124456, 0.94132231]), array([0.79569034, 0.93478261, 0.7557377 , 0.82167563, 0.72829582,\n",
      "       0.92559787, 0.66319773, 0.91706924, 0.93124456, 0.94210091]), array([0.80241449, 0.94345992, 0.76198347, 0.84073928, 0.745986  ,\n",
      "       0.92070485, 0.60956522, 0.92376318, 0.93124456, 0.94171145]), array([1253, 1196, 1220, 1301, 1244, 1129, 1057, 1242, 1149, 1209]))\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(metrics.accuracy_score(logisticModel.predict(fashionValidationSetParams), fashionValidationSetTarget))\n",
    "print(metrics.precision_recall_fscore_support(logisticModel.predict(fashionValidationSetParams), fashionValidationSetTarget))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
