{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Here, we'll explore neural networks applied to the fashion-mnist problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def formatArray (dataFrame, columnToExtract) :\n",
    "    array = dataFrame.values\n",
    "    target = array[:,columnToExtract]\n",
    "    params = np.delete(array, columnToExtract, axis = 1)\n",
    "    return params, target\n",
    "\n",
    "def loadFashionTrainData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_train.csv\")\n",
    "\n",
    "def loadFashionTestData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_test.csv\")\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "First and foremost, we'll open train and test data. The training data is split to obtain validation items and the the target values are also separated from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "fashionTrainDataset = loadFashionTrainData()\n",
    "fashionTestDataset = loadFashionTestData()\n",
    "fashionTrain, fashionValidation = split_train_test(fashionTrainDataset, 0.2)\n",
    "fashionTrain, fashionTarget = formatArray(fashionTrain, 0)\n",
    "\n",
    "print (fashionTrain[:5])\n",
    "print (type(fashionTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation and Softmax Functions\n",
    "First, we'll start by implementing some useful functions seen in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(n):\n",
    "    return (1/(1+exp(-n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(n):\n",
    "    if n < 0:\n",
    "        return 0\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(n):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    return 0.01 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(n):\n",
    "    return np.exp(n)/ np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem details\n",
    "- Input dimension: 28x28 = 784 neurons\n",
    "- Output dimension: 10 classes = 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 1\n",
    "input_neurons = 784\n",
    "hidden_layer_1_neurons = 15\n",
    "hidden_layer_2_neurons = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "In this section, we define forward propagation related functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_1hl(neural_data, hidden_layer_1_neurons, hidden_layer_2_neurons):\n",
    "    neural_data['w1'] = initialize_weight(neural_data['w1'], hidden_layer_1_neurons)\n",
    "    neural_data['w2'] = initialize_weight(neural_data['w2'], hidden_layer_2_neurons)\n",
    "    \n",
    "    neural_data['b1'] = initialize_weight(neural_data['b1'], hidden_layer_1_neurons)\n",
    "    neural_data['b2'] = initialize_weight(neural_data['b2'], hidden_layer_2_neurons)\n",
    "    return model\n",
    "\n",
    "def initialize_2hl(neural_data, hidden_layer_1_neurons, hidden_layer_2_neurons, hidden_layer_3_neurons):\n",
    "\n",
    "    neural_data['w1'] = initialize_weight(neural_data['w1'], hidden_layer_1_neurons)\n",
    "    neural_data['w2'] = initialize_weight(neural_data['w2'], hidden_layer_2_neurons)\n",
    "    neural_data['w3'] = initialize_weight(neural_data['w3'], hidden_layer_3_neurons)\n",
    "\n",
    "    neural_data['b1'] = initialize_weight(neural_data['b1'], hidden_layer_1_neurons)\n",
    "    neural_data['b2'] = initialize_weight(neural_data['b2'], hidden_layer_2_neurons)\n",
    "    neural_data['b3'] = initialize_weight(neural_data['b3'], hidden_layer_3_neurons)\n",
    "    return model\n",
    "    \n",
    "def forward_prop_1hl(x, neural_data):\n",
    "    w1 , w2, b1, b2 = neural_data['w1'], neural_data['w2'], neural_data['b1'], neural_data['b2']\n",
    "    y1 = np.dot(x, w1) + b1\n",
    "    a1 = [relu(n) for n in y1]\n",
    "    y2 = np.dot(a1, w2) + b2\n",
    "    return softmax(y2)\n",
    "\n",
    "def forward_prop_2hl(x, neural_data):\n",
    "    w1 , w2, w3, b1, b2, b3 = neural_data['w1'], neural_data['w2'], neural_data['w3'], neural_data['b1'], neural_data['b2'], neural_data['b3']\n",
    "\n",
    "    y1 = np.dot(x, w1) + b1\n",
    "    a1 = [relu(n) for n in y1]\n",
    "    y2 = np.dot(a1, w2) + b2\n",
    "    a2 = [relu(n) for n in y2]\n",
    "    y3 = np.dot(a2, w3) + b3\n",
    "    return softmax(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Functions\n",
    "Helper functions that return predictions, given our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_1hl(x, neural_data):\n",
    "    return np.argmax(forward_prop_1hl(x,neural_data))\n",
    "\n",
    "def predict_2hl(x, neural_data):\n",
    "    return np.argmax(forward_prop_2hl(x,neural_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(fashionTrainOutput, fashionTarget, fashionTargetMinusOne, testCasesAmount):\n",
    "    final_cost = 0\n",
    "    for j in testCasesAmount:\n",
    "        cost = np.add(np.dot(fashionTarget, np.log10(fashionTrainOutput[j])),np.dot(fashionTargetMinusOne, (np.ones(10) - np.log10(fashionTrainOutput[j]))))\n",
    "    final_cost = np.sum(cost)/testCasesAmount\n",
    "    return final_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionTargetMinusOne = [(1-i) for i in fashionTarget]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
