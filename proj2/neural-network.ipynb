{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Here, we'll explore neural networks applied to the fashion-mnist problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def formatArray (dataFrame, columnToExtract) :\n",
    "    array = dataFrame.values\n",
    "    target = array[:,columnToExtract]\n",
    "    params = np.delete(array, columnToExtract, axis = 1)\n",
    "    return params, target\n",
    "\n",
    "def loadFashionTrainData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_train.csv\")\n",
    "\n",
    "def loadFashionTestData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_test.csv\")\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "def createTarget (target):\n",
    "    results = np.zeros((target.size, 10), dtype=int)\n",
    "    for i in range(10):\n",
    "        for j in range(target.size):\n",
    "            if (target[j] != i):\n",
    "                results[j][i - 1] = 0\n",
    "            else:\n",
    "                results[j][i - 1] = 1\n",
    "    return results\n",
    "\n",
    "def p_print(a):\n",
    "    for x in a:\n",
    "        print(*x, sep=\" \")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "First and foremost, we'll open train and test data. The training data is split to obtain validation items and the the target values are also separated from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionTrainDataset = loadFashionTrainData()\n",
    "fashionTestDataset = loadFashionTestData()\n",
    "fashionTrain, fashionValidation = split_train_test(fashionTrainDataset, 0.2)\n",
    "fashionTrainParams, fashionTrainTarget = formatArray(fashionTrain, 0)\n",
    "fashionTrainTarget = createTarget(fashionTrainTarget)\n",
    "fashionTrainParams = fashionTrainParams/255\n",
    "fashionValidationParams, fashionValidationTarget = formatArray(fashionValidation, 0)\n",
    "fashionValidationTarget = createTarget(fashionValidationTarget)\n",
    "fashionValidationParams = fashionValidationParams/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation and Softmax Functions\n",
    "First, we'll start by implementing some useful functions seen in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(n):\n",
    "    return (1/(1+np.exp(-n)))\n",
    "\n",
    "def derivative_sigmoid(n):\n",
    "    x = sigmoid(n)\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(n):\n",
    "    if n < 0:\n",
    "        return 0\n",
    "    return n\n",
    "\n",
    "def derivative_relu(n):\n",
    "    if n < 0:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(n):\n",
    "    if n > 0:\n",
    "        return n\n",
    "    return 0.01 * n\n",
    "\n",
    "def derivative_leaky_relu(n):\n",
    "    if n < 0:\n",
    "        return 0.01\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(n):\n",
    "    exp = np.exp(n)\n",
    "    test_sum = np.sum(exp, axis=1, keepdims=True)\n",
    "    return exp/test_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "In this section, we define forward propagation related functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_1hl(input_dimension,hidden_layer_1_neurons, output_dimension):\n",
    "    neural_data = {}\n",
    "    np.random.seed()\n",
    "    neural_data['w1'] = np.random.randn(input_dimension, hidden_layer_1_neurons)/ np.sqrt(input_dimension)\n",
    "    neural_data['w2'] = np.random.randn(hidden_layer_1_neurons, output_dimension)/ np.sqrt(input_dimension)\n",
    "    \n",
    "    neural_data['b1'] = np.zeros((1, hidden_layer_1_neurons))\n",
    "    neural_data['b2'] = np.zeros((1, output_dimension))\n",
    "    return neural_data\n",
    "\n",
    "def initialize_2hl(input_dimension, hidden_layer_1_neurons, hidden_layer_2_neurons, output_dimension):\n",
    "    neural_data = {}\n",
    "    np.random.seed(0)\n",
    "\n",
    "    neural_data['w1'] = np.random.randn(input_dimension, hidden_layer_1_neurons)/ np.sqrt(input_dimension)\n",
    "    neural_data['w2'] = np.random.randn(hidden_layer_1_neurons, hidden_layer_2_neurons)/ np.sqrt(hidden_layer_1_neurons)\n",
    "    neural_data['w3'] = np.random.randn(hidden_layer_2_neurons, output_dimension)/ np.sqrt(hidden_layer_2_neurons)\n",
    "\n",
    "    neural_data['b1'] = np.zeros((1, hidden_layer_1_neurons))\n",
    "    neural_data['b2'] = np.zeros((1, hidden_layer_2_neurons))\n",
    "    neural_data['b3'] = np.zeros((1, output_dimension))\n",
    "    return neural_data\n",
    "    \n",
    "def forward_prop_1hl(x, neural_data, activation=\"sigmoid\"):\n",
    "    w1 , w2, b1, b2 = neural_data['w1'], neural_data['w2'], neural_data['b1'], neural_data['b2']\n",
    "    x1 = np.dot(x, w1) + b1 #Output of hidden layer\n",
    "    if activation == \"sigmoid\":\n",
    "        y1 = np.asarray([[sigmoid(n) for n in j] for j in x1]) #Output of hidden layer with activation function\n",
    "    elif activation == \"relu\":\n",
    "        y1 = np.asarray([[relu(n) for n in j] for j in x1]) #Output of hidden layer with activation function\n",
    "    elif activation == \"leaky_relu\":\n",
    "        y1 = np.asarray([[leaky_relu(n) for n in j] for j in x1]) #Output of hidden layer with activation function\n",
    "    x2 = np.dot(y1, w2) + b2 #Output of last layer\n",
    "    neural_data['x1'] = x1\n",
    "    neural_data['x2'] = x2\n",
    "    neural_data['y1'] = y1\n",
    "    neural_data['o'] = softmax(x2)  # Final output with softmax\n",
    "\n",
    "    return neural_data['o']\n",
    "\n",
    "def forward_prop_2hl(x, neural_data):\n",
    "    w1 , w2, w3, b1, b2, b3 = neural_data['w1'], neural_data['w2'], neural_data['w3'], neural_data['b1'], neural_data['b2'], neural_data['b3']\n",
    "\n",
    "    x1 = np.dot(x, w1) + b1\n",
    "    y1 = np.asarray([[relu(n) for n in j] for j in x1])\n",
    "    x2 = np.dot(a1, w2) + b2\n",
    "    y2 = np.asarray([[relu(n) for n in j] for j in x2])\n",
    "    x3 = np.dot(a2, w3) + b3\n",
    "    \n",
    "    neural_data['x1'] = x1\n",
    "    neural_data['x2'] = x2\n",
    "    neural_data['x3'] = x3\n",
    "\n",
    "    neural_data['y1'] = y1\n",
    "    neural_data['y2'] = y2\n",
    "    \n",
    "    neural_data['o'] = softmax(x3)\n",
    "    return neural_data['o']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Functions\n",
    "Helper functions that return predictions, given our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_1hl(x, neural_data):\n",
    "    test = forward_prop_1hl(x,neural_data)\n",
    "    return np.argmax(test, axis=1)\n",
    "\n",
    "def predict_2hl(x, neural_data):\n",
    "    return np.argmax(forward_prop_2hl(x,neural_data), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetworkCostFunction(output, target):\n",
    "#     fashionTargetMinusOne = fashionTarget - 1\n",
    "#     cost = 0\n",
    "#     for j in range(fashionTrainOutput.shape[0]):\n",
    "#         cost += np.sum(np.multiply(fashionTarget, np.log10(fashionTrainOutput[j])),np.multiply(fashionTargetMinusOne, (1- np.log10(fashionTrainOutput[j]))))\n",
    "#     cost = cost*(-1)/fashionTrainOutput.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     partial_cost = -np.log(probs[range(fashionTrainOutput.shape[0]), fashionTarget])\n",
    "#     partial_cost -= np.log(1-probs[range(fashionTrainOutput.shape[0]), fashionTarget])\n",
    "#     cost = np.sum(partial_cost)\n",
    "    \n",
    "    cost = log_loss(target, output)\n",
    "    return cost\n",
    "\n",
    "def meanSquaresCost(fashionTrainOutput, fashionTarget):\n",
    "    diference = fashionTrainOutput - fashionTarget\n",
    "    squareDiference = diference ** 2\n",
    "    n = fashionTrainOutput.shape[0]    \n",
    "    return (np.sum(squareDiference)/(2*n))\n",
    "\n",
    "def accuracy (target, params, neural_model, hidden_layers=1):\n",
    "    right_answers = 0\n",
    "    target_indexes = np.argmax(target, axis=1)\n",
    "    if hidden_layers == 1:\n",
    "        predicted = predict_1hl(params, neural_model)\n",
    "    if hidden_layers == 2:\n",
    "        predicted = predict_2hl(params, neural_model)\n",
    "    n = params.shape[0]\n",
    "    for i in range (n):\n",
    "        if (target_indexes[i] == predicted[i]):\n",
    "            right_answers = right_answers + 1\n",
    "    return right_answers/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and backward propagation\n",
    "\n",
    "Some notes:\n",
    "\n",
    "### For one hidden layer:\n",
    "- x1 = #Output of hidden layer\n",
    "- x2 = #Output of last layer\n",
    "- y1 = #Output of hidden layer with activation function\n",
    "- o = Final output with Softmax\n",
    "\n",
    "### For TWO hidden layers:\n",
    "- x1 = #Output of first hidden layer\n",
    "- x2 = #Output of second hidden layer\n",
    "- x3 = Output of last layer\n",
    "- y1 = #Output of first hidden layer with activation function\n",
    "- y2 = #Output of second hidden layer with activation function\n",
    "- o = Final output with Softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hidden layer\n",
    "\n",
    "Here, we present our code and results achieved by a learning algorithm that uses a neural network with only one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network_1hl(hidden_layer_1_neurons, epochs, trainParams, trainTarget, learning_rate, regularization_rate, activation=\"sigmoid\"):\n",
    "    print(\"Beginning training with \", epochs, \" epochs and \", hidden_layer_1_neurons, \" hidden neurons.\")\n",
    "    input_dimension = 784\n",
    "    output_dimension = 10\n",
    "#     Initializes weights and biases for our neural network\n",
    "    neural_data = initialize_1hl(input_dimension, hidden_layer_1_neurons, output_dimension)\n",
    "    print(\"Initialized weights\")\n",
    "    sigmoid = True\n",
    "    relu = False\n",
    "    leaky_relu = False\n",
    "    \n",
    "#     Prepares for mini-batch\n",
    "    batchSize = 600\n",
    "    start_idx = 0\n",
    "    indices = np.arange(trainParams.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    print(\"Prepared for mini-batch.\")\n",
    "#     Performs Backpropagation\n",
    "    capitalDelta3 = 0\n",
    "    capitalDelta2 = 0\n",
    "    for j in range(epochs):\n",
    "        excerpt = indices[start_idx:start_idx + batchSize]\n",
    "        mini_batch_data = trainParams[excerpt]\n",
    "        miniBatchTarget = trainTarget[excerpt]\n",
    "#         Performs Forward propagation\n",
    "        probs = forward_prop_1hl(mini_batch_data, neural_data, activation)\n",
    "    \n",
    "\n",
    "#         Performs Backward propagation\n",
    "\n",
    "        delta3 = probs - miniBatchTarget\n",
    "\n",
    "        dW2 =(1./batchSize)* (neural_data['y1'].T).dot(delta3)\n",
    "        db2 =(1./batchSize)* ( np.sum(delta3, axis=0, keepdims=True))\n",
    "        delta2 = np.dot(delta3, neural_data['w2'].T)\n",
    "        aux = neural_data['y1']\n",
    "        if activation == \"sigmoid\":\n",
    "            aux = [[derivative_sigmoid(n) for n in x] for x in aux]\n",
    "        if activation == \"relu\":\n",
    "            aux = [[derivative_relu(n) for n in x] for x in aux]\n",
    "        if activation == \"leaky_relu\":\n",
    "            aux = [[derivative_leaky_relu(n) for n in x] for x in aux]\n",
    "\n",
    "        delta2 = delta2 * aux\n",
    "\n",
    "        dW1 = (1./batchSize)*np.dot(mini_batch_data.T, delta2)\n",
    "        db1 = (1./batchSize)*np.sum(delta2, axis=0)\n",
    "        \n",
    "        \n",
    "#          # Performs regularization\n",
    "#         dW2 += regularization_rate * neural_data['w2']\n",
    "#         dW1 += regularization_rate * neural_data['w1']\n",
    "\n",
    "        # Gradient descent parameter update\n",
    "        neural_data['w1'] -= learning_rate * dW1\n",
    "        neural_data['b1'] -= learning_rate * db1\n",
    "        neural_data['w2'] -= learning_rate * dW2\n",
    "        neural_data['b2'] -= learning_rate * db2\n",
    "        \n",
    "        if j%50 == 0:\n",
    "            #         Calculates costs\n",
    "\n",
    "            cost = neuralNetworkCostFunction(probs, miniBatchTarget)\n",
    "            validation_probs = forward_prop_1hl(fashionValidationParams, neural_data)\n",
    "            validation_cost = neuralNetworkCostFunction(validation_probs, fashionValidationTarget)\n",
    "            print(\"Ended iteration\", j,\" Cost: \", cost, \" Validation cost: \", validation_cost)\n",
    "        start_idx += batchSize;\n",
    "        start_idx %= mini_batch_data.shape[0]\n",
    "    return neural_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two hidden layers\n",
    "\n",
    "Same as before, but for 2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, trainParams, trainTarget, learning_rate, regularization_rate):\n",
    "    input_dimension = 784\n",
    "    output_dimension = 10\n",
    "#     Initializes weights and biases for our neural network\n",
    "    neural_data = initialize_2hl(input_dimension, hidden_layer_1_neurons, hidden_layer_2_neurons, output_dimension)\n",
    "    sigmoid = True\n",
    "    relu = False\n",
    "    leaky_relu = False\n",
    "    \n",
    "#     Prepares for mini-batch\n",
    "    batchSize = 64\n",
    "    start_idx = 0;\n",
    "    indices = np.arange(trainParams.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    excerpt = indices[start_idx:start_idx + batchSize]\n",
    "    mini_batch_data = trainParams[excerpt]\n",
    "    miniBatchTarget = createTarget(trainTarget[excerpt])\n",
    "#     Performs Backpropagation\n",
    "    for j in range(epochs):\n",
    "\n",
    "#         Performs Forward propagation\n",
    "        probs = forward_prop_1hl(mini_batch_data, neural_data)\n",
    "        \n",
    "#         Calculates cost\n",
    "\n",
    "#         Performs Backward propagation\n",
    "        delta4 = probs - miniBatchTarget\n",
    "        dW3 = (neural_data['y2'].T).dot(delta4)\n",
    "        db3 = np.sum(delta4, axis=0, keepdims=True)\n",
    "        delta3 = delta4.dot(neural_data['w3'].T)\n",
    "        aux = neural_data['y2']\n",
    "        if sigmoid:\n",
    "            aux = [[derivative_sigmoid(n) for n in x] for x in aux]\n",
    "        if relu:\n",
    "            aux = [[derivative_relu(n) for n in x] for x in aux]\n",
    "        if leaky_relu:\n",
    "            aux = [[derivative_leaky_relu(n) for n in x] for x in aux]        \n",
    "        delta3 = delta3 * aux\n",
    "        dW2 = np.dot(mini_batch_data.T, delta3)\n",
    "        db2 = np.sum(delta3, axis=0)\n",
    "        delta2 = delta3.dot(neural_data['w2'].T)  #look for issues here\n",
    "        aux = neural_data['y1']\n",
    "        if sigmoid:\n",
    "            aux = [[derivative_sigmoid(n) for n in x] for x in aux]\n",
    "        if relu:\n",
    "            aux = [[derivative_relu(n) for n in x] for x in aux]\n",
    "        if leaky_relu:\n",
    "            aux = [[derivative_leaky_relu(n) for n in x] for x in aux]\n",
    "        delta2 = delta2 * aux\n",
    "        dW1 = np.dot(mini_batch_data.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)      \n",
    "        \n",
    "#          # Performs regularization\n",
    "#         dW3 += regularization_rate * neural_data['w3']\n",
    "#         dW2 += regularization_rate * neural_data['w2']\n",
    "#         dW1 += regularization_rate * neural_data['w1']\n",
    "\n",
    "        # Gradient descent parameter update\n",
    "        \n",
    "        neural_data['w1'] += -learning_rate * dW1\n",
    "        neural_data['b1'] += -learning_rate * db1\n",
    "        neural_data['w2'] += -learning_rate * dW2\n",
    "        neural_data['b2'] += -learning_rate * db2\n",
    "        neural_data['w3'] += -learning_rate * dW3\n",
    "        neural_data['b3'] += -learning_rate * db3\n",
    "        \n",
    "        print(\"Ended iteration\", j)\n",
    "        start_idx += 1;\n",
    "        start_idx %= mini_batch_data.shape[0]\n",
    "        \n",
    "    return neural_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the neural networks\n",
    "\n",
    "Now, we'll test our neural networks under multiple circumstances on the validation set, so we can gest the best possible models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem details\n",
    "- Input dimension: 28x28 = 784 neurons\n",
    "- Output dimension: 10 classes = 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 1\n",
    "input_neurons = 784\n",
    "output_neurons = 10\n",
    "hidden_layer_1_neurons = 50\n",
    "hidden_layer_2_neurons = 15\n",
    "learning_rate = 0.1\n",
    "regularization_rate = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our evaluation\n",
    "Here, we define the function which will use the training we implemented before. It will train 3 models (using the same parameters), to test to an extent the impact of random initialization on the weights matrix. After the training, we check the costs and accuracies of each model (both related to train an validation sets), as well as the average of such values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation=\"sigmoid\"):\n",
    "    model_1hl_1 = train_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================First model trained=====================\")\n",
    "    model_1hl_2 = train_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================Second model trained=====================\")\n",
    "    model_1hl_3 = train_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================Third model trained=====================\")\n",
    "    probs_sigmoid1 = forward_prop_1hl(fashionValidationParams, model_1hl_1)\n",
    "    cost1 = neuralNetworkCostFunction(probs_sigmoid1, fashionValidationTarget)\n",
    "    acc1_train = accuracy(fashionTrainTarget, fashionTrainParams, model_1hl_1)\n",
    "    acc1_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_1hl_1)\n",
    "    print(\"First model \", activation, \"validation cost: \", cost1, \" acc_train: {0:.4f} \".format(acc1_train), \" acc_validation: {0:.4f} \".format(acc1_validation))\n",
    "    \n",
    "    probs_sigmoid2 = forward_prop_1hl(fashionValidationParams, model_1hl_2)\n",
    "    cost2 = neuralNetworkCostFunction(probs_sigmoid2, fashionValidationTarget)\n",
    "    acc2_train = accuracy(fashionTrainTarget, fashionTrainParams, model_1hl_2)\n",
    "    acc2_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_1hl_2)\n",
    "    print(\"Second model  \", activation, \"validation cost: \", cost2, \" acc_train:{0:.4f} \".format(acc2_train), \" acc_validation: {0:.4f} \".format(acc2_validation))\n",
    "    \n",
    "    probs_sigmoid3 = forward_prop_1hl(fashionValidationParams, model_1hl_3)\n",
    "    cost3 = neuralNetworkCostFunction(probs_sigmoid3, fashionValidationTarget)\n",
    "    acc3_train = accuracy(fashionTrainTarget, fashionTrainParams, model_1hl_3)\n",
    "    acc3_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_1hl_3)\n",
    "    print(\"Third model \", activation, \"validation cost: \", cost3, \" acc_train:{0:.4f} \".format(acc3_train), \" acc_validation: {0:.4f} \".format(acc3_validation))\n",
    "    \n",
    "    \n",
    "    avg_loss = ((cost1+cost2+cost3)/3)\n",
    "    avg_acc = ((acc1_validation + acc2_validation + acc3_validation)/3)\n",
    "    print(\"Average validation loss: \", avg_loss, \" Average validation accuracy: \", avg_acc)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First experiments\n",
    "First, we will train a model using a hidden layer with 50 neurons and 1000 epochs, which is small given the input of 784 neurons. We will run 3 times for each activation function to get an average result (that depends heavily on the initialization of the weights)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since everything seems ok, we'll increase the number of epochs to 1000, but mantaining the current amount of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  1000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3189274990773403  Validation cost:  2.308840114216827\n",
      "Ended iteration 50  Cost:  2.171037962825242  Validation cost:  2.1837254937446287\n",
      "Ended iteration 100  Cost:  1.8645495813242572  Validation cost:  1.8758884833012268\n",
      "Ended iteration 150  Cost:  1.5806684164274916  Validation cost:  1.5945600691037713\n",
      "Ended iteration 200  Cost:  1.4097875070160208  Validation cost:  1.4268218913522153\n",
      "Ended iteration 250  Cost:  1.2933453573268108  Validation cost:  1.3141021084284596\n",
      "Ended iteration 300  Cost:  1.2042783284529452  Validation cost:  1.2286972348102279\n",
      "Ended iteration 350  Cost:  1.1331665686497145  Validation cost:  1.16157526942327\n",
      "Ended iteration 400  Cost:  1.0773114436869984  Validation cost:  1.1101187761208735\n",
      "Ended iteration 450  Cost:  1.0349248356206233  Validation cost:  1.0723990045324765\n",
      "Ended iteration 500  Cost:  1.003889567761496  Validation cost:  1.0461792243275032\n",
      "Ended iteration 550  Cost:  0.9828096096174345  Validation cost:  1.0297007767623403\n",
      "Ended iteration 600  Cost:  0.9698053064846545  Validation cost:  1.0206495491495502\n",
      "Ended iteration 650  Cost:  0.962532561519184  Validation cost:  1.016339355864724\n",
      "Ended iteration 700  Cost:  0.9592764372493169  Validation cost:  1.0147819927286499\n",
      "Ended iteration 750  Cost:  0.9588078040496714  Validation cost:  1.0145100877877085\n",
      "Ended iteration 800  Cost:  0.9595034678964595  Validation cost:  1.014439345838066\n",
      "Ended iteration 850  Cost:  0.9601211143214111  Validation cost:  1.0152473373353215\n",
      "Ended iteration 900  Cost:  0.9615993876903315  Validation cost:  1.0177173995186495\n",
      "Ended iteration 950  Cost:  0.9645337271894463  Validation cost:  1.0220849239628549\n",
      "======================First model trained=====================\n",
      "Beginning training with  1000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.308209701641873  Validation cost:  2.303586747922412\n",
      "Ended iteration 50  Cost:  2.173073153591573  Validation cost:  2.1720104826168627\n",
      "Ended iteration 100  Cost:  1.8588339148511963  Validation cost:  1.8509872540593713\n",
      "Ended iteration 150  Cost:  1.5825334295189222  Validation cost:  1.5702267009668773\n",
      "Ended iteration 200  Cost:  1.4129576485797453  Validation cost:  1.3956239831997945\n",
      "Ended iteration 250  Cost:  1.2993031199598826  Validation cost:  1.2787752242650758\n",
      "Ended iteration 300  Cost:  1.216291577595487  Validation cost:  1.1948472278331994\n",
      "Ended iteration 350  Cost:  1.1527325532246735  Validation cost:  1.1322602969420765\n",
      "Ended iteration 400  Cost:  1.1024476936436665  Validation cost:  1.083700240080024\n",
      "Ended iteration 450  Cost:  1.0617252343542385  Validation cost:  1.0447507214822378\n",
      "Ended iteration 500  Cost:  1.0286691773068064  Validation cost:  1.013450365048525\n",
      "Ended iteration 550  Cost:  1.0021395641819841  Validation cost:  0.9888182378563024\n",
      "Ended iteration 600  Cost:  0.9816456055900179  Validation cost:  0.9704475068465535\n",
      "Ended iteration 650  Cost:  0.9671752335320343  Validation cost:  0.9582416944189753\n",
      "Ended iteration 700  Cost:  0.9581465239146011  Validation cost:  0.9514536987804479\n",
      "Ended iteration 750  Cost:  0.9531538415598387  Validation cost:  0.9485970512994532\n",
      "Ended iteration 800  Cost:  0.9509500322594105  Validation cost:  0.9483819332905259\n",
      "Ended iteration 850  Cost:  0.9511005302803007  Validation cost:  0.9503458579028617\n",
      "Ended iteration 900  Cost:  0.953611170093606  Validation cost:  0.9544043682865015\n",
      "Ended iteration 950  Cost:  0.9579424713977437  Validation cost:  0.9599449474635673\n",
      "======================Second model trained=====================\n",
      "Beginning training with  1000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.312808641665652  Validation cost:  2.3109665846219394\n",
      "Ended iteration 50  Cost:  2.1654329395186696  Validation cost:  2.179612064686262\n",
      "Ended iteration 100  Cost:  1.8623656994701276  Validation cost:  1.878515612652526\n",
      "Ended iteration 150  Cost:  1.5833488687119048  Validation cost:  1.6008744937385937\n",
      "Ended iteration 200  Cost:  1.3982822553560548  Validation cost:  1.418798222951767\n",
      "Ended iteration 250  Cost:  1.2830563928524832  Validation cost:  1.3070696529931167\n",
      "Ended iteration 300  Cost:  1.2061829042262608  Validation cost:  1.2333640529203054\n",
      "Ended iteration 350  Cost:  1.149202299150249  Validation cost:  1.1791228626729546\n",
      "Ended iteration 400  Cost:  1.1051499206208506  Validation cost:  1.1373198692467286\n",
      "Ended iteration 450  Cost:  1.0704302770140173  Validation cost:  1.1044669147264634\n",
      "Ended iteration 500  Cost:  1.041869589843578  Validation cost:  1.0776166673043175\n",
      "Ended iteration 550  Cost:  1.0173869116384031  Validation cost:  1.054878807328941\n",
      "Ended iteration 600  Cost:  0.9964056813039376  Validation cost:  1.0356734627725332\n",
      "Ended iteration 650  Cost:  0.9788573951297163  Validation cost:  1.0196573368148878\n",
      "Ended iteration 700  Cost:  0.9638039406955007  Validation cost:  1.0059674853247786\n",
      "Ended iteration 750  Cost:  0.949720968865455  Validation cost:  0.9935465274532376\n",
      "Ended iteration 800  Cost:  0.9357214335811341  Validation cost:  0.9818805946262992\n",
      "Ended iteration 850  Cost:  0.9219851018999664  Validation cost:  0.9712575761963851\n",
      "Ended iteration 900  Cost:  0.9092463988189017  Validation cost:  0.9621618688948439\n",
      "Ended iteration 950  Cost:  0.8979995220161684  Validation cost:  0.9547054740077304\n",
      "======================Third model trained=====================\n",
      "First model  sigmoid validation cost:  1.0285726867261866  acc_train: 0.6573   acc_validation: 0.6550 \n",
      "Second model   sigmoid validation cost:  0.9656501904975048  acc_train:0.6638   acc_validation: 0.6612 \n",
      "Third model  sigmoid validation cost:  0.9487465800324559  acc_train:0.6707   acc_validation: 0.6631 \n",
      "Average validation loss:  0.9809898190853824  Average validation accuracy:  0.65975\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for 2000 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.309584803483088  Validation cost:  2.3053486210577807\n",
      "Ended iteration 50  Cost:  2.1564941498806403  Validation cost:  2.1731646967738363\n",
      "Ended iteration 100  Cost:  1.8517262061793849  Validation cost:  1.8712662016631196\n",
      "Ended iteration 150  Cost:  1.5783252719919543  Validation cost:  1.5980975480741204\n",
      "Ended iteration 200  Cost:  1.4099436035618367  Validation cost:  1.4265489245819734\n",
      "Ended iteration 250  Cost:  1.289168316098962  Validation cost:  1.3051478744728737\n",
      "Ended iteration 300  Cost:  1.190502690231248  Validation cost:  1.210246899999425\n",
      "Ended iteration 350  Cost:  1.1110033949449278  Validation cost:  1.1368538902004954\n",
      "Ended iteration 400  Cost:  1.0515953815990229  Validation cost:  1.0834034904084433\n",
      "Ended iteration 450  Cost:  1.0084389890352876  Validation cost:  1.0454901542699924\n",
      "Ended iteration 500  Cost:  0.9764130244304439  Validation cost:  1.0179483344099165\n",
      "Ended iteration 550  Cost:  0.9529195453820277  Validation cost:  0.9977143010100111\n",
      "Ended iteration 600  Cost:  0.9363515556906316  Validation cost:  0.9833098520615883\n",
      "Ended iteration 650  Cost:  0.9251194111399165  Validation cost:  0.9737944206757035\n",
      "Ended iteration 700  Cost:  0.918025604933094  Validation cost:  0.9683923829959307\n",
      "Ended iteration 750  Cost:  0.9139458149629902  Validation cost:  0.9661797669528714\n",
      "Ended iteration 800  Cost:  0.9116499269823044  Validation cost:  0.9661133832629418\n",
      "Ended iteration 850  Cost:  0.9099239545097649  Validation cost:  0.9671742377784056\n",
      "Ended iteration 900  Cost:  0.9076906363577025  Validation cost:  0.9684015562109483\n",
      "Ended iteration 950  Cost:  0.9042896635652731  Validation cost:  0.9693242985148693\n",
      "Ended iteration 1000  Cost:  0.9003224280893944  Validation cost:  0.9703609388967274\n",
      "Ended iteration 1050  Cost:  0.8979844403639387  Validation cost:  0.9724550698590996\n",
      "Ended iteration 1100  Cost:  0.8987814638566645  Validation cost:  0.9756765676488576\n",
      "Ended iteration 1150  Cost:  0.9013967231903871  Validation cost:  0.9788065266479788\n",
      "Ended iteration 1200  Cost:  0.9038217796716056  Validation cost:  0.9805301182531433\n",
      "Ended iteration 1250  Cost:  0.9048928699045969  Validation cost:  0.9798864612186025\n",
      "Ended iteration 1300  Cost:  0.9035285386281395  Validation cost:  0.9765078759140513\n",
      "Ended iteration 1350  Cost:  0.8985186695738326  Validation cost:  0.9705304037708387\n",
      "Ended iteration 1400  Cost:  0.8900732454208323  Validation cost:  0.9625244915968504\n",
      "Ended iteration 1450  Cost:  0.8798444682848365  Validation cost:  0.9534364826567512\n",
      "Ended iteration 1500  Cost:  0.8700340847475565  Validation cost:  0.9443477620517824\n",
      "Ended iteration 1550  Cost:  0.8621218115225632  Validation cost:  0.9362009412179658\n",
      "Ended iteration 1600  Cost:  0.855540389005826  Validation cost:  0.9298470790681522\n",
      "Ended iteration 1650  Cost:  0.8496846578447325  Validation cost:  0.925757851251725\n",
      "Ended iteration 1700  Cost:  0.8444448574676325  Validation cost:  0.923713811702031\n",
      "Ended iteration 1750  Cost:  0.8406428335751758  Validation cost:  0.9232822600782389\n",
      "Ended iteration 1800  Cost:  0.8387487451261216  Validation cost:  0.924034720662994\n",
      "Ended iteration 1850  Cost:  0.8386015669563331  Validation cost:  0.9257867225566792\n",
      "Ended iteration 1900  Cost:  0.8400485333667337  Validation cost:  0.9285803512488223\n",
      "Ended iteration 1950  Cost:  0.8422806665622792  Validation cost:  0.9322152667838066\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.308898700914159  Validation cost:  2.3038171698671284\n",
      "Ended iteration 50  Cost:  2.1533172421176556  Validation cost:  2.1602742737254528\n",
      "Ended iteration 100  Cost:  1.801880675174319  Validation cost:  1.8122006019803272\n",
      "Ended iteration 150  Cost:  1.5346005894441574  Validation cost:  1.5464099950475865\n",
      "Ended iteration 200  Cost:  1.3800033290180682  Validation cost:  1.391769221059025\n",
      "Ended iteration 250  Cost:  1.275841497136302  Validation cost:  1.2882678242336019\n",
      "Ended iteration 300  Cost:  1.1996465884455272  Validation cost:  1.213726534342821\n",
      "Ended iteration 350  Cost:  1.1431268101655079  Validation cost:  1.1598255417812409\n",
      "Ended iteration 400  Cost:  1.1012159387685672  Validation cost:  1.1208370011818185\n",
      "Ended iteration 450  Cost:  1.0698633546031668  Validation cost:  1.0919242622627405\n",
      "Ended iteration 500  Cost:  1.0466226070538294  Validation cost:  1.0703406607800943\n",
      "Ended iteration 550  Cost:  1.029901437931711  Validation cost:  1.0545626169210283\n",
      "Ended iteration 600  Cost:  1.0175700715389193  Validation cost:  1.0426523460134376\n",
      "Ended iteration 650  Cost:  1.0077454340843315  Validation cost:  1.0328901086200175\n",
      "Ended iteration 700  Cost:  0.9994234366006007  Validation cost:  1.024448107942235\n",
      "Ended iteration 750  Cost:  0.9919733665107746  Validation cost:  1.016924780300159\n",
      "Ended iteration 800  Cost:  0.9850207494597163  Validation cost:  1.009971646511968\n",
      "Ended iteration 850  Cost:  0.9779087569100233  Validation cost:  1.0028754513742815\n",
      "Ended iteration 900  Cost:  0.9694818328576296  Validation cost:  0.9945428110991394\n",
      "Ended iteration 950  Cost:  0.9586235109559372  Validation cost:  0.9840095211198897\n",
      "Ended iteration 1000  Cost:  0.9455860145342437  Validation cost:  0.9714588950600964\n",
      "Ended iteration 1050  Cost:  0.9337210875702863  Validation cost:  0.9596986854875692\n",
      "Ended iteration 1100  Cost:  0.926005026388815  Validation cost:  0.9515985359238827\n",
      "Ended iteration 1150  Cost:  0.9214102719234883  Validation cost:  0.9465070678502454\n",
      "Ended iteration 1200  Cost:  0.9177859177193282  Validation cost:  0.9424545453248308\n",
      "Ended iteration 1250  Cost:  0.9136851670936378  Validation cost:  0.9384172529301767\n",
      "Ended iteration 1300  Cost:  0.9087498991374187  Validation cost:  0.9342522476524047\n",
      "Ended iteration 1350  Cost:  0.9030395770165232  Validation cost:  0.93007041342936\n",
      "Ended iteration 1400  Cost:  0.8965786458781264  Validation cost:  0.9260440844372512\n",
      "Ended iteration 1450  Cost:  0.8896791046583318  Validation cost:  0.922361378395392\n",
      "Ended iteration 1500  Cost:  0.8830734283604624  Validation cost:  0.9191222929296466\n",
      "Ended iteration 1550  Cost:  0.8770343102607895  Validation cost:  0.916415467102607\n",
      "Ended iteration 1600  Cost:  0.8715967334465169  Validation cost:  0.9141901359605845\n",
      "Ended iteration 1650  Cost:  0.8670642496442365  Validation cost:  0.9123895345116692\n",
      "Ended iteration 1700  Cost:  0.8633621743591343  Validation cost:  0.9109848764976267\n",
      "Ended iteration 1750  Cost:  0.8602599670349993  Validation cost:  0.909804459706733\n",
      "Ended iteration 1800  Cost:  0.8575507688269571  Validation cost:  0.9085196921719838\n",
      "Ended iteration 1850  Cost:  0.8548601769316554  Validation cost:  0.9067353684438232\n",
      "Ended iteration 1900  Cost:  0.8514951015339197  Validation cost:  0.9042777682273043\n",
      "Ended iteration 1950  Cost:  0.8469764366620797  Validation cost:  0.9013360091871411\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3075288635681064  Validation cost:  2.308160905496335\n",
      "Ended iteration 50  Cost:  2.123145568932113  Validation cost:  2.1477017298040253\n",
      "Ended iteration 100  Cost:  1.7855803862434747  Validation cost:  1.8230903822119537\n",
      "Ended iteration 150  Cost:  1.513668323919067  Validation cost:  1.5600083906453768\n",
      "Ended iteration 200  Cost:  1.3467019245101453  Validation cost:  1.3993119063857276\n",
      "Ended iteration 250  Cost:  1.2330211994102527  Validation cost:  1.2919916447830744\n",
      "Ended iteration 300  Cost:  1.1492195416099042  Validation cost:  1.2140632709505834\n",
      "Ended iteration 350  Cost:  1.0866156438379766  Validation cost:  1.1563726208682774\n",
      "Ended iteration 400  Cost:  1.0415579855089223  Validation cost:  1.1153518178692434\n",
      "Ended iteration 450  Cost:  1.0107907953408652  Validation cost:  1.0880855032174228\n",
      "Ended iteration 500  Cost:  0.9902292245365731  Validation cost:  1.0707659567132917\n",
      "Ended iteration 550  Cost:  0.9755439175505267  Validation cost:  1.0589002235659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 600  Cost:  0.963479722465216  Validation cost:  1.04860675376449\n",
      "Ended iteration 650  Cost:  0.9522941504067068  Validation cost:  1.0380138911191579\n",
      "Ended iteration 700  Cost:  0.9417452730100038  Validation cost:  1.0276939998175203\n",
      "Ended iteration 750  Cost:  0.9330948128908453  Validation cost:  1.0193251169222695\n",
      "Ended iteration 800  Cost:  0.9263927527873125  Validation cost:  1.0129030581571532\n",
      "Ended iteration 850  Cost:  0.9208004949146568  Validation cost:  1.0074923076629423\n",
      "Ended iteration 900  Cost:  0.9160770407094939  Validation cost:  1.0027822347719297\n",
      "Ended iteration 950  Cost:  0.9123219217235048  Validation cost:  0.999009417463767\n",
      "Ended iteration 1000  Cost:  0.9095474923731378  Validation cost:  0.9964851227517391\n",
      "Ended iteration 1050  Cost:  0.9074910001637647  Validation cost:  0.9951597154204993\n",
      "Ended iteration 1100  Cost:  0.9056020781955374  Validation cost:  0.994461693276095\n",
      "Ended iteration 1150  Cost:  0.9030818108945793  Validation cost:  0.9936492687228251\n",
      "Ended iteration 1200  Cost:  0.8997152576986404  Validation cost:  0.9923564833928223\n",
      "Ended iteration 1250  Cost:  0.8961302406114392  Validation cost:  0.9907033126862659\n",
      "Ended iteration 1300  Cost:  0.8931021321713623  Validation cost:  0.9891196101388452\n",
      "Ended iteration 1350  Cost:  0.8910553065737633  Validation cost:  0.9882464056173749\n",
      "Ended iteration 1400  Cost:  0.889968581729514  Validation cost:  0.9883939333415386\n",
      "Ended iteration 1450  Cost:  0.8890447566660066  Validation cost:  0.9891291890372507\n",
      "Ended iteration 1500  Cost:  0.887686453512454  Validation cost:  0.9897242031005495\n",
      "Ended iteration 1550  Cost:  0.8855624955224145  Validation cost:  0.9896916954538265\n",
      "Ended iteration 1600  Cost:  0.8823263406623625  Validation cost:  0.9890436144542415\n",
      "Ended iteration 1650  Cost:  0.877541648360294  Validation cost:  0.9878563155357312\n",
      "Ended iteration 1700  Cost:  0.871129271520846  Validation cost:  0.9865305699702304\n",
      "Ended iteration 1750  Cost:  0.8641907652943527  Validation cost:  0.9856101162992821\n",
      "Ended iteration 1800  Cost:  0.8572593962565549  Validation cost:  0.9848235308485297\n",
      "Ended iteration 1850  Cost:  0.8494335600363274  Validation cost:  0.9831851598490734\n",
      "Ended iteration 1900  Cost:  0.8413421636177636  Validation cost:  0.980108372431456\n",
      "Ended iteration 1950  Cost:  0.8341989577202471  Validation cost:  0.975544182649\n",
      "======================Third model trained=====================\n",
      "First model  sigmoid validation cost:  0.9359071624726623  acc_train: 0.6321   acc_validation: 0.6286 \n",
      "Second model   sigmoid validation cost:  0.8983447765077189  acc_train:0.6485   acc_validation: 0.6502 \n",
      "Third model  sigmoid validation cost:  0.9698482209197378  acc_train:0.6458   acc_validation: 0.6511 \n",
      "Average validation loss:  0.9347000533000397  Average validation accuracy:  0.6432777777777777\n"
     ]
    }
   ],
   "source": [
    "epochs=2000\n",
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these trainings, we see that we achieve best performance generally around 1500 epochs. Now we'll test with other activation functions.\n",
    "\n",
    "## Relu.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  1500  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3164666632507918  Validation cost:  2.310441018496367\n",
      "Ended iteration 50  Cost:  1.192824575839597  Validation cost:  1.8104917507244445\n",
      "Ended iteration 100  Cost:  0.8314183993936627  Validation cost:  1.6243965565701601\n",
      "Ended iteration 150  Cost:  0.6845210967789782  Validation cost:  1.5555502310877352\n",
      "Ended iteration 200  Cost:  0.5860866183761796  Validation cost:  1.515126787072321\n",
      "Ended iteration 250  Cost:  0.5125848460900257  Validation cost:  1.482372410330805\n",
      "Ended iteration 300  Cost:  0.4554583950718295  Validation cost:  1.453276918008165\n",
      "Ended iteration 350  Cost:  0.408742077923518  Validation cost:  1.42777488816148\n",
      "Ended iteration 400  Cost:  0.39400495390197515  Validation cost:  1.3824527567363778\n",
      "Ended iteration 450  Cost:  0.3538569726985296  Validation cost:  1.350752855588127\n",
      "Ended iteration 500  Cost:  0.3180160542618654  Validation cost:  1.3280849297402255\n",
      "Ended iteration 550  Cost:  0.29071894928908043  Validation cost:  1.2833024564089524\n",
      "Ended iteration 600  Cost:  0.27856357890429995  Validation cost:  1.2690077706742224\n",
      "Ended iteration 650  Cost:  0.2609613461680573  Validation cost:  1.2524885807310655\n",
      "Ended iteration 700  Cost:  0.24257123838413833  Validation cost:  1.2244275701239442\n",
      "Ended iteration 750  Cost:  0.2158613765824391  Validation cost:  1.190527938668348\n",
      "Ended iteration 800  Cost:  0.20195505840915337  Validation cost:  1.1672687567181457\n",
      "Ended iteration 850  Cost:  0.19056746104368388  Validation cost:  1.1493644734579085\n",
      "Ended iteration 900  Cost:  0.18216852388621646  Validation cost:  1.1337743506289362\n",
      "Ended iteration 950  Cost:  0.1725810368286876  Validation cost:  1.1196919648389656\n",
      "Ended iteration 1000  Cost:  0.15652749531496274  Validation cost:  1.106921778476631\n",
      "Ended iteration 1050  Cost:  0.13721097558411013  Validation cost:  1.0995979927914454\n",
      "Ended iteration 1100  Cost:  0.14486655706989568  Validation cost:  1.101909560936762\n",
      "Ended iteration 1150  Cost:  0.139567752452121  Validation cost:  1.0750191003500749\n",
      "Ended iteration 1200  Cost:  0.15011287069714177  Validation cost:  1.090004378420949\n",
      "Ended iteration 1250  Cost:  0.126177656163345  Validation cost:  1.0744592727765103\n",
      "Ended iteration 1300  Cost:  0.10126979078073911  Validation cost:  1.0620250286525605\n",
      "Ended iteration 1350  Cost:  0.09691144558457708  Validation cost:  1.0574854338688973\n",
      "Ended iteration 1400  Cost:  0.09008083295117633  Validation cost:  1.0518185327668466\n",
      "Ended iteration 1450  Cost:  0.08279983273869389  Validation cost:  1.0468703429527448\n",
      "======================First model trained=====================\n",
      "Beginning training with  1500  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.2994195883848585  Validation cost:  2.2990013028902845\n",
      "Ended iteration 50  Cost:  1.1104975178253897  Validation cost:  1.78318948776497\n",
      "Ended iteration 100  Cost:  0.7978332694368016  Validation cost:  1.5639009210387254\n",
      "Ended iteration 150  Cost:  0.6731113996971818  Validation cost:  1.477726014305891\n",
      "Ended iteration 200  Cost:  0.5816041496837944  Validation cost:  1.4264960885067623\n",
      "Ended iteration 250  Cost:  0.5057304279912342  Validation cost:  1.389309406513466\n",
      "Ended iteration 300  Cost:  0.4409585831207287  Validation cost:  1.3592725808967412\n",
      "Ended iteration 350  Cost:  0.38424387242066776  Validation cost:  1.3329833620888558\n",
      "Ended iteration 400  Cost:  0.35964382010075574  Validation cost:  1.2922043291537586\n",
      "Ended iteration 450  Cost:  0.31545438858796054  Validation cost:  1.2589057404612152\n",
      "Ended iteration 500  Cost:  0.2781628095869407  Validation cost:  1.2279088295353637\n",
      "Ended iteration 550  Cost:  0.24627789414244147  Validation cost:  1.2003317434949354\n",
      "Ended iteration 600  Cost:  0.2189619036007239  Validation cost:  1.1755513438439043\n",
      "Ended iteration 650  Cost:  0.20113605581674424  Validation cost:  1.1443818480879375\n",
      "Ended iteration 700  Cost:  0.1881890722294403  Validation cost:  1.1259596175548785\n",
      "Ended iteration 750  Cost:  0.16526503271695933  Validation cost:  1.106862952578042\n",
      "Ended iteration 800  Cost:  0.15036462994508426  Validation cost:  1.08503523195675\n",
      "Ended iteration 850  Cost:  0.1275391776391907  Validation cost:  1.0729698136729375\n",
      "Ended iteration 900  Cost:  0.11358458030617176  Validation cost:  1.0616733836704557\n",
      "Ended iteration 950  Cost:  0.0992775226825231  Validation cost:  1.0452098265487701\n",
      "Ended iteration 1000  Cost:  0.08711220707673654  Validation cost:  1.0378062976841442\n",
      "Ended iteration 1050  Cost:  0.07886461624103835  Validation cost:  1.0300991701662376\n",
      "Ended iteration 1100  Cost:  0.07174325352311757  Validation cost:  1.0230842294804245\n",
      "Ended iteration 1150  Cost:  0.06550560715486942  Validation cost:  1.0167780337365562\n",
      "Ended iteration 1200  Cost:  0.06002183144197147  Validation cost:  1.0110971237342974\n",
      "Ended iteration 1250  Cost:  0.05518101835436537  Validation cost:  1.0059551569653296\n",
      "Ended iteration 1300  Cost:  0.05089600523552362  Validation cost:  1.0012810019349743\n",
      "Ended iteration 1350  Cost:  0.047083237329638254  Validation cost:  0.9970164803384032\n",
      "Ended iteration 1400  Cost:  0.043679006059349955  Validation cost:  0.9931088824268915\n",
      "Ended iteration 1450  Cost:  0.04063502105445181  Validation cost:  0.9895155279751359\n",
      "======================Second model trained=====================\n",
      "Beginning training with  1500  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.309383917993285  Validation cost:  2.304491243789836\n",
      "Ended iteration 50  Cost:  1.1863009917023741  Validation cost:  1.8115428080319007\n",
      "Ended iteration 100  Cost:  0.8741593656631624  Validation cost:  1.6437652323779106\n",
      "Ended iteration 150  Cost:  0.7107292409231841  Validation cost:  1.5856397643111935\n",
      "Ended iteration 200  Cost:  0.5896661443690991  Validation cost:  1.559909770573777\n",
      "Ended iteration 250  Cost:  0.5000937160406678  Validation cost:  1.541574094991354\n",
      "Ended iteration 300  Cost:  0.4315608232769703  Validation cost:  1.5260237383317763\n",
      "Ended iteration 350  Cost:  0.4448117517201657  Validation cost:  1.4870963973842812\n",
      "Ended iteration 400  Cost:  0.3506884833881669  Validation cost:  1.4495682072935372\n",
      "Ended iteration 450  Cost:  0.31321171443900947  Validation cost:  1.4223385218693316\n",
      "Ended iteration 500  Cost:  0.27928902286476853  Validation cost:  1.3987337317354056\n",
      "Ended iteration 550  Cost:  0.2500592424581336  Validation cost:  1.3764292448725015\n",
      "Ended iteration 600  Cost:  0.22878086680527465  Validation cost:  1.3516887337481769\n",
      "Ended iteration 650  Cost:  0.20688212113814358  Validation cost:  1.3278524169890351\n",
      "Ended iteration 700  Cost:  0.187929299716094  Validation cost:  1.308511229754899\n",
      "Ended iteration 750  Cost:  0.18355925716184543  Validation cost:  1.2961116244826483\n",
      "Ended iteration 800  Cost:  0.1580417513225839  Validation cost:  1.2861304579753023\n",
      "Ended iteration 850  Cost:  0.14450036034751926  Validation cost:  1.2718037588148174\n",
      "Ended iteration 900  Cost:  0.13092700146976766  Validation cost:  1.2587966787726743\n",
      "Ended iteration 950  Cost:  0.11786068469567826  Validation cost:  1.2473138618437822\n",
      "Ended iteration 1000  Cost:  0.10534584800066793  Validation cost:  1.2359705361100477\n",
      "Ended iteration 1050  Cost:  0.10181781632353891  Validation cost:  1.187515928982655\n",
      "Ended iteration 1100  Cost:  0.10724167975742513  Validation cost:  1.1744608994810317\n",
      "Ended iteration 1150  Cost:  0.07842946985738986  Validation cost:  1.1801475505510999\n",
      "Ended iteration 1200  Cost:  0.07040890350839694  Validation cost:  1.1804926208693405\n",
      "Ended iteration 1250  Cost:  0.06405828269370036  Validation cost:  1.180143253720788\n",
      "Ended iteration 1300  Cost:  0.05860609688178343  Validation cost:  1.1799536926187397\n",
      "Ended iteration 1350  Cost:  0.053851107091677314  Validation cost:  1.179333049170521\n",
      "Ended iteration 1400  Cost:  0.04964737822434713  Validation cost:  1.1786288058769898\n",
      "Ended iteration 1450  Cost:  0.045918989486370555  Validation cost:  1.1780632868354521\n",
      "======================Third model trained=====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First model  relu validation cost:  1.0318463453792883  acc_train: 0.6719   acc_validation: 0.6644 \n",
      "Second model   relu validation cost:  0.9862588391588282  acc_train:0.7053   acc_validation: 0.7005 \n",
      "Third model  relu validation cost:  1.1776426395270934  acc_train:0.5824   acc_validation: 0.5805 \n",
      "Average validation loss:  1.0652492746884032  Average validation accuracy:  0.6484722222222222\n"
     ]
    }
   ],
   "source": [
    "epochs = 1500\n",
    "activation = \"relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky-relu.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.302849938656908  Validation cost:  2.3105654144774914\n",
      "Ended iteration 50  Cost:  1.1070574951364116  Validation cost:  2.01886601262095\n",
      "Ended iteration 100  Cost:  0.7581413648313114  Validation cost:  1.9395130288641822\n",
      "Ended iteration 150  Cost:  0.6476219339071607  Validation cost:  1.8893976713865486\n",
      "Ended iteration 200  Cost:  0.540676911591149  Validation cost:  1.8701075154785436\n",
      "Ended iteration 250  Cost:  0.44555981541257667  Validation cost:  1.8564365609984277\n",
      "Ended iteration 300  Cost:  0.3878401627297766  Validation cost:  1.8342690908634722\n",
      "Ended iteration 350  Cost:  0.3358157162023498  Validation cost:  1.8140881000201092\n",
      "Ended iteration 400  Cost:  0.28948118827006947  Validation cost:  1.7940775202525074\n",
      "Ended iteration 450  Cost:  0.2541457454134992  Validation cost:  1.784445262402187\n",
      "Ended iteration 500  Cost:  0.22815904051620284  Validation cost:  1.766573699166547\n",
      "Ended iteration 550  Cost:  0.20711017988278257  Validation cost:  1.7636228652826849\n",
      "Ended iteration 600  Cost:  0.18872565542141362  Validation cost:  1.7457416666131698\n",
      "Ended iteration 650  Cost:  0.16166693631742915  Validation cost:  1.7441481451046927\n",
      "Ended iteration 700  Cost:  0.13280723799690786  Validation cost:  1.7372093812607303\n",
      "Ended iteration 750  Cost:  0.11843374383814255  Validation cost:  1.7296606361685665\n",
      "Ended iteration 800  Cost:  0.1520626157723274  Validation cost:  1.7293809662396988\n",
      "Ended iteration 850  Cost:  0.08775970998479787  Validation cost:  1.7325659342403226\n",
      "Ended iteration 900  Cost:  0.08178463973089407  Validation cost:  1.7362416280165962\n",
      "Ended iteration 950  Cost:  0.07474500001659884  Validation cost:  1.6879996784690425\n",
      "Ended iteration 1000  Cost:  0.06447252477045538  Validation cost:  1.7161449481763078\n",
      "Ended iteration 1050  Cost:  0.058074480813280246  Validation cost:  1.7201676160682788\n",
      "Ended iteration 1100  Cost:  0.05262803709116173  Validation cost:  1.721606823748815\n",
      "Ended iteration 1150  Cost:  0.047910719872562305  Validation cost:  1.7216019117152577\n",
      "Ended iteration 1200  Cost:  0.04381417700060119  Validation cost:  1.7223241437365013\n",
      "Ended iteration 1250  Cost:  0.04024392241421235  Validation cost:  1.7231132083595713\n",
      "Ended iteration 1300  Cost:  0.037105352918356066  Validation cost:  1.7240194513800307\n",
      "Ended iteration 1350  Cost:  0.03433906110035912  Validation cost:  1.725131720279935\n",
      "Ended iteration 1400  Cost:  0.031881896196668556  Validation cost:  1.7264250237781664\n",
      "Ended iteration 1450  Cost:  0.029703472972825593  Validation cost:  1.7280131033116959\n",
      "Ended iteration 1500  Cost:  0.027756014006664078  Validation cost:  1.7292679478696764\n",
      "Ended iteration 1550  Cost:  0.02600830084827689  Validation cost:  1.730681954663386\n",
      "Ended iteration 1600  Cost:  0.024435808148740114  Validation cost:  1.731902413194046\n",
      "Ended iteration 1650  Cost:  0.023013746829644795  Validation cost:  1.7331779982292403\n",
      "Ended iteration 1700  Cost:  0.021724711597029784  Validation cost:  1.734464614175197\n",
      "Ended iteration 1750  Cost:  0.020551430626829546  Validation cost:  1.7359350902214343\n",
      "Ended iteration 1800  Cost:  0.019481091398585205  Validation cost:  1.7371497907538886\n",
      "Ended iteration 1850  Cost:  0.018501626579621202  Validation cost:  1.7383524338651133\n",
      "Ended iteration 1900  Cost:  0.01760236415139768  Validation cost:  1.7396606798442056\n",
      "Ended iteration 1950  Cost:  0.01677623561798026  Validation cost:  1.7407607401431167\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3095637548784858  Validation cost:  2.300882958697063\n",
      "Ended iteration 50  Cost:  0.9978796588288382  Validation cost:  1.9463370723473823\n",
      "Ended iteration 100  Cost:  0.733865356881182  Validation cost:  1.8699819262994533\n",
      "Ended iteration 150  Cost:  0.6504823473627038  Validation cost:  1.8197588180647477\n",
      "Ended iteration 200  Cost:  0.5618703500088539  Validation cost:  1.8006722551890004\n",
      "Ended iteration 250  Cost:  0.49144937381329196  Validation cost:  1.7890187629437957\n",
      "Ended iteration 300  Cost:  0.43260456899407757  Validation cost:  1.782222643948745\n",
      "Ended iteration 350  Cost:  0.38134278457008075  Validation cost:  1.7787021365369016\n",
      "Ended iteration 400  Cost:  0.34473089313491667  Validation cost:  1.7715983795486479\n",
      "Ended iteration 450  Cost:  0.3096048244220274  Validation cost:  1.7607318308737498\n",
      "Ended iteration 500  Cost:  0.28289274715168333  Validation cost:  1.7551387786965547\n",
      "Ended iteration 550  Cost:  0.25816745134934604  Validation cost:  1.7478289748414475\n",
      "Ended iteration 600  Cost:  0.23935552671211877  Validation cost:  1.7542453643479996\n",
      "Ended iteration 650  Cost:  0.2060355680732231  Validation cost:  1.747051020160335\n",
      "Ended iteration 700  Cost:  0.20000989227597454  Validation cost:  1.7516195914007495\n",
      "Ended iteration 750  Cost:  0.20531905366588213  Validation cost:  1.7208641428944795\n",
      "Ended iteration 800  Cost:  0.1630244152129356  Validation cost:  1.7165193669085341\n",
      "Ended iteration 850  Cost:  0.14672206430571233  Validation cost:  1.71991501950382\n",
      "Ended iteration 900  Cost:  0.132432283995463  Validation cost:  1.7200212677178768\n",
      "Ended iteration 950  Cost:  0.13389263349661054  Validation cost:  1.7279847355158158\n",
      "Ended iteration 1000  Cost:  0.09095462354839831  Validation cost:  1.7144363198970738\n",
      "Ended iteration 1050  Cost:  0.13448983000039044  Validation cost:  1.7303136560547057\n",
      "Ended iteration 1100  Cost:  0.07383563955560078  Validation cost:  1.721721867095981\n",
      "Ended iteration 1150  Cost:  0.06649033609453103  Validation cost:  1.7261450922694632\n",
      "Ended iteration 1200  Cost:  0.06038276501594233  Validation cost:  1.7289924975133892\n",
      "Ended iteration 1250  Cost:  0.05474342245431811  Validation cost:  1.7317038064556498\n",
      "Ended iteration 1300  Cost:  0.049848008291784124  Validation cost:  1.7347826353723945\n",
      "Ended iteration 1350  Cost:  0.04562020209792163  Validation cost:  1.737680875805789\n",
      "Ended iteration 1400  Cost:  0.041928259304891045  Validation cost:  1.7400837896765127\n",
      "Ended iteration 1450  Cost:  0.038692931114554345  Validation cost:  1.7420635415235768\n",
      "Ended iteration 1500  Cost:  0.03583263423741277  Validation cost:  1.7438352710291682\n",
      "Ended iteration 1550  Cost:  0.03329247754599532  Validation cost:  1.7453770889149232\n",
      "Ended iteration 1600  Cost:  0.031025684173680852  Validation cost:  1.7469124709617911\n",
      "Ended iteration 1650  Cost:  0.02901105505771893  Validation cost:  1.7486079708246074\n",
      "Ended iteration 1700  Cost:  0.02719441143336262  Validation cost:  1.750675394419673\n",
      "Ended iteration 1750  Cost:  0.02556184842037502  Validation cost:  1.752445397786895\n",
      "Ended iteration 1800  Cost:  0.024084349327219482  Validation cost:  1.7544029456837438\n",
      "Ended iteration 1850  Cost:  0.02274635551300733  Validation cost:  1.7562404848167752\n",
      "Ended iteration 1900  Cost:  0.02152575781152667  Validation cost:  1.7581564351958983\n",
      "Ended iteration 1950  Cost:  0.02041379317056302  Validation cost:  1.7598657496081567\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.291262472712508  Validation cost:  2.3113372135529686\n",
      "Ended iteration 50  Cost:  1.0336697627227387  Validation cost:  2.0261684623125245\n",
      "Ended iteration 100  Cost:  0.7774866466459304  Validation cost:  1.911710622737708\n",
      "Ended iteration 150  Cost:  0.6303827494377707  Validation cost:  1.8533952127671467\n",
      "Ended iteration 200  Cost:  0.5378952700870565  Validation cost:  1.828386582974579\n",
      "Ended iteration 250  Cost:  0.46375315952008617  Validation cost:  1.8177770195506364\n",
      "Ended iteration 300  Cost:  0.4023856754957902  Validation cost:  1.8130318437172033\n",
      "Ended iteration 350  Cost:  0.3505062604649903  Validation cost:  1.8126548083245155\n",
      "Ended iteration 400  Cost:  0.30510883438886044  Validation cost:  1.8140800013308962\n",
      "Ended iteration 450  Cost:  0.2649589055464702  Validation cost:  1.8179316648041595\n",
      "Ended iteration 500  Cost:  0.2308716597556778  Validation cost:  1.825892683044074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 550  Cost:  0.2093029258962358  Validation cost:  1.8546940257167583\n",
      "Ended iteration 600  Cost:  0.17423445345901142  Validation cost:  1.8470965484529684\n",
      "Ended iteration 650  Cost:  0.15434463024690387  Validation cost:  1.8587937357873874\n",
      "Ended iteration 700  Cost:  0.13672680853957211  Validation cost:  1.8627474393242591\n",
      "Ended iteration 750  Cost:  0.120293890925472  Validation cost:  1.8647950738438892\n",
      "Ended iteration 800  Cost:  0.10459350140890224  Validation cost:  1.8650641559913508\n",
      "Ended iteration 850  Cost:  0.09087174195103441  Validation cost:  1.8663997094308604\n",
      "Ended iteration 900  Cost:  0.07899083887561886  Validation cost:  1.8686638342812463\n",
      "Ended iteration 950  Cost:  0.06995370157897664  Validation cost:  1.8738920463455728\n",
      "Ended iteration 1000  Cost:  0.06285652497457526  Validation cost:  1.877260104046379\n",
      "Ended iteration 1050  Cost:  0.05680201408836956  Validation cost:  1.8793766454951626\n",
      "Ended iteration 1100  Cost:  0.051596156296783234  Validation cost:  1.8819777889835525\n",
      "Ended iteration 1150  Cost:  0.047089087873054124  Validation cost:  1.8844496750933688\n",
      "Ended iteration 1200  Cost:  0.043153275906647644  Validation cost:  1.8859303005095487\n",
      "Ended iteration 1250  Cost:  0.03972249094774807  Validation cost:  1.8877737160415153\n",
      "Ended iteration 1300  Cost:  0.03669634968407869  Validation cost:  1.8891196609794065\n",
      "Ended iteration 1350  Cost:  0.03402334505831174  Validation cost:  1.8910046047073268\n",
      "Ended iteration 1400  Cost:  0.031646639723538206  Validation cost:  1.8923288093029247\n",
      "Ended iteration 1450  Cost:  0.029525172155216696  Validation cost:  1.8935971730599568\n",
      "Ended iteration 1500  Cost:  0.02762438790715623  Validation cost:  1.894871034431333\n",
      "Ended iteration 1550  Cost:  0.025916872799653226  Validation cost:  1.8956343238970512\n",
      "Ended iteration 1600  Cost:  0.02438330542510378  Validation cost:  1.896590302166498\n",
      "Ended iteration 1650  Cost:  0.022985892922918947  Validation cost:  1.897945245669832\n",
      "Ended iteration 1700  Cost:  0.02171914570014841  Validation cost:  1.899384464207554\n",
      "Ended iteration 1750  Cost:  0.020564162922921316  Validation cost:  1.9005656265993558\n",
      "Ended iteration 1800  Cost:  0.019509186309655497  Validation cost:  1.9018299823565024\n",
      "Ended iteration 1850  Cost:  0.01854125032429175  Validation cost:  1.9024162347333429\n",
      "Ended iteration 1900  Cost:  0.017656617722068304  Validation cost:  1.9034091181718225\n",
      "Ended iteration 1950  Cost:  0.016838028826460575  Validation cost:  1.9046049772852494\n",
      "======================Third model trained=====================\n",
      "First model  leaky_relu validation cost:  1.741718151045658  acc_train: 0.2649   acc_validation: 0.2599 \n",
      "Second model   leaky_relu validation cost:  1.7615741650600831  acc_train:0.3660   acc_validation: 0.3661 \n",
      "Third model  leaky_relu validation cost:  1.9059653342277234  acc_train:0.3448   acc_validation: 0.3432 \n",
      "Average validation loss:  1.8030858834444883  Average validation accuracy:  0.32308333333333333\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "activation = \"leaky_relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing hidden layer size\n",
    "Now we will experiment changing the amount of neurons on the hidden layer and see the impact on different activation functions. We will fix the amount of epochs to 1000, which generates an average-to-good result for all activation functions. Besides that, we'll use a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1_neurons = 100\n",
    "epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky Relu.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"leaky_relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding to 500 neurons on the hidden layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1_neurons = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid.500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu.500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky Relu.500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"leaky_relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
