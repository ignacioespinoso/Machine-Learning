{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Running\n",
    "Add files fashion-mnist_train.csv and fashion-mnist_test.csv to the fashion-mnist-dataset folder.\n",
    "\n",
    "# Introduction\n",
    "Here, we'll explore neural networks applied to the fashion-mnist problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def formatArray (dataFrame, columnToExtract) :\n",
    "    array = dataFrame.values\n",
    "    target = array[:,columnToExtract]\n",
    "    params = np.delete(array, columnToExtract, axis = 1)\n",
    "    return params, target\n",
    "\n",
    "def loadFashionTrainData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_train.csv\")\n",
    "\n",
    "def loadFashionTestData():\n",
    "    return pd.read_csv(\"fashion-mnist-dataset/fashion-mnist_test.csv\")\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "def createTarget (target):\n",
    "    results = np.zeros((target.size, 10), dtype=int)\n",
    "    for i in range(10):\n",
    "        for j in range(target.size):\n",
    "            if (target[j] != i):\n",
    "                results[j][i - 1] = 0\n",
    "            else:\n",
    "                results[j][i - 1] = 1\n",
    "    return results\n",
    "\n",
    "def p_print(a):\n",
    "    for x in a:\n",
    "        print(*x, sep=\"   \")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "First and foremost, we'll open train and test data. The training data is split to obtain validation items and the the target values are also separated from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionTrainDataset = loadFashionTrainData()\n",
    "fashionTestDataset = loadFashionTestData()\n",
    "fashionTrain, fashionValidation = split_train_test(fashionTrainDataset, 0.2)\n",
    "fashionTrainParams, fashionTrainTarget = formatArray(fashionTrain, 0)\n",
    "fashionTrainTarget = createTarget(fashionTrainTarget)\n",
    "fashionTrainParams = fashionTrainParams/255\n",
    "fashionValidationParams, fashionValidationTarget = formatArray(fashionValidation, 0)\n",
    "fashionValidationTarget = createTarget(fashionValidationTarget)\n",
    "fashionValidationParams = fashionValidationParams/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation and Softmax Functions\n",
    "First, we'll start by implementing some useful functions seen in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(n):\n",
    "    return (1/(1+np.exp(-n)))\n",
    "\n",
    "def derivative_sigmoid(n):\n",
    "    x = sigmoid(n)\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(n):\n",
    "    if n < 0:\n",
    "        return 0\n",
    "    return n\n",
    "\n",
    "def derivative_relu(n):\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(n):\n",
    "    if n > 0:\n",
    "        return n\n",
    "    return 0.01 * n\n",
    "\n",
    "def derivative_leaky_relu(n):\n",
    "    if n <= 0:\n",
    "        return 0.01\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(n):\n",
    "    exp = np.exp(n)\n",
    "    test_sum = np.sum(exp, axis=1, keepdims=True)\n",
    "    return exp/test_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "In this section, we define forward propagation related functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_1hl(input_dimension,hidden_layer_1_neurons, output_dimension):\n",
    "    neural_data = {}\n",
    "    np.random.seed()\n",
    "    neural_data['w1'] = np.random.randn(input_dimension, hidden_layer_1_neurons)/ np.sqrt(input_dimension)\n",
    "    neural_data['w2'] = np.random.randn(hidden_layer_1_neurons, output_dimension)/ np.sqrt(input_dimension)\n",
    "    \n",
    "    neural_data['b1'] = np.zeros((1, hidden_layer_1_neurons))\n",
    "    neural_data['b2'] = np.zeros((1, output_dimension))\n",
    "    return neural_data\n",
    "\n",
    "def initialize_2hl(input_dimension, hidden_layer_1_neurons, hidden_layer_2_neurons, output_dimension):\n",
    "    neural_data = {}\n",
    "    np.random.seed()\n",
    "\n",
    "    neural_data['w1'] = np.random.randn(input_dimension, hidden_layer_1_neurons)/ np.sqrt(input_dimension)\n",
    "    neural_data['w2'] = np.random.randn(hidden_layer_1_neurons, hidden_layer_2_neurons)/ np.sqrt(hidden_layer_1_neurons)\n",
    "    neural_data['w3'] = np.random.randn(hidden_layer_2_neurons, output_dimension)/ np.sqrt(hidden_layer_2_neurons)\n",
    "    \n",
    "    neural_data['b1'] = np.zeros((1, hidden_layer_1_neurons))\n",
    "    neural_data['b2'] = np.zeros((1, hidden_layer_2_neurons))\n",
    "    neural_data['b3'] = np.zeros((1, output_dimension))\n",
    "    return neural_data\n",
    "    \n",
    "def forward_prop_1hl(x, neural_data, activation=\"sigmoid\"):\n",
    "    w1 , w2, b1, b2 = neural_data['w1'], neural_data['w2'], neural_data['b1'], neural_data['b2']\n",
    "    x1 = np.dot(x, w1) + b1 #Output of hidden layer\n",
    "    if activation == \"sigmoid\":\n",
    "        y1 = np.asarray([[sigmoid(n) for n in j] for j in x1]) #Output of hidden layer with activation function\n",
    "    elif activation == \"relu\":\n",
    "        y1 = np.asarray([[relu(n) for n in j] for j in x1]) #Output of hidden layer with activation function\n",
    "    elif activation == \"leaky_relu\":\n",
    "        y1 = np.asarray([[leaky_relu(n) for n in j] for j in x1]) #Output of hidden layer with activation function\n",
    "    x2 = np.dot(y1, w2) + b2 #Output of last layer\n",
    "    neural_data['x1'] = x1\n",
    "    neural_data['x2'] = x2\n",
    "    neural_data['y1'] = y1\n",
    "    neural_data['o'] = softmax(x2)  # Final output with softmax\n",
    "\n",
    "    return neural_data['o']\n",
    "\n",
    "def forward_prop_2hl(x, neural_data, activation=\"sigmoid\"):\n",
    "    w1 , w2, w3, b1, b2, b3 = neural_data['w1'], neural_data['w2'], neural_data['w3'], neural_data['b1'], neural_data['b2'], neural_data['b3']\n",
    "\n",
    "    x1 = np.dot(x, w1) + b1\n",
    "    if activation == \"sigmoid\":\n",
    "        y1 = np.asarray([[sigmoid(n) for n in j] for j in x1]) #Output of hidden layer with activation function\n",
    "    elif activation == \"relu\":\n",
    "        y1 = np.asarray([[relu(n) for n in j] for j in x1]) #Output of hidden layer with activation function\n",
    "    elif activation == \"leaky_relu\":\n",
    "        y1 = np.asarray([[leaky_relu(n) for n in j] for j in x1])\n",
    "        \n",
    "    \n",
    "    x2 = np.dot(y1, w2) + b2\n",
    "    if activation==\"sigmoid\":\n",
    "        y2 = np.asarray([[sigmoid(n) for n in j] for j in x2])\n",
    "    elif activation==\"relu\":\n",
    "        y2 = np.asarray([[relu(n) for n in j] for j in x2])\n",
    "    elif activation==\"leaky_relu\":\n",
    "        y2 = np.asarray([[leaky_relu(n) for n in j] for j in x2])\n",
    "    x3 = np.dot(y2, w3) + b3\n",
    "    \n",
    "    neural_data['x1'] = x1\n",
    "    neural_data['x2'] = x2\n",
    "    neural_data['x3'] = x3\n",
    "\n",
    "    neural_data['y1'] = y1\n",
    "    neural_data['y2'] = y2\n",
    "    neural_data['o'] = softmax(x3)\n",
    "    \n",
    "    return neural_data['o']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Functions\n",
    "Helper functions that return predictions, given our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_1hl(x, neural_data):\n",
    "    test = forward_prop_1hl(x,neural_data)\n",
    "    return np.argmax(test, axis=1)\n",
    "\n",
    "def predict_2hl(x, neural_data):\n",
    "    return np.argmax(forward_prop_2hl(x,neural_data), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetworkCostFunction(output, target):\n",
    "#     fashionTargetMinusOne = fashionTarget - 1\n",
    "#     cost = 0\n",
    "#     for j in range(fashionTrainOutput.shape[0]):\n",
    "#         cost += np.sum(np.multiply(fashionTarget, np.log10(fashionTrainOutput[j])),np.multiply(fashionTargetMinusOne, (1- np.log10(fashionTrainOutput[j]))))\n",
    "#     cost = cost*(-1)/fashionTrainOutput.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     partial_cost = -np.log(probs[range(fashionTrainOutput.shape[0]), fashionTarget])\n",
    "#     partial_cost -= np.log(1-probs[range(fashionTrainOutput.shape[0]), fashionTarget])\n",
    "#     cost = np.sum(partial_cost)\n",
    "    \n",
    "    cost = log_loss(target, output)\n",
    "    return cost\n",
    "\n",
    "def meanSquaresCost(fashionTrainOutput, fashionTarget):\n",
    "    diference = fashionTrainOutput - fashionTarget\n",
    "    squareDiference = diference ** 2\n",
    "    n = fashionTrainOutput.shape[0]    \n",
    "    return (np.sum(squareDiference)/(2*n))\n",
    "\n",
    "def accuracy (target, params, neural_model, hidden_layers=1):\n",
    "    right_answers = 0\n",
    "    target_indexes = np.argmax(target, axis=1)\n",
    "    if hidden_layers == 1:\n",
    "        predicted = predict_1hl(params, neural_model)\n",
    "    if hidden_layers == 2:\n",
    "        predicted = predict_2hl(params, neural_model)\n",
    "    n = params.shape[0]\n",
    "    for i in range (n):\n",
    "        if (target_indexes[i] == predicted[i]):\n",
    "            right_answers = right_answers + 1\n",
    "    return right_answers/n\n",
    "\n",
    "def construct_confusion_matrix (results, model, X):\n",
    "    confusion_matrix = np.zeros((10, 10), dtype=int)\n",
    "    predicted = predict_1hl(X, model)\n",
    "    n = X.shape[0]\n",
    "    for i in range (n):\n",
    "        confusion_matrix[results[i]][predicted[i]] = confusion_matrix[results[i]][predicted[i]] + 1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and backward propagation\n",
    "\n",
    "Some notes:\n",
    "\n",
    "### For one hidden layer:\n",
    "- x1 = #Output of hidden layer\n",
    "- x2 = #Output of last layer\n",
    "- y1 = #Output of hidden layer with activation function\n",
    "- o = Final output with Softmax\n",
    "\n",
    "### For TWO hidden layers:\n",
    "- x1 = #Output of first hidden layer\n",
    "- x2 = #Output of second hidden layer\n",
    "- x3 = Output of last layer\n",
    "- y1 = #Output of first hidden layer with activation function\n",
    "- y2 = #Output of second hidden layer with activation function\n",
    "- o = Final output with Softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hidden layer\n",
    "\n",
    "Here, we present our code and results achieved by a learning algorithm that uses a neural network with only one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network_1hl(hidden_layer_1_neurons, epochs, trainParams, trainTarget, learning_rate, regularization_rate, activation=\"sigmoid\"):\n",
    "    print(\"Beginning training with \", epochs, \" epochs and \", hidden_layer_1_neurons, \" hidden neurons.\")\n",
    "    input_dimension = 784\n",
    "    output_dimension = 10\n",
    "#     Initializes weights and biases for our neural network\n",
    "    neural_data = initialize_1hl(input_dimension, hidden_layer_1_neurons, output_dimension)\n",
    "    print(\"Initialized weights\")\n",
    "    \n",
    "#     Prepares for mini-batch\n",
    "    batchSize = 600\n",
    "    start_idx = 0\n",
    "    indices = np.arange(trainParams.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    print(\"Prepared for mini-batch.\")\n",
    "#     Performs Backpropagation\n",
    "    capitalDelta3 = 0\n",
    "    capitalDelta2 = 0\n",
    "    for j in range(epochs):\n",
    "        excerpt = indices[start_idx:start_idx + batchSize]\n",
    "        mini_batch_data = trainParams[excerpt]\n",
    "        miniBatchTarget = trainTarget[excerpt]\n",
    "#         Performs Forward propagation\n",
    "        probs = forward_prop_1hl(mini_batch_data, neural_data, activation)\n",
    "\n",
    "#         Performs Backward propagation\n",
    "\n",
    "        delta3 = probs - miniBatchTarget\n",
    "\n",
    "        dW2 =(1./batchSize)* (neural_data['y1'].T).dot(delta3)\n",
    "        db2 =(1./batchSize)* ( np.sum(delta3, axis=0, keepdims=True))\n",
    "        delta2 = np.dot(delta3, neural_data['w2'].T)\n",
    "        aux = neural_data['y1']\n",
    "        if activation == \"sigmoid\":\n",
    "            aux = [[derivative_sigmoid(n) for n in x] for x in aux]\n",
    "        if activation == \"relu\":\n",
    "            aux = [[derivative_relu(n) for n in x] for x in aux]\n",
    "        if activation == \"leaky_relu\":\n",
    "            aux = [[derivative_leaky_relu(n) for n in x] for x in aux]\n",
    "\n",
    "        delta2 = delta2 * aux\n",
    "\n",
    "        dW1 = (1./batchSize)*np.dot(mini_batch_data.T, delta2)\n",
    "        db1 = (1./batchSize)*np.sum(delta2, axis=0)\n",
    "        \n",
    "        \n",
    "#          # Performs regularization\n",
    "#         dW2 += regularization_rate * neural_data['w2']\n",
    "#         dW1 += regularization_rate * neural_data['w1']\n",
    "\n",
    "        # Gradient descent parameter update\n",
    "        neural_data['w1'] -= learning_rate * dW1\n",
    "        neural_data['b1'] -= learning_rate * db1\n",
    "        neural_data['w2'] -= learning_rate * dW2\n",
    "        neural_data['b2'] -= learning_rate * db2\n",
    "        \n",
    "        if j%50 == 0:\n",
    "            #         Calculates costs\n",
    "\n",
    "            cost = neuralNetworkCostFunction(probs, miniBatchTarget)\n",
    "            validation_probs = forward_prop_1hl(fashionValidationParams, neural_data)\n",
    "            validation_cost = neuralNetworkCostFunction(validation_probs, fashionValidationTarget)\n",
    "            print(\"Ended iteration\", j,\" Cost: \", cost, \" Validation cost: \", validation_cost)\n",
    "        start_idx += batchSize;\n",
    "        start_idx %= mini_batch_data.shape[0]\n",
    "    return neural_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two hidden layers\n",
    "\n",
    "Same as before, but for 2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, trainParams, trainTarget, learning_rate, regularization_rate, activation=\"sigmoid\"):\n",
    "    print(\"Beginning training with\", epochs, \"epochs,\", hidden_layer_1_neurons, \"neurons (1st layer)\", hidden_layer_2_neurons, \"neurons (2nd layer)\")\n",
    "\n",
    "    input_dimension = 784\n",
    "    output_dimension = 10\n",
    "#     Initializes weights and biases for our neural network\n",
    "    neural_data = initialize_2hl(input_dimension, hidden_layer_1_neurons, hidden_layer_2_neurons, output_dimension)\n",
    "    print(\"Initialized weights\")\n",
    "    \n",
    "#     Prepares for mini-batch\n",
    "    batchSize = 600\n",
    "    start_idx = 0\n",
    "    indices = np.arange(trainParams.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    print(\"Prepared for mini-batch.\")\n",
    "#     Performs Backpropagation\n",
    "    for j in range(epochs):\n",
    "        excerpt = indices[start_idx:start_idx + batchSize]\n",
    "        mini_batch_data = trainParams[excerpt]\n",
    "        miniBatchTarget = trainTarget[excerpt]\n",
    "#         Performs Forward propagation\n",
    "        probs = forward_prop_2hl(mini_batch_data, neural_data, activation)\n",
    "        \n",
    "#         Performs Backward propagation\n",
    "        delta4 = probs - miniBatchTarget\n",
    "        dW3 = 1/batchSize * (neural_data['y2'].T).dot(delta4)\n",
    "        db3 = 1/batchSize * np.sum(delta4, axis=0, keepdims=True)\n",
    "        delta3 = delta4.dot(neural_data['w3'].T)\n",
    "        aux = neural_data['y2']\n",
    "        if activation==\"sigmoid\":\n",
    "            aux = [[derivative_sigmoid(n) for n in x] for x in aux]\n",
    "        if activation==\"relu\":\n",
    "            aux = [[derivative_relu(n) for n in x] for x in aux]\n",
    "        if activation==\"leaky_relu\":\n",
    "            aux = [[derivative_leaky_relu(n) for n in x] for x in aux]        \n",
    "        delta3 = delta3 * aux\n",
    "        dW2 = 1/batchSize * np.dot(neural_data['y1'].T, delta3)\n",
    "        db2 = 1/batchSize * np.sum(delta3, axis=0, keepdims=True)\n",
    "        delta2 = delta3.dot(neural_data['w2'].T)  #look for issues here\n",
    "        aux = neural_data['y1']\n",
    "        if activation==\"sigmoid\":\n",
    "            aux = [[derivative_sigmoid(n) for n in x] for x in aux]\n",
    "        if activation==\"relu\":\n",
    "            aux = [[derivative_relu(n) for n in x] for x in aux]\n",
    "        if activation==\"leaky_relu\":\n",
    "            aux = [[derivative_leaky_relu(n) for n in x] for x in aux]\n",
    "        delta2 = delta2 * aux\n",
    "        dW1 = 1/batchSize * np.dot(mini_batch_data.T, delta2)\n",
    "        db1 = 1/batchSize * np.sum(delta2, axis=0, keepdims=True)      \n",
    "        \n",
    "#          # Performs regularization\n",
    "#         dW3 += regularization_rate * neural_data['w3']\n",
    "#         dW2 += regularization_rate * neural_data['w2']\n",
    "#         dW1 += regularization_rate * neural_data['w1']\n",
    "\n",
    "        # Gradient descent parameter update\n",
    "        neural_data['w1'] -= learning_rate * dW1\n",
    "        neural_data['b1'] -= learning_rate * db1\n",
    "        neural_data['w2'] -= learning_rate * dW2\n",
    "        neural_data['b2'] -= learning_rate * db2\n",
    "        neural_data['w3'] -= learning_rate * dW3\n",
    "        neural_data['b3'] -= learning_rate * db3\n",
    "        \n",
    "        if j%50 == 0:\n",
    "            #         Calculates costs\n",
    "\n",
    "            cost = neuralNetworkCostFunction(probs, miniBatchTarget)\n",
    "            validation_probs = forward_prop_2hl(fashionValidationParams, neural_data)\n",
    "            validation_cost = neuralNetworkCostFunction(validation_probs, fashionValidationTarget)\n",
    "            print(\"Ended iteration\", j,\" Cost: \", cost, \" Validation cost: \", validation_cost)\n",
    "        start_idx += 1;\n",
    "        start_idx %= mini_batch_data.shape[0]\n",
    "        \n",
    "    return neural_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the neural networks\n",
    "\n",
    "Now, we'll test our neural networks under multiple circumstances on the validation set, so we can gest the best possible models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem details\n",
    "- Input dimension: 28x28 = 784 neurons\n",
    "- Output dimension: 10 classes = 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 1\n",
    "input_neurons = 784\n",
    "output_neurons = 10\n",
    "hidden_layer_1_neurons = 50\n",
    "hidden_layer_2_neurons = 15\n",
    "learning_rate = 0.1\n",
    "regularization_rate = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our evaluation\n",
    "Here, we define the function which will use the training we implemented before. It will train 3 models (using the same parameters), to test to an extent the impact of random initialization on the weights matrix. After the training, we check the costs and accuracies of each model (both related to train an validation sets), as well as the average of such values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation=\"sigmoid\"):\n",
    "    model_1hl_1 = train_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================First model trained=====================\")\n",
    "    model_1hl_2 = train_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================Second model trained=====================\")\n",
    "    model_1hl_3 = train_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================Third model trained=====================\")\n",
    "    probs_sigmoid1 = forward_prop_1hl(fashionValidationParams, model_1hl_1)\n",
    "    cost1 = neuralNetworkCostFunction(probs_sigmoid1, fashionValidationTarget)\n",
    "    acc1_train = accuracy(fashionTrainTarget, fashionTrainParams, model_1hl_1)\n",
    "    acc1_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_1hl_1)\n",
    "    print(\"First model \", activation, \"validation cost: \", cost1, \" acc_train: {0:.4f} \".format(acc1_train), \" acc_validation: {0:.4f} \".format(acc1_validation))\n",
    "    \n",
    "    probs_sigmoid2 = forward_prop_1hl(fashionValidationParams, model_1hl_2)\n",
    "    cost2 = neuralNetworkCostFunction(probs_sigmoid2, fashionValidationTarget)\n",
    "    acc2_train = accuracy(fashionTrainTarget, fashionTrainParams, model_1hl_2)\n",
    "    acc2_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_1hl_2)\n",
    "    print(\"Second model  \", activation, \"validation cost: \", cost2, \" acc_train:{0:.4f} \".format(acc2_train), \" acc_validation: {0:.4f} \".format(acc2_validation))\n",
    "    \n",
    "    probs_sigmoid3 = forward_prop_1hl(fashionValidationParams, model_1hl_3)\n",
    "    cost3 = neuralNetworkCostFunction(probs_sigmoid3, fashionValidationTarget)\n",
    "    acc3_train = accuracy(fashionTrainTarget, fashionTrainParams, model_1hl_3)\n",
    "    acc3_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_1hl_3)\n",
    "    print(\"Third model \", activation, \"validation cost: \", cost3, \" acc_train:{0:.4f} \".format(acc3_train), \" acc_validation: {0:.4f} \".format(acc3_validation))\n",
    "    \n",
    "    \n",
    "    avg_loss = ((cost1+cost2+cost3)/3)\n",
    "    avg_acc = ((acc1_validation + acc2_validation + acc3_validation)/3)\n",
    "    print(\"Average validation loss: \", avg_loss, \" Average validation accuracy: \", avg_acc)\n",
    "    return\n",
    "\n",
    "def evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation=\"sigmoid\"):\n",
    "    model_2hl_1 = train_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================First model trained=====================\")\n",
    "    model_2hl_2 = train_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================Second model trained=====================\")\n",
    "    model_2hl_3 = train_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n",
    "    print(\"======================Third model trained=====================\")\n",
    "    probs_sigmoid1 = forward_prop_2hl(fashionValidationParams, model_2hl_1)\n",
    "    cost1 = neuralNetworkCostFunction(probs_sigmoid1, fashionValidationTarget)\n",
    "    acc1_train = accuracy(fashionTrainTarget, fashionTrainParams, model_2hl_1, hidden_layers=2)\n",
    "    acc1_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_2hl_1, hidden_layers=2)\n",
    "    print(\"First model \", activation, \"validation cost: \", cost1, \" acc_train: {0:.4f} \".format(acc1_train), \" acc_validation: {0:.4f} \".format(acc1_validation))\n",
    "    \n",
    "    probs_sigmoid2 = forward_prop_2hl(fashionValidationParams, model_2hl_2)\n",
    "    cost2 = neuralNetworkCostFunction(probs_sigmoid2, fashionValidationTarget)\n",
    "    acc2_train = accuracy(fashionTrainTarget, fashionTrainParams, model_2hl_2, hidden_layers=2)\n",
    "    acc2_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_2hl_2, hidden_layers=2)\n",
    "    print(\"Second model  \", activation, \"validation cost: \", cost2, \" acc_train:{0:.4f} \".format(acc2_train), \" acc_validation: {0:.4f} \".format(acc2_validation))\n",
    "    \n",
    "    probs_sigmoid3 = forward_prop_2hl(fashionValidationParams, model_2hl_3)\n",
    "    cost3 = neuralNetworkCostFunction(probs_sigmoid3, fashionValidationTarget)\n",
    "    acc3_train = accuracy(fashionTrainTarget, fashionTrainParams, model_2hl_3, hidden_layers=2)\n",
    "    acc3_validation = accuracy(fashionValidationTarget, fashionValidationParams, model_2hl_3, hidden_layers=2)\n",
    "    print(\"Third model \", activation, \"validation cost: \", cost3, \" acc_train:{0:.4f} \".format(acc3_train), \" acc_validation: {0:.4f} \".format(acc3_validation))\n",
    "    \n",
    "    \n",
    "    avg_loss = ((cost1+cost2+cost3)/3)\n",
    "    avg_acc = ((acc1_validation + acc2_validation + acc3_validation)/3)\n",
    "    print(\"Average validation loss: \", avg_loss, \" Average validation accuracy: \", avg_acc)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First experiments\n",
    "First, we will train a model using a hidden layer with 50 neurons and 1000 epochs, which is small given the input of 784 neurons. We will run 3 times for each activation function to get an average result (that depends heavily on the initialization of the weights)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since everything seems ok, we'll increase the number of epochs to 1000, but mantaining the current amount of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3095678010957243  Validation cost:  2.303000951389828\n",
      "Ended iteration 50  Cost:  2.10616453431803  Validation cost:  2.1116563286158287\n",
      "Ended iteration 100  Cost:  1.7660127041980669  Validation cost:  1.778048729409108\n",
      "Ended iteration 150  Cost:  1.5228663380362844  Validation cost:  1.5365662872767576\n",
      "Ended iteration 200  Cost:  1.3641502752722172  Validation cost:  1.3778975257467707\n",
      "Ended iteration 250  Cost:  1.2510247578583324  Validation cost:  1.2652103078619668\n",
      "Ended iteration 300  Cost:  1.168143734613796  Validation cost:  1.1831522078464725\n",
      "Ended iteration 350  Cost:  1.1073639262438901  Validation cost:  1.1228406807385178\n",
      "Ended iteration 400  Cost:  1.0633856492650084  Validation cost:  1.0785116708034872\n",
      "Ended iteration 450  Cost:  1.0325790540350563  Validation cost:  1.0468535494605153\n",
      "Ended iteration 500  Cost:  1.0111647902257948  Validation cost:  1.025120088387487\n",
      "Ended iteration 550  Cost:  0.9955023292309253  Validation cost:  1.0104724286766824\n",
      "Ended iteration 600  Cost:  0.983330385679995  Validation cost:  1.0005848502418453\n",
      "Ended iteration 650  Cost:  0.973943412035405  Validation cost:  0.9939682263486873\n",
      "Ended iteration 700  Cost:  0.9674564666645727  Validation cost:  0.9900135461361426\n",
      "Ended iteration 750  Cost:  0.9637749008807731  Validation cost:  0.98834108014912\n",
      "Ended iteration 800  Cost:  0.9620620830783408  Validation cost:  0.988141761680292\n",
      "Ended iteration 850  Cost:  0.9610958983140004  Validation cost:  0.988160656263597\n",
      "Ended iteration 900  Cost:  0.9596407297634502  Validation cost:  0.9872404645324893\n",
      "Ended iteration 950  Cost:  0.9566438393175376  Validation cost:  0.9845876508089764\n",
      "Ended iteration 1000  Cost:  0.9513640484714633  Validation cost:  0.9797881254038869\n",
      "Ended iteration 1050  Cost:  0.9437829665924514  Validation cost:  0.9730397400349962\n",
      "Ended iteration 1100  Cost:  0.9349228378188034  Validation cost:  0.965193430740862\n",
      "Ended iteration 1150  Cost:  0.926271099632632  Validation cost:  0.957279668553367\n",
      "Ended iteration 1200  Cost:  0.9187835015488095  Validation cost:  0.9499497205206404\n",
      "Ended iteration 1250  Cost:  0.9121218558773876  Validation cost:  0.9434670780652712\n",
      "Ended iteration 1300  Cost:  0.905496108359821  Validation cost:  0.9378154687008424\n",
      "Ended iteration 1350  Cost:  0.8986560775215189  Validation cost:  0.9327894137276895\n",
      "Ended iteration 1400  Cost:  0.8916771685002122  Validation cost:  0.9281906176830954\n",
      "Ended iteration 1450  Cost:  0.8845150142115038  Validation cost:  0.923901061782752\n",
      "Ended iteration 1500  Cost:  0.877178035902529  Validation cost:  0.9198522231753024\n",
      "Ended iteration 1550  Cost:  0.8698792673235877  Validation cost:  0.9160257915467579\n",
      "Ended iteration 1600  Cost:  0.8626702164837051  Validation cost:  0.9123941893522302\n",
      "Ended iteration 1650  Cost:  0.8553266510835456  Validation cost:  0.9088398472034772\n",
      "Ended iteration 1700  Cost:  0.847454384186304  Validation cost:  0.905146140164689\n",
      "Ended iteration 1750  Cost:  0.8388821021395213  Validation cost:  0.9009809547773941\n",
      "Ended iteration 1800  Cost:  0.8302122404477709  Validation cost:  0.8960585877471035\n",
      "Ended iteration 1850  Cost:  0.8225616479716286  Validation cost:  0.8909457596955921\n",
      "Ended iteration 1900  Cost:  0.8170377941353751  Validation cost:  0.8868913843986578\n",
      "Ended iteration 1950  Cost:  0.8140977520352076  Validation cost:  0.8843089249286011\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3134541949570613  Validation cost:  2.306202427001535\n",
      "Ended iteration 50  Cost:  2.1436154962061504  Validation cost:  2.1553802859784224\n",
      "Ended iteration 100  Cost:  1.7932620909522148  Validation cost:  1.8118381134671395\n",
      "Ended iteration 150  Cost:  1.5055342455620317  Validation cost:  1.5345218814371395\n",
      "Ended iteration 200  Cost:  1.3236410481390306  Validation cost:  1.3628536333575094\n",
      "Ended iteration 250  Cost:  1.2018971413553432  Validation cost:  1.2513443660041037\n",
      "Ended iteration 300  Cost:  1.1134881834946153  Validation cost:  1.1735791111579044\n",
      "Ended iteration 350  Cost:  1.0447640575192307  Validation cost:  1.1152460445623993\n",
      "Ended iteration 400  Cost:  0.989630199375295  Validation cost:  1.069370431875477\n",
      "Ended iteration 450  Cost:  0.9453804663023203  Validation cost:  1.0332017059048744\n",
      "Ended iteration 500  Cost:  0.9101308797866303  Validation cost:  1.0048440688940403\n",
      "Ended iteration 550  Cost:  0.8824249684804113  Validation cost:  0.9826630226578149\n",
      "Ended iteration 600  Cost:  0.8615611647100078  Validation cost:  0.9659117970410565\n",
      "Ended iteration 650  Cost:  0.8466710654335255  Validation cost:  0.9539925855445789\n",
      "Ended iteration 700  Cost:  0.835880987187834  Validation cost:  0.9457866425110993\n",
      "Ended iteration 750  Cost:  0.8272353896691174  Validation cost:  0.9399592821624428\n",
      "Ended iteration 800  Cost:  0.8195143120905863  Validation cost:  0.9352851334365511\n",
      "Ended iteration 850  Cost:  0.8121118485668248  Validation cost:  0.9311546730526155\n",
      "Ended iteration 900  Cost:  0.8049304744138238  Validation cost:  0.9276743896709255\n",
      "Ended iteration 950  Cost:  0.7984422472173617  Validation cost:  0.9252038838800772\n",
      "Ended iteration 1000  Cost:  0.7928790724223418  Validation cost:  0.9238536935208598\n",
      "Ended iteration 1050  Cost:  0.7879758649167673  Validation cost:  0.9233809310247948\n",
      "Ended iteration 1100  Cost:  0.783262942134997  Validation cost:  0.923293472307791\n",
      "Ended iteration 1150  Cost:  0.7782401386298616  Validation cost:  0.9229303989502854\n",
      "Ended iteration 1200  Cost:  0.7726614496592977  Validation cost:  0.9218136617886369\n",
      "Ended iteration 1250  Cost:  0.7663960953322178  Validation cost:  0.9197913496822927\n",
      "Ended iteration 1300  Cost:  0.759282748081289  Validation cost:  0.9169076131532686\n",
      "Ended iteration 1350  Cost:  0.7510785821126365  Validation cost:  0.9132867243922127\n",
      "Ended iteration 1400  Cost:  0.7415128836505004  Validation cost:  0.9090679777781153\n",
      "Ended iteration 1450  Cost:  0.7308307957503769  Validation cost:  0.9044361099403242\n",
      "Ended iteration 1500  Cost:  0.7199349184572599  Validation cost:  0.8997234694197911\n",
      "Ended iteration 1550  Cost:  0.7097603526713724  Validation cost:  0.8953013933059946\n",
      "Ended iteration 1600  Cost:  0.700885835828278  Validation cost:  0.8913574997349685\n",
      "Ended iteration 1650  Cost:  0.6932150033399185  Validation cost:  0.8878283050700057\n",
      "Ended iteration 1700  Cost:  0.6859351430022581  Validation cost:  0.8847623869187126\n",
      "Ended iteration 1750  Cost:  0.6786975797706609  Validation cost:  0.8823615676341433\n",
      "Ended iteration 1800  Cost:  0.6727696094760269  Validation cost:  0.8807758755415445\n",
      "Ended iteration 1850  Cost:  0.6684333674318851  Validation cost:  0.8797958914090098\n",
      "Ended iteration 1900  Cost:  0.6644697418629132  Validation cost:  0.8791053662480719\n",
      "Ended iteration 1950  Cost:  0.6603531201541017  Validation cost:  0.878606335546121\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3072010660747004  Validation cost:  2.3088292850829273\n",
      "Ended iteration 50  Cost:  2.1588219636587955  Validation cost:  2.1636717034522848\n",
      "Ended iteration 100  Cost:  1.8233561707116046  Validation cost:  1.8321586859006351\n",
      "Ended iteration 150  Cost:  1.5559459126221995  Validation cost:  1.5717066071750074\n",
      "Ended iteration 200  Cost:  1.3896273332063147  Validation cost:  1.4095670315741151\n",
      "Ended iteration 250  Cost:  1.2710751248548873  Validation cost:  1.293871523937982\n",
      "Ended iteration 300  Cost:  1.1767441143587594  Validation cost:  1.2021115849088693\n",
      "Ended iteration 350  Cost:  1.100699852276698  Validation cost:  1.1287771572651923\n",
      "Ended iteration 400  Cost:  1.0408269006731594  Validation cost:  1.0720128373784943\n",
      "Ended iteration 450  Cost:  0.99438627104661  Validation cost:  1.0294018767231263\n",
      "Ended iteration 500  Cost:  0.9590301565839953  Validation cost:  0.9984829196181055\n",
      "Ended iteration 550  Cost:  0.9319933142168725  Validation cost:  0.9763048914855627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 600  Cost:  0.9115678459965239  Validation cost:  0.9605446726906532\n",
      "Ended iteration 650  Cost:  0.8970000118468242  Validation cost:  0.9496318568068141\n",
      "Ended iteration 700  Cost:  0.8865149403750778  Validation cost:  0.9419996332043648\n",
      "Ended iteration 750  Cost:  0.8782232098970195  Validation cost:  0.9364397295185798\n",
      "Ended iteration 800  Cost:  0.8714638860865  Validation cost:  0.9324109385672628\n",
      "Ended iteration 850  Cost:  0.8663766102939  Validation cost:  0.9297573105675492\n",
      "Ended iteration 900  Cost:  0.8625049463171979  Validation cost:  0.9279543288071915\n",
      "Ended iteration 950  Cost:  0.858756631389545  Validation cost:  0.9261277561856857\n",
      "Ended iteration 1000  Cost:  0.8544883626369539  Validation cost:  0.9238158764029166\n",
      "Ended iteration 1050  Cost:  0.8495444397869906  Validation cost:  0.9210669661499139\n",
      "Ended iteration 1100  Cost:  0.8434986621776092  Validation cost:  0.9179185709285963\n",
      "Ended iteration 1150  Cost:  0.8358760281616388  Validation cost:  0.9142155860208337\n",
      "Ended iteration 1200  Cost:  0.8269699417807914  Validation cost:  0.9100274249863424\n",
      "Ended iteration 1250  Cost:  0.817546722503065  Validation cost:  0.9057278553661942\n",
      "Ended iteration 1300  Cost:  0.808391496611866  Validation cost:  0.9017061797594157\n",
      "Ended iteration 1350  Cost:  0.8000296102888582  Validation cost:  0.8980120276983089\n",
      "Ended iteration 1400  Cost:  0.7925426386453144  Validation cost:  0.8943976579111056\n",
      "Ended iteration 1450  Cost:  0.7857283062103835  Validation cost:  0.8906125610962554\n",
      "Ended iteration 1500  Cost:  0.7795388335257771  Validation cost:  0.8867161411444173\n",
      "Ended iteration 1550  Cost:  0.7736939050310231  Validation cost:  0.8829197953158785\n",
      "Ended iteration 1600  Cost:  0.767943099018593  Validation cost:  0.8794034661734729\n",
      "Ended iteration 1650  Cost:  0.7622842829067995  Validation cost:  0.8763024510542363\n",
      "Ended iteration 1700  Cost:  0.7569011685257468  Validation cost:  0.8736388555926369\n",
      "Ended iteration 1750  Cost:  0.7519963629512042  Validation cost:  0.8713612886652837\n",
      "Ended iteration 1800  Cost:  0.7474597183784106  Validation cost:  0.8694537936008956\n",
      "Ended iteration 1850  Cost:  0.7430920589382055  Validation cost:  0.8679574799810034\n",
      "Ended iteration 1900  Cost:  0.7386266528220882  Validation cost:  0.866924982321259\n",
      "Ended iteration 1950  Cost:  0.7337951946919721  Validation cost:  0.8663641369670524\n",
      "======================Third model trained=====================\n",
      "First model  sigmoid validation cost:  0.8828596886022492  acc_train: 0.6733   acc_validation: 0.6678 \n",
      "Second model   sigmoid validation cost:  0.8781935049303574  acc_train:0.6691   acc_validation: 0.6666 \n",
      "Third model  sigmoid validation cost:  0.8663177635156282  acc_train:0.6904   acc_validation: 0.6855 \n",
      "Average validation loss:  0.8757903190160783  Average validation accuracy:  0.6733055555555555\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for 2000 epochs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these trainings, we see that we achieve best performance generally around 1500 epochs. Now we'll test with other activation functions.\n",
    "\n",
    "## Relu.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3023907772287755  Validation cost:  2.3020479915883687\n",
      "Ended iteration 50  Cost:  1.1720106350637778  Validation cost:  1.765683460081947\n",
      "Ended iteration 100  Cost:  0.8134728432848074  Validation cost:  1.5422806043742943\n",
      "Ended iteration 150  Cost:  0.6670156268686959  Validation cost:  1.455052639440825\n",
      "Ended iteration 200  Cost:  0.5686379914438255  Validation cost:  1.4049963179594882\n",
      "Ended iteration 250  Cost:  0.49183080584850053  Validation cost:  1.3684917942759816\n",
      "Ended iteration 300  Cost:  0.4278990737591168  Validation cost:  1.3387356667262964\n",
      "Ended iteration 350  Cost:  0.37342250044910436  Validation cost:  1.313632286143536\n",
      "Ended iteration 400  Cost:  0.38090584329533445  Validation cost:  1.2972852267904575\n",
      "Ended iteration 450  Cost:  0.32321557937099377  Validation cost:  1.2517586152452962\n",
      "Ended iteration 500  Cost:  0.2922801646854352  Validation cost:  1.221732390108751\n",
      "Ended iteration 550  Cost:  0.2649409126789188  Validation cost:  1.195579116075218\n",
      "Ended iteration 600  Cost:  0.24067048513437309  Validation cost:  1.172687400999412\n",
      "Ended iteration 650  Cost:  0.2186810167554903  Validation cost:  1.1522731427832662\n",
      "Ended iteration 700  Cost:  0.1972954916843119  Validation cost:  1.1344823923490743\n",
      "Ended iteration 750  Cost:  0.18640972705277278  Validation cost:  1.0898943903054275\n",
      "Ended iteration 800  Cost:  0.18634715382385128  Validation cost:  1.0953758547212793\n",
      "Ended iteration 850  Cost:  0.1530977124651171  Validation cost:  1.0785437849598423\n",
      "Ended iteration 900  Cost:  0.14778482706520607  Validation cost:  1.0536417523505772\n",
      "Ended iteration 950  Cost:  0.1468855850758413  Validation cost:  1.024139258171414\n",
      "Ended iteration 1000  Cost:  0.12309448226491955  Validation cost:  1.0059159099916695\n",
      "Ended iteration 1050  Cost:  0.11830849792374964  Validation cost:  0.9997648047336961\n",
      "Ended iteration 1100  Cost:  0.0946393324343248  Validation cost:  0.9929196408208154\n",
      "Ended iteration 1150  Cost:  0.10661925488322391  Validation cost:  0.9901635961480237\n",
      "Ended iteration 1200  Cost:  0.07610793965166224  Validation cost:  0.9768525960862939\n",
      "Ended iteration 1250  Cost:  0.0677665988520019  Validation cost:  0.9722425787866076\n",
      "Ended iteration 1300  Cost:  0.061078868073147635  Validation cost:  0.9680516775978889\n",
      "Ended iteration 1350  Cost:  0.05542138292173351  Validation cost:  0.9643965794265212\n",
      "Ended iteration 1400  Cost:  0.05057256513339889  Validation cost:  0.9612063336181618\n",
      "Ended iteration 1450  Cost:  0.0463784990000308  Validation cost:  0.9583776551842005\n",
      "Ended iteration 1500  Cost:  0.04271035571257358  Validation cost:  0.9558440335301981\n",
      "Ended iteration 1550  Cost:  0.039496309624483014  Validation cost:  0.9535562181167668\n",
      "Ended iteration 1600  Cost:  0.03666183977196526  Validation cost:  0.9514798119450021\n",
      "Ended iteration 1650  Cost:  0.034148303107462905  Validation cost:  0.9495892762239999\n",
      "Ended iteration 1700  Cost:  0.03190652296845124  Validation cost:  0.9478625648000341\n",
      "Ended iteration 1750  Cost:  0.029899672145105725  Validation cost:  0.9462803670202669\n",
      "Ended iteration 1800  Cost:  0.02809616092761048  Validation cost:  0.9448295659326877\n",
      "Ended iteration 1850  Cost:  0.02646226994482222  Validation cost:  0.9434983197903216\n",
      "Ended iteration 1900  Cost:  0.024965470577423224  Validation cost:  0.9422799189336419\n",
      "Ended iteration 1950  Cost:  0.023605070533907167  Validation cost:  0.941157572907808\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.302603156418618  Validation cost:  2.302621340983296\n",
      "Ended iteration 50  Cost:  1.112564004168632  Validation cost:  1.7960322536396665\n",
      "Ended iteration 100  Cost:  0.7996311837828467  Validation cost:  1.60901560531609\n",
      "Ended iteration 150  Cost:  0.6607340146998786  Validation cost:  1.539550133641739\n",
      "Ended iteration 200  Cost:  0.5545259386103043  Validation cost:  1.5041866360075815\n",
      "Ended iteration 250  Cost:  0.46594358301521527  Validation cost:  1.482580078066439\n",
      "Ended iteration 300  Cost:  0.39372080074166893  Validation cost:  1.4684935246422086\n",
      "Ended iteration 350  Cost:  0.33590903508196773  Validation cost:  1.4593021002318642\n",
      "Ended iteration 400  Cost:  0.3420493533300605  Validation cost:  1.4361334324870147\n",
      "Ended iteration 450  Cost:  0.26323827031881386  Validation cost:  1.4223283495425518\n",
      "Ended iteration 500  Cost:  0.25125655460933  Validation cost:  1.4298735614683755\n",
      "Ended iteration 550  Cost:  0.21409320503389404  Validation cost:  1.3846620595097654\n",
      "Ended iteration 600  Cost:  0.20572408352003724  Validation cost:  1.3837958715362286\n",
      "Ended iteration 650  Cost:  0.1783055404338604  Validation cost:  1.3543966083847707\n",
      "Ended iteration 700  Cost:  0.16903399958293466  Validation cost:  1.2779194980678286\n",
      "Ended iteration 750  Cost:  0.1430497597143689  Validation cost:  1.2624946564358095\n",
      "Ended iteration 800  Cost:  0.1312042892682714  Validation cost:  1.2517144517378413\n",
      "Ended iteration 850  Cost:  0.11979372800175651  Validation cost:  1.2704556927584187\n",
      "Ended iteration 900  Cost:  0.12257751489778478  Validation cost:  1.2843843353411923\n",
      "Ended iteration 950  Cost:  0.09509940034807057  Validation cost:  1.2190010804831402\n",
      "Ended iteration 1000  Cost:  0.08533236577405898  Validation cost:  1.2133635941002976\n",
      "Ended iteration 1050  Cost:  0.07711502589356362  Validation cost:  1.2064827059240555\n",
      "Ended iteration 1100  Cost:  0.0700028291367951  Validation cost:  1.200331022821783\n",
      "Ended iteration 1150  Cost:  0.06378812641796734  Validation cost:  1.194756832421235\n",
      "Ended iteration 1200  Cost:  0.05833075629185174  Validation cost:  1.1896328486796335\n",
      "Ended iteration 1250  Cost:  0.05351385765179726  Validation cost:  1.1848659536615878\n",
      "Ended iteration 1300  Cost:  0.049254717389981814  Validation cost:  1.1804222808677465\n",
      "Ended iteration 1350  Cost:  0.045479665540607395  Validation cost:  1.176270085394022\n",
      "Ended iteration 1400  Cost:  0.04212255780237491  Validation cost:  1.1723824113353576\n",
      "Ended iteration 1450  Cost:  0.0391330722329749  Validation cost:  1.168733485031526\n",
      "Ended iteration 1500  Cost:  0.036456969184707776  Validation cost:  1.165303436767531\n",
      "Ended iteration 1550  Cost:  0.03405465413191881  Validation cost:  1.1620747553748725\n",
      "Ended iteration 1600  Cost:  0.03189041264704499  Validation cost:  1.1590303741366001\n",
      "Ended iteration 1650  Cost:  0.02993547677214884  Validation cost:  1.1561517024410906\n",
      "Ended iteration 1700  Cost:  0.028164965268864587  Validation cost:  1.1534265347741077\n",
      "Ended iteration 1750  Cost:  0.026557216245971512  Validation cost:  1.1508448817839412\n",
      "Ended iteration 1800  Cost:  0.02509378274066013  Validation cost:  1.148396973850398\n",
      "Ended iteration 1850  Cost:  0.023761346603485865  Validation cost:  1.1460719455323296\n",
      "Ended iteration 1900  Cost:  0.022541066518245747  Validation cost:  1.1438614769705384\n",
      "Ended iteration 1950  Cost:  0.02142089821093759  Validation cost:  1.141756563675749\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.310458774730892  Validation cost:  2.309312113814541\n",
      "Ended iteration 50  Cost:  1.1604356322171396  Validation cost:  1.781747039588239\n",
      "Ended iteration 100  Cost:  0.8137612799971806  Validation cost:  1.5973376873470677\n",
      "Ended iteration 150  Cost:  0.6614923096420451  Validation cost:  1.5507469111470327\n",
      "Ended iteration 200  Cost:  0.5654524823193018  Validation cost:  1.5364147969308584\n",
      "Ended iteration 250  Cost:  0.4945764247734851  Validation cost:  1.5289035370738966\n",
      "Ended iteration 300  Cost:  0.4367115403765516  Validation cost:  1.5230943768568999\n",
      "Ended iteration 350  Cost:  0.3881674448264046  Validation cost:  1.5202325387155173\n",
      "Ended iteration 400  Cost:  0.3700958130487014  Validation cost:  1.501461544544619\n",
      "Ended iteration 450  Cost:  0.34538871672701515  Validation cost:  1.4427039872969427\n",
      "Ended iteration 500  Cost:  0.31988809202217483  Validation cost:  1.4422471667537853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 550  Cost:  0.2934286787990864  Validation cost:  1.3850787084096676\n",
      "Ended iteration 600  Cost:  0.27935066363558503  Validation cost:  1.3909649208591561\n",
      "Ended iteration 650  Cost:  0.2746709636587201  Validation cost:  1.3292639631872696\n",
      "Ended iteration 700  Cost:  0.23687825935304654  Validation cost:  1.3397742436290734\n",
      "Ended iteration 750  Cost:  0.22479383828529706  Validation cost:  1.2941935311310693\n",
      "Ended iteration 800  Cost:  0.20195888808526788  Validation cost:  1.2764857861782242\n",
      "Ended iteration 850  Cost:  0.1810648805838559  Validation cost:  1.2797762521624643\n",
      "Ended iteration 900  Cost:  0.20160401215581586  Validation cost:  1.236069437344204\n",
      "Ended iteration 950  Cost:  0.16933502954263727  Validation cost:  1.2447711326626023\n",
      "Ended iteration 1000  Cost:  0.1442884758118689  Validation cost:  1.225156770741262\n",
      "Ended iteration 1050  Cost:  0.11357866924627023  Validation cost:  1.213043566479511\n",
      "Ended iteration 1100  Cost:  0.10031594634304507  Validation cost:  1.2119444884192567\n",
      "Ended iteration 1150  Cost:  0.09033032870652713  Validation cost:  1.2105137442381748\n",
      "Ended iteration 1200  Cost:  0.08172516618338867  Validation cost:  1.2092588060929006\n",
      "Ended iteration 1250  Cost:  0.07420370516261267  Validation cost:  1.2081415159313333\n",
      "Ended iteration 1300  Cost:  0.06763934794311592  Validation cost:  1.2071539899616879\n",
      "Ended iteration 1350  Cost:  0.061864729471423616  Validation cost:  1.2063366689452448\n",
      "Ended iteration 1400  Cost:  0.056784327672103514  Validation cost:  1.2056601146649661\n",
      "Ended iteration 1450  Cost:  0.05229766054292398  Validation cost:  1.2050985212676368\n",
      "Ended iteration 1500  Cost:  0.048322901560735675  Validation cost:  1.2046336604300483\n",
      "Ended iteration 1550  Cost:  0.044785538576204535  Validation cost:  1.2042238786959105\n",
      "Ended iteration 1600  Cost:  0.04162725050987371  Validation cost:  1.2038934158608008\n",
      "Ended iteration 1650  Cost:  0.038801707632037  Validation cost:  1.20364565432872\n",
      "Ended iteration 1700  Cost:  0.0362698087884937  Validation cost:  1.2034670390315925\n",
      "Ended iteration 1750  Cost:  0.0339915466439432  Validation cost:  1.2033408217544295\n",
      "Ended iteration 1800  Cost:  0.03194741673870303  Validation cost:  1.2032622296082232\n",
      "Ended iteration 1850  Cost:  0.030111620952591126  Validation cost:  1.2032257044316503\n",
      "Ended iteration 1900  Cost:  0.028443622855298525  Validation cost:  1.2032378558225676\n",
      "Ended iteration 1950  Cost:  0.026926265950049526  Validation cost:  1.2032882136322411\n",
      "======================Third model trained=====================\n",
      "First model  relu validation cost:  0.9401408287442021  acc_train: 0.6797   acc_validation: 0.6717 \n",
      "Second model   relu validation cost:  1.139789487278604  acc_train:0.5284   acc_validation: 0.5281 \n",
      "Third model  relu validation cost:  1.2033742367700282  acc_train:0.5623   acc_validation: 0.5565 \n",
      "Average validation loss:  1.0944348509309447  Average validation accuracy:  0.5854166666666666\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "activation = \"relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky-relu.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.303072272687457  Validation cost:  2.30205808136482\n",
      "Ended iteration 50  Cost:  1.0681808666430463  Validation cost:  2.0110539301754606\n",
      "Ended iteration 100  Cost:  0.7502436454467308  Validation cost:  1.9413271614820673\n",
      "Ended iteration 150  Cost:  0.6487268719290502  Validation cost:  1.8835401225174797\n",
      "Ended iteration 200  Cost:  0.5486457661532882  Validation cost:  1.873943349388835\n",
      "Ended iteration 250  Cost:  0.46882519646401816  Validation cost:  1.871568264870146\n",
      "Ended iteration 300  Cost:  0.4023194568380842  Validation cost:  1.8738037099581664\n",
      "Ended iteration 350  Cost:  0.34884159310255697  Validation cost:  1.8804156403154104\n",
      "Ended iteration 400  Cost:  0.3022883031370993  Validation cost:  1.8874781233871714\n",
      "Ended iteration 450  Cost:  0.26097549447109514  Validation cost:  1.8890856657344082\n",
      "Ended iteration 500  Cost:  0.2515211147907723  Validation cost:  1.8855012331270378\n",
      "Ended iteration 550  Cost:  0.21067501630582067  Validation cost:  1.8931876479097203\n",
      "Ended iteration 600  Cost:  0.18929786707001794  Validation cost:  1.903551152424332\n",
      "Ended iteration 650  Cost:  0.16773858549498058  Validation cost:  1.9116872315285587\n",
      "Ended iteration 700  Cost:  0.15178646565526088  Validation cost:  1.9158415406020932\n",
      "Ended iteration 750  Cost:  0.12191687269299209  Validation cost:  1.8664282574866669\n",
      "Ended iteration 800  Cost:  0.11927235025843506  Validation cost:  1.8923704181434113\n",
      "Ended iteration 850  Cost:  0.10216270634643528  Validation cost:  1.9078818081442217\n",
      "Ended iteration 900  Cost:  0.089353162830692  Validation cost:  1.9226612679632678\n",
      "Ended iteration 950  Cost:  0.07853330975116467  Validation cost:  1.9371837554068716\n",
      "Ended iteration 1000  Cost:  0.07101051977320007  Validation cost:  1.9482415589238093\n",
      "Ended iteration 1050  Cost:  0.06342260555433729  Validation cost:  1.957357691943871\n",
      "Ended iteration 1100  Cost:  0.05737763005749524  Validation cost:  1.965620544823425\n",
      "Ended iteration 1150  Cost:  0.05237712108536107  Validation cost:  1.9738643371182378\n",
      "Ended iteration 1200  Cost:  0.04784916748929136  Validation cost:  1.9801860095449364\n",
      "Ended iteration 1250  Cost:  0.043972816283592515  Validation cost:  1.9864892406868946\n",
      "Ended iteration 1300  Cost:  0.040586558227718623  Validation cost:  1.9926737421157374\n",
      "Ended iteration 1350  Cost:  0.037570911591656965  Validation cost:  1.9981205221988132\n",
      "Ended iteration 1400  Cost:  0.03491990409293199  Validation cost:  2.0039449295435854\n",
      "Ended iteration 1450  Cost:  0.03254569353187051  Validation cost:  2.009208022283129\n",
      "Ended iteration 1500  Cost:  0.030420415184729308  Validation cost:  2.014357280694379\n",
      "Ended iteration 1550  Cost:  0.028515043952836442  Validation cost:  2.019312498426056\n",
      "Ended iteration 1600  Cost:  0.02679444490254262  Validation cost:  2.0239174813026817\n",
      "Ended iteration 1650  Cost:  0.025239438825642637  Validation cost:  2.028607899126435\n",
      "Ended iteration 1700  Cost:  0.02382942240983997  Validation cost:  2.032919666809999\n",
      "Ended iteration 1750  Cost:  0.022545813159963776  Validation cost:  2.037221704335182\n",
      "Ended iteration 1800  Cost:  0.021372832826585954  Validation cost:  2.041325451520109\n",
      "Ended iteration 1850  Cost:  0.020300337707385225  Validation cost:  2.0451855527052474\n",
      "Ended iteration 1900  Cost:  0.01931414600944637  Validation cost:  2.0488854056778374\n",
      "Ended iteration 1950  Cost:  0.01840828011763633  Validation cost:  2.0527277240657726\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.298924832887274  Validation cost:  2.3067441677099136\n",
      "Ended iteration 50  Cost:  1.0791688752003026  Validation cost:  1.9750319945369028\n",
      "Ended iteration 100  Cost:  0.8383938439065423  Validation cost:  1.8590279869628419\n",
      "Ended iteration 150  Cost:  0.673149761122482  Validation cost:  1.7834958512877326\n",
      "Ended iteration 200  Cost:  0.5688870234700464  Validation cost:  1.74305289635126\n",
      "Ended iteration 250  Cost:  0.4833645211324388  Validation cost:  1.7156057476811348\n",
      "Ended iteration 300  Cost:  0.41782930360056875  Validation cost:  1.702748382427863\n",
      "Ended iteration 350  Cost:  0.37641854413949205  Validation cost:  1.6895892021769556\n",
      "Ended iteration 400  Cost:  0.29611520119880363  Validation cost:  1.661526091493626\n",
      "Ended iteration 450  Cost:  0.27290047591813665  Validation cost:  1.653669191674165\n",
      "Ended iteration 500  Cost:  0.23313882281814335  Validation cost:  1.6499028740656054\n",
      "Ended iteration 550  Cost:  0.19752017144542247  Validation cost:  1.6532353623705642\n",
      "Ended iteration 600  Cost:  0.15056586738712455  Validation cost:  1.6257665029825723\n",
      "Ended iteration 650  Cost:  0.21984517131349388  Validation cost:  1.652393353423756\n",
      "Ended iteration 700  Cost:  0.11278774225646103  Validation cost:  1.6285235246050234\n",
      "Ended iteration 750  Cost:  0.09814053068761316  Validation cost:  1.630936329301206\n",
      "Ended iteration 800  Cost:  0.0867605410185124  Validation cost:  1.6315380555411758\n",
      "Ended iteration 850  Cost:  0.07622589838786008  Validation cost:  1.6315808930455453\n",
      "Ended iteration 900  Cost:  0.06746879938573519  Validation cost:  1.6308217236263614\n",
      "Ended iteration 950  Cost:  0.06024998375573508  Validation cost:  1.6295234086517685\n",
      "Ended iteration 1000  Cost:  0.05418607070721163  Validation cost:  1.6284323912933767\n",
      "Ended iteration 1050  Cost:  0.049013455704691254  Validation cost:  1.627210754355392\n",
      "Ended iteration 1100  Cost:  0.044565440055176125  Validation cost:  1.626084591441114\n",
      "Ended iteration 1150  Cost:  0.04072459522384202  Validation cost:  1.6251999099177594\n",
      "Ended iteration 1200  Cost:  0.03738270479217814  Validation cost:  1.6245678403969128\n",
      "Ended iteration 1250  Cost:  0.034463227436110716  Validation cost:  1.623994760511061\n",
      "Ended iteration 1300  Cost:  0.031897088029136475  Validation cost:  1.623537118962611\n",
      "Ended iteration 1350  Cost:  0.02963017359535293  Validation cost:  1.6231682046355416\n",
      "Ended iteration 1400  Cost:  0.027615084566955314  Validation cost:  1.6226201182920479\n",
      "Ended iteration 1450  Cost:  0.025819743350566804  Validation cost:  1.6220493131691045\n",
      "Ended iteration 1500  Cost:  0.024212120487016105  Validation cost:  1.6220026011234117\n",
      "Ended iteration 1550  Cost:  0.022765144397360302  Validation cost:  1.6213484012555137\n",
      "Ended iteration 1600  Cost:  0.0214581220524667  Validation cost:  1.621284315177288\n",
      "Ended iteration 1650  Cost:  0.020274352762142605  Validation cost:  1.6211566911823059\n",
      "Ended iteration 1700  Cost:  0.01919714485602369  Validation cost:  1.620944860739676\n",
      "Ended iteration 1750  Cost:  0.018214195621974377  Validation cost:  1.6209553361887452\n",
      "Ended iteration 1800  Cost:  0.017313486414290667  Validation cost:  1.620590661632765\n",
      "Ended iteration 1850  Cost:  0.01648710931440376  Validation cost:  1.6205967240528194\n",
      "Ended iteration 1900  Cost:  0.01572679211711222  Validation cost:  1.620589314450545\n",
      "Ended iteration 1950  Cost:  0.015024885841256837  Validation cost:  1.6207834919812492\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  50  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3109023013159002  Validation cost:  2.306332274787707\n",
      "Ended iteration 50  Cost:  1.0344374557488223  Validation cost:  2.015000663843592\n",
      "Ended iteration 100  Cost:  0.7319716903618574  Validation cost:  1.9756519689920327\n",
      "Ended iteration 150  Cost:  0.6436394106843185  Validation cost:  1.967830907732882\n",
      "Ended iteration 200  Cost:  0.5537291011190079  Validation cost:  1.9636031283907278\n",
      "Ended iteration 250  Cost:  0.4780981269823537  Validation cost:  1.9615978445676352\n",
      "Ended iteration 300  Cost:  0.42008515479226094  Validation cost:  1.9526517752875285\n",
      "Ended iteration 350  Cost:  0.37542032449862506  Validation cost:  1.893104790469006\n",
      "Ended iteration 400  Cost:  0.323761441269635  Validation cost:  1.886850709776694\n",
      "Ended iteration 450  Cost:  0.2921738146663178  Validation cost:  1.8848261602561391\n",
      "Ended iteration 500  Cost:  0.2633868142622431  Validation cost:  1.9039865580175972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 550  Cost:  0.2210748581665382  Validation cost:  1.8879569888874463\n",
      "Ended iteration 600  Cost:  0.20688651731369367  Validation cost:  1.8352735894156076\n",
      "Ended iteration 650  Cost:  0.18060055239713566  Validation cost:  1.836152653121338\n",
      "Ended iteration 700  Cost:  0.15740029728607483  Validation cost:  1.8382645532729334\n",
      "Ended iteration 750  Cost:  0.1876991499776744  Validation cost:  1.8386439690286418\n",
      "Ended iteration 800  Cost:  0.1556908973971127  Validation cost:  1.863695192903362\n",
      "Ended iteration 850  Cost:  0.09171970282067309  Validation cost:  1.854861458704534\n",
      "Ended iteration 900  Cost:  0.08732834654998634  Validation cost:  1.8722255316294945\n",
      "Ended iteration 950  Cost:  0.07310613412769776  Validation cost:  1.8359799478059682\n",
      "Ended iteration 1000  Cost:  0.06504449917381032  Validation cost:  1.852034395348534\n",
      "Ended iteration 1050  Cost:  0.05858342443478149  Validation cost:  1.861032134745804\n",
      "Ended iteration 1100  Cost:  0.0530612035333704  Validation cost:  1.8688421987633304\n",
      "Ended iteration 1150  Cost:  0.04827933658286247  Validation cost:  1.8752018218711037\n",
      "Ended iteration 1200  Cost:  0.04413414245217057  Validation cost:  1.8811623065695906\n",
      "Ended iteration 1250  Cost:  0.040510754612191065  Validation cost:  1.8868495741829332\n",
      "Ended iteration 1300  Cost:  0.037331586253919385  Validation cost:  1.8919203996152194\n",
      "Ended iteration 1350  Cost:  0.03453259270226437  Validation cost:  1.896537832870456\n",
      "Ended iteration 1400  Cost:  0.032056114227524496  Validation cost:  1.9007439416726544\n",
      "Ended iteration 1450  Cost:  0.029847054005134554  Validation cost:  1.9051023527248119\n",
      "Ended iteration 1500  Cost:  0.027882233814681124  Validation cost:  1.9092289469933348\n",
      "Ended iteration 1550  Cost:  0.026115221216199462  Validation cost:  1.9134710192744995\n",
      "Ended iteration 1600  Cost:  0.024522830131327958  Validation cost:  1.9168124225669605\n",
      "Ended iteration 1650  Cost:  0.02308535012332646  Validation cost:  1.9204767369605846\n",
      "Ended iteration 1700  Cost:  0.02178285432068809  Validation cost:  1.9239778483412853\n",
      "Ended iteration 1750  Cost:  0.020598841480247036  Validation cost:  1.9274469794790305\n",
      "Ended iteration 1800  Cost:  0.01952073103331227  Validation cost:  1.930850861991288\n",
      "Ended iteration 1850  Cost:  0.018532631718553086  Validation cost:  1.9336031999806167\n",
      "Ended iteration 1900  Cost:  0.01762629335667335  Validation cost:  1.9367620101487604\n",
      "Ended iteration 1950  Cost:  0.01679416859067445  Validation cost:  1.9399861255403248\n",
      "======================Third model trained=====================\n",
      "First model  leaky_relu validation cost:  2.0559434952028455  acc_train: 0.2643   acc_validation: 0.2574 \n",
      "Second model   leaky_relu validation cost:  1.6207787522197599  acc_train:0.4255   acc_validation: 0.4207 \n",
      "Third model  leaky_relu validation cost:  1.942812291212975  acc_train:0.2652   acc_validation: 0.2578 \n",
      "Average validation loss:  1.8731781795451934  Average validation accuracy:  0.31197222222222226\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "activation = \"leaky_relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing hidden layer size\n",
    "Now we will experiment changing the amount of neurons on the hidden layer and see the impact on different activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1_neurons = 100\n",
    "epochs = 2000\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3075846360878094  Validation cost:  2.30166912236039\n",
      "Ended iteration 50  Cost:  2.0267707646786883  Validation cost:  2.0328058382214964\n",
      "Ended iteration 100  Cost:  1.6260374943217202  Validation cost:  1.6394500177382314\n",
      "Ended iteration 150  Cost:  1.3668992618600615  Validation cost:  1.3814861675491574\n",
      "Ended iteration 200  Cost:  1.2118115674610441  Validation cost:  1.2254510768741862\n",
      "Ended iteration 250  Cost:  1.1039309143059788  Validation cost:  1.117058627982523\n",
      "Ended iteration 300  Cost:  1.0213709305604552  Validation cost:  1.0349520143313642\n",
      "Ended iteration 350  Cost:  0.9557367847952559  Validation cost:  0.9709088444869152\n",
      "Ended iteration 400  Cost:  0.9026429214323518  Validation cost:  0.9205562116641143\n",
      "Ended iteration 450  Cost:  0.8593947219558076  Validation cost:  0.8808794202834821\n",
      "Ended iteration 500  Cost:  0.8244829578490879  Validation cost:  0.849782160821395\n",
      "Ended iteration 550  Cost:  0.7966894535672103  Validation cost:  0.8257016476092509\n",
      "Ended iteration 600  Cost:  0.7745837224058191  Validation cost:  0.8072289120194067\n",
      "Ended iteration 650  Cost:  0.7568353902489009  Validation cost:  0.7931116639661826\n",
      "Ended iteration 700  Cost:  0.7424540567450176  Validation cost:  0.7823607132101583\n",
      "Ended iteration 750  Cost:  0.7307775530161149  Validation cost:  0.7742621918242961\n",
      "Ended iteration 800  Cost:  0.7213913196081007  Validation cost:  0.768341181880434\n",
      "Ended iteration 850  Cost:  0.7140408084050393  Validation cost:  0.764315822953777\n",
      "Ended iteration 900  Cost:  0.7085405278120985  Validation cost:  0.7620379836647968\n",
      "Ended iteration 950  Cost:  0.7047020188488515  Validation cost:  0.7614202347617709\n",
      "Ended iteration 1000  Cost:  0.702314802340494  Validation cost:  0.7623833581321813\n",
      "Ended iteration 1050  Cost:  0.7011940876302432  Validation cost:  0.7648621891077634\n",
      "Ended iteration 1100  Cost:  0.7012887866743092  Validation cost:  0.7688693526192463\n",
      "Ended iteration 1150  Cost:  0.7027721245877172  Validation cost:  0.7745523120987897\n",
      "Ended iteration 1200  Cost:  0.7059021706177191  Validation cost:  0.7820952639069632\n",
      "Ended iteration 1250  Cost:  0.7106186138641105  Validation cost:  0.7913988264400363\n",
      "Ended iteration 1300  Cost:  0.716278618073738  Validation cost:  0.8018161345880308\n",
      "Ended iteration 1350  Cost:  0.7218198529934337  Validation cost:  0.8122704195107182\n",
      "Ended iteration 1400  Cost:  0.7261631405685113  Validation cost:  0.8216327127233223\n",
      "Ended iteration 1450  Cost:  0.7285556511801429  Validation cost:  0.829069983271997\n",
      "Ended iteration 1500  Cost:  0.7287105039246565  Validation cost:  0.8342233999160776\n",
      "Ended iteration 1550  Cost:  0.72678173224829  Validation cost:  0.8371893241302638\n",
      "Ended iteration 1600  Cost:  0.7232575842042063  Validation cost:  0.8383735277812334\n",
      "Ended iteration 1650  Cost:  0.7187565108692179  Validation cost:  0.8383151959883374\n",
      "Ended iteration 1700  Cost:  0.7137709124871937  Validation cost:  0.8375196223509634\n",
      "Ended iteration 1750  Cost:  0.7085860856151078  Validation cost:  0.836327401463599\n",
      "Ended iteration 1800  Cost:  0.7033385805939747  Validation cost:  0.8348773896596493\n",
      "Ended iteration 1850  Cost:  0.698047556477492  Validation cost:  0.8331716741537201\n",
      "Ended iteration 1900  Cost:  0.6926792833231796  Validation cost:  0.8311886879832229\n",
      "Ended iteration 1950  Cost:  0.6872579960835203  Validation cost:  0.828979544637682\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3237884731837837  Validation cost:  2.310785426018909\n",
      "Ended iteration 50  Cost:  2.0333220315763225  Validation cost:  2.065450445688119\n",
      "Ended iteration 100  Cost:  1.6124002105321715  Validation cost:  1.6586239631248951\n",
      "Ended iteration 150  Cost:  1.342336964678849  Validation cost:  1.3943265106509206\n",
      "Ended iteration 200  Cost:  1.1799818312584556  Validation cost:  1.2320247362139296\n",
      "Ended iteration 250  Cost:  1.0625483009429137  Validation cost:  1.1144056347808127\n",
      "Ended iteration 300  Cost:  0.971698825623047  Validation cost:  1.024664406190998\n",
      "Ended iteration 350  Cost:  0.9007048966609068  Validation cost:  0.9561437432026151\n",
      "Ended iteration 400  Cost:  0.8456070603689477  Validation cost:  0.904425689328617\n",
      "Ended iteration 450  Cost:  0.8030036725362075  Validation cost:  0.8657057477748876\n",
      "Ended iteration 500  Cost:  0.7697421528280173  Validation cost:  0.8366141570555543\n",
      "Ended iteration 550  Cost:  0.7433235469248823  Validation cost:  0.8145074638643595\n",
      "Ended iteration 600  Cost:  0.7220232556766699  Validation cost:  0.7975360347505212\n",
      "Ended iteration 650  Cost:  0.7047193850627739  Validation cost:  0.7844766186173784\n",
      "Ended iteration 700  Cost:  0.6906555209645793  Validation cost:  0.7745046155424291\n",
      "Ended iteration 750  Cost:  0.6792954113121821  Validation cost:  0.767033151602645\n",
      "Ended iteration 800  Cost:  0.6702873551591805  Validation cost:  0.7616337628006581\n",
      "Ended iteration 850  Cost:  0.663421848459878  Validation cost:  0.7579802866249326\n",
      "Ended iteration 900  Cost:  0.6585527442188505  Validation cost:  0.7558082272749239\n",
      "Ended iteration 950  Cost:  0.6555174741970348  Validation cost:  0.754894759938671\n",
      "Ended iteration 1000  Cost:  0.6540932343270203  Validation cost:  0.7550573249203684\n",
      "Ended iteration 1050  Cost:  0.654015663034988  Validation cost:  0.7561710994761506\n",
      "Ended iteration 1100  Cost:  0.6550384829456904  Validation cost:  0.7581783168388647\n",
      "Ended iteration 1150  Cost:  0.6569594211401308  Validation cost:  0.761042305120434\n",
      "Ended iteration 1200  Cost:  0.6595554772534595  Validation cost:  0.7646473800846596\n",
      "Ended iteration 1250  Cost:  0.6624720966835507  Validation cost:  0.7687341483715994\n",
      "Ended iteration 1300  Cost:  0.6652384163596128  Validation cost:  0.7729729523915712\n",
      "Ended iteration 1350  Cost:  0.6677040672890785  Validation cost:  0.777145260125196\n",
      "Ended iteration 1400  Cost:  0.6704594316478818  Validation cost:  0.7811432368561682\n",
      "Ended iteration 1450  Cost:  0.6737512445315768  Validation cost:  0.7847078189809887\n",
      "Ended iteration 1500  Cost:  0.6769649290568797  Validation cost:  0.7876030475745617\n",
      "Ended iteration 1550  Cost:  0.6795848858451744  Validation cost:  0.789934645484133\n",
      "Ended iteration 1600  Cost:  0.6817261204975972  Validation cost:  0.7921201602853548\n",
      "Ended iteration 1650  Cost:  0.6840449419416875  Validation cost:  0.794633892888102\n",
      "Ended iteration 1700  Cost:  0.6870982692361857  Validation cost:  0.7977012720284752\n",
      "Ended iteration 1750  Cost:  0.6909644056823315  Validation cost:  0.8012890127072985\n",
      "Ended iteration 1800  Cost:  0.6954819983034282  Validation cost:  0.8053912357724582\n",
      "Ended iteration 1850  Cost:  0.7003894307710583  Validation cost:  0.8101123338234326\n",
      "Ended iteration 1900  Cost:  0.70541127831125  Validation cost:  0.8155203631975255\n",
      "Ended iteration 1950  Cost:  0.7103552044586269  Validation cost:  0.8216107781831373\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3073392564010304  Validation cost:  2.3058822747778533\n",
      "Ended iteration 50  Cost:  2.0197741311555553  Validation cost:  2.026047403008659\n",
      "Ended iteration 100  Cost:  1.5759983407449267  Validation cost:  1.5938162380765593\n",
      "Ended iteration 150  Cost:  1.3027782721490377  Validation cost:  1.3310039344102034\n",
      "Ended iteration 200  Cost:  1.1362649706943555  Validation cost:  1.174661489922221\n",
      "Ended iteration 250  Cost:  1.0175666847348281  Validation cost:  1.0662641582934769\n",
      "Ended iteration 300  Cost:  0.9278803012818002  Validation cost:  0.9862051654490884\n",
      "Ended iteration 350  Cost:  0.8597962843085823  Validation cost:  0.9266257778895856\n",
      "Ended iteration 400  Cost:  0.8082588128321783  Validation cost:  0.8825427220144737\n",
      "Ended iteration 450  Cost:  0.7690229746362712  Validation cost:  0.8498964587878909\n",
      "Ended iteration 500  Cost:  0.7386952602578748  Validation cost:  0.8253979305554006\n",
      "Ended iteration 550  Cost:  0.7146853761827756  Validation cost:  0.8065356988393476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 600  Cost:  0.6951197636222699  Validation cost:  0.7915350376262178\n",
      "Ended iteration 650  Cost:  0.6787017179992102  Validation cost:  0.7792206987458926\n",
      "Ended iteration 700  Cost:  0.6645501059825832  Validation cost:  0.7688406604169998\n",
      "Ended iteration 750  Cost:  0.6520700624699882  Validation cost:  0.7599146674502072\n",
      "Ended iteration 800  Cost:  0.6408594229418599  Validation cost:  0.7521261811847595\n",
      "Ended iteration 850  Cost:  0.63064139888207  Validation cost:  0.745253457771234\n",
      "Ended iteration 900  Cost:  0.621220314263828  Validation cost:  0.7391307510350252\n",
      "Ended iteration 950  Cost:  0.6124567509479087  Validation cost:  0.7336303420924526\n",
      "Ended iteration 1000  Cost:  0.6042519861535273  Validation cost:  0.7286551900572344\n",
      "Ended iteration 1050  Cost:  0.5965339063048809  Validation cost:  0.724132883537785\n",
      "Ended iteration 1100  Cost:  0.589252432980419  Validation cost:  0.7200097684148276\n",
      "Ended iteration 1150  Cost:  0.5824008654522654  Validation cost:  0.7162558059855479\n",
      "Ended iteration 1200  Cost:  0.5760678358866436  Validation cost:  0.7128924373975499\n",
      "Ended iteration 1250  Cost:  0.5704847156279843  Validation cost:  0.7100290041253493\n",
      "Ended iteration 1300  Cost:  0.5659584761538995  Validation cost:  0.7078346338405245\n",
      "Ended iteration 1350  Cost:  0.5626713568012078  Validation cost:  0.7064170034236416\n",
      "Ended iteration 1400  Cost:  0.5605901206835172  Validation cost:  0.7057557429668067\n",
      "Ended iteration 1450  Cost:  0.5595713756390374  Validation cost:  0.7057613282087369\n",
      "Ended iteration 1500  Cost:  0.5594759310572858  Validation cost:  0.7063472611589832\n",
      "Ended iteration 1550  Cost:  0.5602079223649395  Validation cost:  0.7074575380021841\n",
      "Ended iteration 1600  Cost:  0.5617145759924924  Validation cost:  0.7090717467843015\n",
      "Ended iteration 1650  Cost:  0.5639812547120048  Validation cost:  0.7112100550946721\n",
      "Ended iteration 1700  Cost:  0.5670400860904795  Validation cost:  0.713943977570656\n",
      "Ended iteration 1750  Cost:  0.570998587585657  Validation cost:  0.7174099123735931\n",
      "Ended iteration 1800  Cost:  0.5760736420683341  Validation cost:  0.7218188688097037\n",
      "Ended iteration 1850  Cost:  0.5826012753091071  Validation cost:  0.7274494694658005\n",
      "Ended iteration 1900  Cost:  0.5909674140954498  Validation cost:  0.734591971566367\n",
      "Ended iteration 1950  Cost:  0.601437240299668  Validation cost:  0.7434294928398746\n",
      "======================Third model trained=====================\n",
      "First model  sigmoid validation cost:  0.8267170488853927  acc_train: 0.7141   acc_validation: 0.7077 \n",
      "Second model   sigmoid validation cost:  0.8280578051583898  acc_train:0.7265   acc_validation: 0.7217 \n",
      "Third model  sigmoid validation cost:  0.7536917155965238  acc_train:0.7341   acc_validation: 0.7306 \n",
      "Average validation loss:  0.8028221898801021  Average validation accuracy:  0.7199722222222222\n"
     ]
    }
   ],
   "source": [
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.31402656905383  Validation cost:  2.2964020686328404\n",
      "Ended iteration 50  Cost:  1.070137640987048  Validation cost:  1.6904258337124654\n",
      "Ended iteration 100  Cost:  0.752082822021523  Validation cost:  1.5000885217389575\n",
      "Ended iteration 150  Cost:  0.6084849469856618  Validation cost:  1.4437978529024849\n",
      "Ended iteration 200  Cost:  0.5103456280006297  Validation cost:  1.4234569545373597\n",
      "Ended iteration 250  Cost:  0.436823462858009  Validation cost:  1.413487899663024\n",
      "Ended iteration 300  Cost:  0.3787286451556218  Validation cost:  1.4062283869430157\n",
      "Ended iteration 350  Cost:  0.3307037871949107  Validation cost:  1.3992621463342338\n",
      "Ended iteration 400  Cost:  0.3298164172975005  Validation cost:  1.3889777930032938\n",
      "Ended iteration 450  Cost:  0.2881774430799724  Validation cost:  1.366435786221274\n",
      "Ended iteration 500  Cost:  0.2540882189443649  Validation cost:  1.3149230069246796\n",
      "Ended iteration 550  Cost:  0.23599529196737593  Validation cost:  1.294343765095471\n",
      "Ended iteration 600  Cost:  0.21041266298518835  Validation cost:  1.2720121675479483\n",
      "Ended iteration 650  Cost:  0.22500185023276753  Validation cost:  1.247399200908089\n",
      "Ended iteration 700  Cost:  0.17841930614894072  Validation cost:  1.2496300679493346\n",
      "Ended iteration 750  Cost:  0.17309656222613048  Validation cost:  1.230618718147905\n",
      "Ended iteration 800  Cost:  0.15815863455426424  Validation cost:  1.2169450735831844\n",
      "Ended iteration 850  Cost:  0.14562349994621526  Validation cost:  1.201693092117048\n",
      "Ended iteration 900  Cost:  0.12945575355148667  Validation cost:  1.1866399371015333\n",
      "Ended iteration 950  Cost:  0.12478077358093567  Validation cost:  1.1778067427794852\n",
      "Ended iteration 1000  Cost:  0.11170973784700995  Validation cost:  1.165338616780746\n",
      "Ended iteration 1050  Cost:  0.10463661875957155  Validation cost:  1.126460573261386\n",
      "Ended iteration 1100  Cost:  0.08318546091527843  Validation cost:  1.128920024343231\n",
      "Ended iteration 1150  Cost:  0.07546191011442555  Validation cost:  1.123270362466971\n",
      "Ended iteration 1200  Cost:  0.06874573213773362  Validation cost:  1.1181948032748694\n",
      "Ended iteration 1250  Cost:  0.06285462620008977  Validation cost:  1.1136187555638046\n",
      "Ended iteration 1300  Cost:  0.057670557676310436  Validation cost:  1.109421548123407\n",
      "Ended iteration 1350  Cost:  0.053095068097794205  Validation cost:  1.1055721308789281\n",
      "Ended iteration 1400  Cost:  0.04905667988213901  Validation cost:  1.1022039949501907\n",
      "Ended iteration 1450  Cost:  0.045467985859403426  Validation cost:  1.0991179119517267\n",
      "Ended iteration 1500  Cost:  0.0422581542753278  Validation cost:  1.0962345143607415\n",
      "Ended iteration 1550  Cost:  0.03938739869828101  Validation cost:  1.093585977986137\n",
      "Ended iteration 1600  Cost:  0.036810233650095704  Validation cost:  1.091155412254245\n",
      "Ended iteration 1650  Cost:  0.034491483721562306  Validation cost:  1.0889165893971469\n",
      "Ended iteration 1700  Cost:  0.03239744695680515  Validation cost:  1.0868482559261812\n",
      "Ended iteration 1750  Cost:  0.03050092897554241  Validation cost:  1.0849341862301471\n",
      "Ended iteration 1800  Cost:  0.028779115969070852  Validation cost:  1.083160657025389\n",
      "Ended iteration 1850  Cost:  0.027209760669527405  Validation cost:  1.0815158862075727\n",
      "Ended iteration 1900  Cost:  0.025775858469070573  Validation cost:  1.0799873748915425\n",
      "Ended iteration 1950  Cost:  0.02446198921193607  Validation cost:  1.0785649028655107\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3350416098762823  Validation cost:  2.3103378696481474\n",
      "Ended iteration 50  Cost:  1.0040292316214892  Validation cost:  1.682372150883677\n",
      "Ended iteration 100  Cost:  0.6902781174399301  Validation cost:  1.5160841610697244\n",
      "Ended iteration 150  Cost:  0.5660169242117321  Validation cost:  1.4816758688993226\n",
      "Ended iteration 200  Cost:  0.4839054707015877  Validation cost:  1.4768541823120802\n",
      "Ended iteration 250  Cost:  0.4185945668332834  Validation cost:  1.481559691052956\n",
      "Ended iteration 300  Cost:  0.36379344274976394  Validation cost:  1.4899473512413877\n",
      "Ended iteration 350  Cost:  0.31737541791621393  Validation cost:  1.4996933691417254\n",
      "Ended iteration 400  Cost:  0.2777926409977294  Validation cost:  1.5095426420598281\n",
      "Ended iteration 450  Cost:  0.2443504805928031  Validation cost:  1.5205375757204196\n",
      "Ended iteration 500  Cost:  0.24783458229857758  Validation cost:  1.5265430333141548\n",
      "Ended iteration 550  Cost:  0.21976225854939746  Validation cost:  1.51504695867171\n",
      "Ended iteration 600  Cost:  0.19749541317009509  Validation cost:  1.5065962160729836\n",
      "Ended iteration 650  Cost:  0.17786220952281193  Validation cost:  1.499736260107689\n",
      "Ended iteration 700  Cost:  0.15953356446868217  Validation cost:  1.4938678888934562\n",
      "Ended iteration 750  Cost:  0.14227346012590744  Validation cost:  1.4888894904292955\n",
      "Ended iteration 800  Cost:  0.1265946308397417  Validation cost:  1.484413312714605\n",
      "Ended iteration 850  Cost:  0.11869643555934273  Validation cost:  1.4788743635374686\n",
      "Ended iteration 900  Cost:  0.10068241050903733  Validation cost:  1.4687051747350521\n",
      "Ended iteration 950  Cost:  0.0904044485537819  Validation cost:  1.467620833443875\n",
      "Ended iteration 1000  Cost:  0.09494877932830215  Validation cost:  1.4611671497275291\n",
      "Ended iteration 1050  Cost:  0.07656470747318796  Validation cost:  1.4512347895768076\n",
      "Ended iteration 1100  Cost:  0.06934910228280544  Validation cost:  1.453719748425706\n",
      "Ended iteration 1150  Cost:  0.063105564427561  Validation cost:  1.456226995556796\n",
      "Ended iteration 1200  Cost:  0.05761995011843505  Validation cost:  1.4586823710955157\n",
      "Ended iteration 1250  Cost:  0.05276582939241804  Validation cost:  1.4610560281764298\n",
      "Ended iteration 1300  Cost:  0.04845316353975619  Validation cost:  1.4632905633410451\n",
      "Ended iteration 1350  Cost:  0.04461701264829077  Validation cost:  1.465364108860496\n",
      "Ended iteration 1400  Cost:  0.04119611064008247  Validation cost:  1.4672696857118104\n",
      "Ended iteration 1450  Cost:  0.03816936998821703  Validation cost:  1.4690426399688732\n",
      "Ended iteration 1500  Cost:  0.035469747939154236  Validation cost:  1.4706791335946874\n",
      "Ended iteration 1550  Cost:  0.03304956313609393  Validation cost:  1.4721798469760319\n",
      "Ended iteration 1600  Cost:  0.03088072969994656  Validation cost:  1.4735558495394003\n",
      "Ended iteration 1650  Cost:  0.028931589274279183  Validation cost:  1.4748289091895155\n",
      "Ended iteration 1700  Cost:  0.02717490406069443  Validation cost:  1.4760137069845607\n",
      "Ended iteration 1750  Cost:  0.025583747086019126  Validation cost:  1.4771267279546219\n",
      "Ended iteration 1800  Cost:  0.02413723552089793  Validation cost:  1.4781724471791564\n",
      "Ended iteration 1850  Cost:  0.022820848878140544  Validation cost:  1.4791562889941197\n",
      "Ended iteration 1900  Cost:  0.02162025585729155  Validation cost:  1.4800902998062992\n",
      "Ended iteration 1950  Cost:  0.020522465421203624  Validation cost:  1.480979702293999\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3187689410335066  Validation cost:  2.2986676192533064\n",
      "Ended iteration 50  Cost:  1.0384628763640364  Validation cost:  1.666201150984481\n",
      "Ended iteration 100  Cost:  0.7329967422311634  Validation cost:  1.4918528805108902\n",
      "Ended iteration 150  Cost:  0.5951712581529189  Validation cost:  1.4463858243204601\n",
      "Ended iteration 200  Cost:  0.5004970216770327  Validation cost:  1.4319218439605643\n",
      "Ended iteration 250  Cost:  0.42698819100434043  Validation cost:  1.4226999075446798\n",
      "Ended iteration 300  Cost:  0.36753281750005945  Validation cost:  1.4140633841039008\n",
      "Ended iteration 350  Cost:  0.34955857720091227  Validation cost:  1.3774168071606643\n",
      "Ended iteration 400  Cost:  0.3087733796956351  Validation cost:  1.3461907043204728\n",
      "Ended iteration 450  Cost:  0.2764918484814909  Validation cost:  1.3171818019050856\n",
      "Ended iteration 500  Cost:  0.2568903666179208  Validation cost:  1.2836506388732827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 550  Cost:  0.23887321216331306  Validation cost:  1.2692129140654962\n",
      "Ended iteration 600  Cost:  0.2100780713875348  Validation cost:  1.2446365185396675\n",
      "Ended iteration 650  Cost:  0.19405603951345957  Validation cost:  1.2067534256930832\n",
      "Ended iteration 700  Cost:  0.16989987122544836  Validation cost:  1.1828971867625815\n",
      "Ended iteration 750  Cost:  0.24802423503125492  Validation cost:  1.1989749381013757\n",
      "Ended iteration 800  Cost:  0.137725706886031  Validation cost:  1.1667894581703755\n",
      "Ended iteration 850  Cost:  0.13418805705939207  Validation cost:  1.1386395886656777\n",
      "Ended iteration 900  Cost:  0.1150490277989385  Validation cost:  1.1299986444516643\n",
      "Ended iteration 950  Cost:  0.1954508924312723  Validation cost:  1.1456096466855739\n",
      "Ended iteration 1000  Cost:  0.09761054720857548  Validation cost:  1.1042954055812313\n",
      "Ended iteration 1050  Cost:  0.19208623484221105  Validation cost:  1.100527385936976\n",
      "Ended iteration 1100  Cost:  0.08687881441473093  Validation cost:  1.0939069783285005\n",
      "Ended iteration 1150  Cost:  0.0768091091527489  Validation cost:  1.0881510290099596\n",
      "Ended iteration 1200  Cost:  0.07481896758378333  Validation cost:  1.0904559325810628\n",
      "Ended iteration 1250  Cost:  0.17679095667586628  Validation cost:  1.051911281723091\n",
      "Ended iteration 1300  Cost:  0.06491027395033162  Validation cost:  1.057448760426794\n",
      "Ended iteration 1350  Cost:  0.058653998233848745  Validation cost:  1.055257445419831\n",
      "Ended iteration 1400  Cost:  0.05341352876403941  Validation cost:  1.053681793462938\n",
      "Ended iteration 1450  Cost:  0.04889736958553447  Validation cost:  1.0525028565686714\n",
      "Ended iteration 1500  Cost:  0.04495876201091866  Validation cost:  1.0516166332676207\n",
      "Ended iteration 1550  Cost:  0.04148978015094138  Validation cost:  1.0509506917086644\n",
      "Ended iteration 1600  Cost:  0.03842080753425328  Validation cost:  1.0504515570256718\n",
      "Ended iteration 1650  Cost:  0.03569457965093104  Validation cost:  1.050076029186014\n",
      "Ended iteration 1700  Cost:  0.03326301458317159  Validation cost:  1.049803917735266\n",
      "Ended iteration 1750  Cost:  0.031089153007344824  Validation cost:  1.049615886377049\n",
      "Ended iteration 1800  Cost:  0.029135136196478614  Validation cost:  1.0495044456542588\n",
      "Ended iteration 1850  Cost:  0.027372296541476177  Validation cost:  1.0494594780111726\n",
      "Ended iteration 1900  Cost:  0.02577719397463796  Validation cost:  1.0494663924612193\n",
      "Ended iteration 1950  Cost:  0.02432911344141366  Validation cost:  1.0495156888786201\n",
      "======================Third model trained=====================\n",
      "First model  relu validation cost:  1.0772656224216925  acc_train: 0.5814   acc_validation: 0.5823 \n",
      "Second model   relu validation cost:  1.481813492525213  acc_train:0.4029   acc_validation: 0.4002 \n",
      "Third model  relu validation cost:  1.049603557381297  acc_train:0.5796   acc_validation: 0.5740 \n",
      "Average validation loss:  1.202894224109401  Average validation accuracy:  0.5188333333333334\n"
     ]
    }
   ],
   "source": [
    "activation = \"relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Leaky Relu.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.2802938851389927  Validation cost:  2.3179310101475283\n",
      "Ended iteration 50  Cost:  0.9355064264957242  Validation cost:  1.8997123034784462\n",
      "Ended iteration 100  Cost:  0.6990077051114352  Validation cost:  1.8037354016280653\n",
      "Ended iteration 150  Cost:  0.6051762776325995  Validation cost:  1.7579096597279347\n",
      "Ended iteration 200  Cost:  0.529707563087128  Validation cost:  1.7428700666579964\n",
      "Ended iteration 250  Cost:  0.46718578987986104  Validation cost:  1.7256272278055513\n",
      "Ended iteration 300  Cost:  0.4329180291428354  Validation cost:  1.7167262797694522\n",
      "Ended iteration 350  Cost:  0.376384508786149  Validation cost:  1.707025289799464\n",
      "Ended iteration 400  Cost:  0.34623087549452075  Validation cost:  1.6909719012096693\n",
      "Ended iteration 450  Cost:  0.30913387479308535  Validation cost:  1.6791930290868688\n",
      "Ended iteration 500  Cost:  0.27730891105293154  Validation cost:  1.647231306600821\n",
      "Ended iteration 550  Cost:  0.2553557396957974  Validation cost:  1.6401500538744758\n",
      "Ended iteration 600  Cost:  0.25130771628372844  Validation cost:  1.6557463503118428\n",
      "Ended iteration 650  Cost:  0.20156734142204472  Validation cost:  1.6359588264146803\n",
      "Ended iteration 700  Cost:  0.20373768638196282  Validation cost:  1.6074016587766624\n",
      "Ended iteration 750  Cost:  0.1621575451148129  Validation cost:  1.6112614939901753\n",
      "Ended iteration 800  Cost:  0.15441475860316725  Validation cost:  1.6112806993843733\n",
      "Ended iteration 850  Cost:  0.13636327565023218  Validation cost:  1.614185254970834\n",
      "Ended iteration 900  Cost:  0.12969260535207278  Validation cost:  1.622976989083501\n",
      "Ended iteration 950  Cost:  0.10165989664408932  Validation cost:  1.5968725385497655\n",
      "Ended iteration 1000  Cost:  0.13597216238032211  Validation cost:  1.5887280370205354\n",
      "Ended iteration 1050  Cost:  0.08171094115764986  Validation cost:  1.603939927380582\n",
      "Ended iteration 1100  Cost:  0.0749486302690748  Validation cost:  1.6034631015510337\n",
      "Ended iteration 1150  Cost:  0.06791640035774293  Validation cost:  1.6044866652385872\n",
      "Ended iteration 1200  Cost:  0.06101000891637746  Validation cost:  1.6043921947082793\n",
      "Ended iteration 1250  Cost:  0.055665308754748025  Validation cost:  1.6020791959751295\n",
      "Ended iteration 1300  Cost:  0.05110817964744196  Validation cost:  1.6006272169039524\n",
      "Ended iteration 1350  Cost:  0.047082449821590884  Validation cost:  1.59929911190861\n",
      "Ended iteration 1400  Cost:  0.04349780330814285  Validation cost:  1.5977422459271835\n",
      "Ended iteration 1450  Cost:  0.0403276035632821  Validation cost:  1.5966521488590024\n",
      "Ended iteration 1500  Cost:  0.037501208292865254  Validation cost:  1.5958496742479116\n",
      "Ended iteration 1550  Cost:  0.03496469484497806  Validation cost:  1.5947742701980294\n",
      "Ended iteration 1600  Cost:  0.03268737182756023  Validation cost:  1.59401210481095\n",
      "Ended iteration 1650  Cost:  0.030644426866144183  Validation cost:  1.5933833930529813\n",
      "Ended iteration 1700  Cost:  0.028792340277733263  Validation cost:  1.5931440222482143\n",
      "Ended iteration 1750  Cost:  0.027117289371408854  Validation cost:  1.5925260906931036\n",
      "Ended iteration 1800  Cost:  0.02559463765320545  Validation cost:  1.592280114509175\n",
      "Ended iteration 1850  Cost:  0.024206449773914812  Validation cost:  1.5919273607675541\n",
      "Ended iteration 1900  Cost:  0.02293856201028187  Validation cost:  1.591781464534003\n",
      "Ended iteration 1950  Cost:  0.021777624436319303  Validation cost:  1.5916371371721618\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.287288963875032  Validation cost:  2.3031415568325984\n",
      "Ended iteration 50  Cost:  1.0017793511057607  Validation cost:  1.9020499843465737\n",
      "Ended iteration 100  Cost:  0.7328827747465753  Validation cost:  1.794688482265\n",
      "Ended iteration 150  Cost:  0.6318120375494907  Validation cost:  1.7473808645201896\n",
      "Ended iteration 200  Cost:  0.5376249859105572  Validation cost:  1.734386992151992\n",
      "Ended iteration 250  Cost:  0.4804469805621399  Validation cost:  1.7332773375876547\n",
      "Ended iteration 300  Cost:  0.4336232674602176  Validation cost:  1.6929431821270242\n",
      "Ended iteration 350  Cost:  0.352591486787106  Validation cost:  1.6711354529266909\n",
      "Ended iteration 400  Cost:  0.3193822450098901  Validation cost:  1.677438051524275\n",
      "Ended iteration 450  Cost:  0.27918570512003943  Validation cost:  1.6731823084264037\n",
      "Ended iteration 500  Cost:  0.26272719078853835  Validation cost:  1.6403057790655378\n",
      "Ended iteration 550  Cost:  0.22026033939785122  Validation cost:  1.621360891428474\n",
      "Ended iteration 600  Cost:  0.23467093657146387  Validation cost:  1.6506333265822377\n",
      "Ended iteration 650  Cost:  0.17314902289611978  Validation cost:  1.6192578148609842\n",
      "Ended iteration 700  Cost:  0.1514959133454991  Validation cost:  1.6185561678113876\n",
      "Ended iteration 750  Cost:  0.12675760901550048  Validation cost:  1.6186413811102223\n",
      "Ended iteration 800  Cost:  0.11153673507434263  Validation cost:  1.605219379427747\n",
      "Ended iteration 850  Cost:  0.14489840945395263  Validation cost:  1.54099897569115\n",
      "Ended iteration 900  Cost:  0.08680072383469259  Validation cost:  1.5967422421386814\n",
      "Ended iteration 950  Cost:  0.08027621760317404  Validation cost:  1.6000841871470857\n",
      "Ended iteration 1000  Cost:  0.07723440508918705  Validation cost:  1.5998468202122267\n",
      "Ended iteration 1050  Cost:  0.06508640760068135  Validation cost:  1.599768884979936\n",
      "Ended iteration 1100  Cost:  0.05932836493919188  Validation cost:  1.6008063475883434\n",
      "Ended iteration 1150  Cost:  0.054008237269613686  Validation cost:  1.6018916945593848\n",
      "Ended iteration 1200  Cost:  0.04947738800153792  Validation cost:  1.6024791399373923\n",
      "Ended iteration 1250  Cost:  0.04547135212371079  Validation cost:  1.603745038555599\n",
      "Ended iteration 1300  Cost:  0.041962855343932556  Validation cost:  1.6045888425670891\n",
      "Ended iteration 1350  Cost:  0.03882527652625091  Validation cost:  1.6052156268795812\n",
      "Ended iteration 1400  Cost:  0.036042250466472144  Validation cost:  1.606676117561739\n",
      "Ended iteration 1450  Cost:  0.03354766092715916  Validation cost:  1.6079868082919155\n",
      "Ended iteration 1500  Cost:  0.03132307132659989  Validation cost:  1.6089964299605557\n",
      "Ended iteration 1550  Cost:  0.029302137743467186  Validation cost:  1.6099139948382972\n",
      "Ended iteration 1600  Cost:  0.02748609306826746  Validation cost:  1.6113568911433294\n",
      "Ended iteration 1650  Cost:  0.025841096598286997  Validation cost:  1.6113702214764496\n",
      "Ended iteration 1700  Cost:  0.02435788569265733  Validation cost:  1.6133097384063328\n",
      "Ended iteration 1750  Cost:  0.022992239242922784  Validation cost:  1.6145882990588336\n",
      "Ended iteration 1800  Cost:  0.021758428766009207  Validation cost:  1.6158918740292108\n",
      "Ended iteration 1850  Cost:  0.020627609881931575  Validation cost:  1.616619074724\n",
      "Ended iteration 1900  Cost:  0.019590259902417338  Validation cost:  1.617699360727529\n",
      "Ended iteration 1950  Cost:  0.018633512340003367  Validation cost:  1.6196671583421316\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  100  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3104809655693628  Validation cost:  2.3197813412981088\n",
      "Ended iteration 50  Cost:  0.9512738198808589  Validation cost:  1.9110781067903118\n",
      "Ended iteration 100  Cost:  0.7352997915693461  Validation cost:  1.812461585247152\n",
      "Ended iteration 150  Cost:  0.588064693428429  Validation cost:  1.7646664341322071\n",
      "Ended iteration 200  Cost:  0.4875165586471606  Validation cost:  1.7323746452078619\n",
      "Ended iteration 250  Cost:  0.4090773109891244  Validation cost:  1.70750107401327\n",
      "Ended iteration 300  Cost:  0.372074628687936  Validation cost:  1.7193210198135875\n",
      "Ended iteration 350  Cost:  0.3181103085898554  Validation cost:  1.6768731966269637\n",
      "Ended iteration 400  Cost:  0.2588313681061602  Validation cost:  1.659696844163891\n",
      "Ended iteration 450  Cost:  0.24038564003079194  Validation cost:  1.6412906241000877\n",
      "Ended iteration 500  Cost:  0.2063296571524396  Validation cost:  1.6492813208821069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 550  Cost:  0.21732342620926826  Validation cost:  1.6003572515412376\n",
      "Ended iteration 600  Cost:  0.15160135279062156  Validation cost:  1.622497408234889\n",
      "Ended iteration 650  Cost:  0.13816318951531845  Validation cost:  1.65066362962536\n",
      "Ended iteration 700  Cost:  0.1098576949287344  Validation cost:  1.624615080304567\n",
      "Ended iteration 750  Cost:  0.10335737667237721  Validation cost:  1.6161478758497148\n",
      "Ended iteration 800  Cost:  0.08274725427577341  Validation cost:  1.599358874375777\n",
      "Ended iteration 850  Cost:  0.07262781515317902  Validation cost:  1.6054790296052208\n",
      "Ended iteration 900  Cost:  0.06457756025865008  Validation cost:  1.6040660524992232\n",
      "Ended iteration 950  Cost:  0.05772439141885362  Validation cost:  1.6026961678824918\n",
      "Ended iteration 1000  Cost:  0.0519588564003288  Validation cost:  1.6000716384063272\n",
      "Ended iteration 1050  Cost:  0.04702100555300621  Validation cost:  1.597831744059009\n",
      "Ended iteration 1100  Cost:  0.042786620260297115  Validation cost:  1.5956790003602614\n",
      "Ended iteration 1150  Cost:  0.03912943557776958  Validation cost:  1.592865518746638\n",
      "Ended iteration 1200  Cost:  0.03594720485664345  Validation cost:  1.5911302878962612\n",
      "Ended iteration 1250  Cost:  0.033163809275497  Validation cost:  1.5895946100853977\n",
      "Ended iteration 1300  Cost:  0.030714448301651102  Validation cost:  1.587021910857182\n",
      "Ended iteration 1350  Cost:  0.028546178354537932  Validation cost:  1.5853975217916172\n",
      "Ended iteration 1400  Cost:  0.026617393457813384  Validation cost:  1.583845200390829\n",
      "Ended iteration 1450  Cost:  0.024896297415446612  Validation cost:  1.5824385693263179\n",
      "Ended iteration 1500  Cost:  0.023350541495017432  Validation cost:  1.5813581601776543\n",
      "Ended iteration 1550  Cost:  0.02195943761607785  Validation cost:  1.5802422521139796\n",
      "Ended iteration 1600  Cost:  0.020703757207774703  Validation cost:  1.5789709218088566\n",
      "Ended iteration 1650  Cost:  0.01956503377884237  Validation cost:  1.5780702777481614\n",
      "Ended iteration 1700  Cost:  0.01852909917323027  Validation cost:  1.577274550758424\n",
      "Ended iteration 1750  Cost:  0.017583535881002116  Validation cost:  1.5763174713231376\n",
      "Ended iteration 1800  Cost:  0.016717352975105973  Validation cost:  1.5756063075031603\n",
      "Ended iteration 1850  Cost:  0.01592308721367146  Validation cost:  1.5748457725425684\n",
      "Ended iteration 1900  Cost:  0.01519062120679932  Validation cost:  1.574263114994508\n",
      "Ended iteration 1950  Cost:  0.0145147903689152  Validation cost:  1.5738290905015182\n",
      "======================Third model trained=====================\n",
      "First model  leaky_relu validation cost:  1.5916571294478392  acc_train: 0.4973   acc_validation: 0.4974 \n",
      "Second model   leaky_relu validation cost:  1.62031732955656  acc_train:0.4156   acc_validation: 0.4120 \n",
      "Third model  leaky_relu validation cost:  1.5734955147008511  acc_train:0.3996   acc_validation: 0.3933 \n",
      "Average validation loss:  1.5951566579017502  Average validation accuracy:  0.43425\n"
     ]
    }
   ],
   "source": [
    "activation = \"leaky_relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now 500 neurons\n",
    "Expanding to 500 neurons on the hidden layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1_neurons = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid.500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3034062422651496  Validation cost:  2.283836165931808\n",
      "Ended iteration 50  Cost:  1.4898286081689696  Validation cost:  1.5313818152672172\n",
      "Ended iteration 100  Cost:  1.0858993069291962  Validation cost:  1.1497947197672445\n",
      "Ended iteration 150  Cost:  0.8937476133945215  Validation cost:  0.9722722534266183\n",
      "Ended iteration 200  Cost:  0.781985685464608  Validation cost:  0.8730845707494518\n",
      "Ended iteration 250  Cost:  0.7082765065231559  Validation cost:  0.81110199702847\n",
      "Ended iteration 300  Cost:  0.6551739512600292  Validation cost:  0.7692382897673442\n",
      "Ended iteration 350  Cost:  0.6140956195576965  Validation cost:  0.7390831044020313\n",
      "Ended iteration 400  Cost:  0.5804393697939575  Validation cost:  0.716139895741206\n",
      "Ended iteration 450  Cost:  0.5516066947293081  Validation cost:  0.6978834669603703\n",
      "Ended iteration 500  Cost:  0.5260728546113802  Validation cost:  0.6828423508308997\n",
      "Ended iteration 550  Cost:  0.5029166698818932  Validation cost:  0.6701325948744449\n",
      "Ended iteration 600  Cost:  0.48156993245701946  Validation cost:  0.6592086820031946\n",
      "Ended iteration 650  Cost:  0.4616770081361706  Validation cost:  0.6497246236250732\n",
      "Ended iteration 700  Cost:  0.44301230848548584  Validation cost:  0.6414535684344014\n",
      "Ended iteration 750  Cost:  0.4254296303242329  Validation cost:  0.6342398758083533\n",
      "Ended iteration 800  Cost:  0.4088298492119833  Validation cost:  0.6279699774283498\n",
      "Ended iteration 850  Cost:  0.39313974093153936  Validation cost:  0.6225546002013098\n",
      "Ended iteration 900  Cost:  0.3782982750022056  Validation cost:  0.6179181907517085\n",
      "Ended iteration 950  Cost:  0.3642487107165713  Validation cost:  0.6139930415299178\n",
      "Ended iteration 1000  Cost:  0.3509353448388499  Validation cost:  0.6107163952800926\n",
      "Ended iteration 1050  Cost:  0.33830337476656835  Validation cost:  0.6080292519661247\n",
      "Ended iteration 1100  Cost:  0.3263001496340751  Validation cost:  0.605876028578631\n",
      "Ended iteration 1150  Cost:  0.31487654152937095  Validation cost:  0.6042046048086401\n",
      "Ended iteration 1200  Cost:  0.3039878655722465  Validation cost:  0.6029665198885972\n",
      "Ended iteration 1250  Cost:  0.29359426019206286  Validation cost:  0.6021171851481505\n",
      "Ended iteration 1300  Cost:  0.2836606378983957  Validation cost:  0.6016160245709636\n",
      "Ended iteration 1350  Cost:  0.27415635405059297  Validation cost:  0.6014264966173112\n",
      "Ended iteration 1400  Cost:  0.2650547209555522  Validation cost:  0.6015159875450024\n",
      "Ended iteration 1450  Cost:  0.2563324626212847  Validation cost:  0.6018555922479026\n",
      "Ended iteration 1500  Cost:  0.24796917496337764  Validation cost:  0.6024198115872526\n",
      "Ended iteration 1550  Cost:  0.239946830311744  Validation cost:  0.6031861985281426\n",
      "Ended iteration 1600  Cost:  0.23224934468850492  Validation cost:  0.6041349832057288\n",
      "Ended iteration 1650  Cost:  0.22486221190053185  Validation cost:  0.6052487022722747\n",
      "Ended iteration 1700  Cost:  0.2177721997410698  Validation cost:  0.6065118521134177\n",
      "Ended iteration 1750  Cost:  0.21096709962816804  Validation cost:  0.6079105795191566\n",
      "Ended iteration 1800  Cost:  0.20443552053088335  Validation cost:  0.6094324175392007\n",
      "Ended iteration 1850  Cost:  0.1981667196374813  Validation cost:  0.6110660688546087\n",
      "Ended iteration 1900  Cost:  0.19215046460152577  Validation cost:  0.6128012344002693\n",
      "Ended iteration 1950  Cost:  0.18637692432916203  Validation cost:  0.6146284815314874\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.4253195601340196  Validation cost:  2.306669949088141\n",
      "Ended iteration 50  Cost:  1.4957175517528967  Validation cost:  1.5326715394547736\n",
      "Ended iteration 100  Cost:  1.1062165439390665  Validation cost:  1.1579513986998913\n",
      "Ended iteration 150  Cost:  0.9187473833786514  Validation cost:  0.9805506063243303\n",
      "Ended iteration 200  Cost:  0.808402678103462  Validation cost:  0.8797859662151626\n",
      "Ended iteration 250  Cost:  0.735333568705008  Validation cost:  0.8162653300568333\n",
      "Ended iteration 300  Cost:  0.682545829812339  Validation cost:  0.7731222994485697\n",
      "Ended iteration 350  Cost:  0.641604023505733  Validation cost:  0.7419462283743957\n",
      "Ended iteration 400  Cost:  0.6079816121040774  Validation cost:  0.7182002298893762\n",
      "Ended iteration 450  Cost:  0.5791134390983141  Validation cost:  0.6993092439559402\n",
      "Ended iteration 500  Cost:  0.5534849627281528  Validation cost:  0.6837545878405229\n",
      "Ended iteration 550  Cost:  0.5301762881251035  Validation cost:  0.6706122157427696\n",
      "Ended iteration 600  Cost:  0.5086189697140707  Validation cost:  0.6593042413493295\n",
      "Ended iteration 650  Cost:  0.48845821263605754  Validation cost:  0.6494590988104498\n",
      "Ended iteration 700  Cost:  0.4694706491921338  Validation cost:  0.6408299283008183\n",
      "Ended iteration 750  Cost:  0.4515131388149448  Validation cost:  0.6332457620131489\n",
      "Ended iteration 800  Cost:  0.434489863353175  Validation cost:  0.6265820345117247\n",
      "Ended iteration 850  Cost:  0.4183310937232318  Validation cost:  0.620742813486763\n",
      "Ended iteration 900  Cost:  0.4029801872838352  Validation cost:  0.6156501705251812\n",
      "Ended iteration 950  Cost:  0.3883866401168247  Validation cost:  0.6112378504638358\n",
      "Ended iteration 1000  Cost:  0.3745032254614222  Validation cost:  0.6074475190560467\n",
      "Ended iteration 1050  Cost:  0.36128536398340044  Validation cost:  0.6042265771783527\n",
      "Ended iteration 1100  Cost:  0.3486913410555021  Validation cost:  0.60152692981323\n",
      "Ended iteration 1150  Cost:  0.3366826160470325  Validation cost:  0.599304315521212\n",
      "Ended iteration 1200  Cost:  0.3252239497897148  Validation cost:  0.5975179362794563\n",
      "Ended iteration 1250  Cost:  0.3142833233954595  Validation cost:  0.5961302239035096\n",
      "Ended iteration 1300  Cost:  0.3038317066307826  Validation cost:  0.5951066506413115\n",
      "Ended iteration 1350  Cost:  0.29384274428008583  Validation cost:  0.5944155408728858\n",
      "Ended iteration 1400  Cost:  0.2842924147292075  Validation cost:  0.5940278709884909\n",
      "Ended iteration 1450  Cost:  0.27515869692370165  Validation cost:  0.5939170599332929\n",
      "Ended iteration 1500  Cost:  0.266421266423263  Validation cost:  0.5940587586303171\n",
      "Ended iteration 1550  Cost:  0.2580612299855469  Validation cost:  0.5944306468175472\n",
      "Ended iteration 1600  Cost:  0.2500609008426116  Validation cost:  0.5950122437488718\n",
      "Ended iteration 1650  Cost:  0.24240361283904424  Validation cost:  0.5957847364783846\n",
      "Ended iteration 1700  Cost:  0.23507356989048214  Validation cost:  0.5967308269670849\n",
      "Ended iteration 1750  Cost:  0.22805572681070913  Validation cost:  0.5978345973900147\n",
      "Ended iteration 1800  Cost:  0.22133569766728167  Validation cost:  0.5990813918669846\n",
      "Ended iteration 1850  Cost:  0.21489968798416914  Validation cost:  0.6004577123292065\n",
      "Ended iteration 1900  Cost:  0.20873444713003597  Validation cost:  0.601951126224026\n",
      "Ended iteration 1950  Cost:  0.20282723713610837  Validation cost:  0.6035501840660006\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3987313224828872  Validation cost:  2.323861307722424\n",
      "Ended iteration 50  Cost:  1.5160826721973903  Validation cost:  1.5343043222167978\n",
      "Ended iteration 100  Cost:  1.1109752523466778  Validation cost:  1.1468490290180664\n",
      "Ended iteration 150  Cost:  0.9166591217087595  Validation cost:  0.9668814444569681\n",
      "Ended iteration 200  Cost:  0.804160437620642  Validation cost:  0.8669381086381157\n",
      "Ended iteration 250  Cost:  0.730999194647183  Validation cost:  0.8050045037640658\n",
      "Ended iteration 300  Cost:  0.6792172271781282  Validation cost:  0.7635613969763845\n",
      "Ended iteration 350  Cost:  0.6398420141537425  Validation cost:  0.73397101916835\n",
      "Ended iteration 400  Cost:  0.6080487838547263  Validation cost:  0.7116241751342365\n",
      "Ended iteration 450  Cost:  0.5811253501080555  Validation cost:  0.6939403787367697\n",
      "Ended iteration 500  Cost:  0.5574881453538253  Validation cost:  0.6794166533117273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 550  Cost:  0.5361788505821514  Validation cost:  0.6671450078026562\n",
      "Ended iteration 600  Cost:  0.5165974641571971  Validation cost:  0.6565575084870661\n",
      "Ended iteration 650  Cost:  0.49835595762517876  Validation cost:  0.6472867364075642\n",
      "Ended iteration 700  Cost:  0.48119539000243494  Validation cost:  0.6390868074005868\n",
      "Ended iteration 750  Cost:  0.464937522996615  Validation cost:  0.6317872791963306\n",
      "Ended iteration 800  Cost:  0.44945582129027095  Validation cost:  0.6252655310606624\n",
      "Ended iteration 850  Cost:  0.4346576897349567  Validation cost:  0.6194298594417511\n",
      "Ended iteration 900  Cost:  0.42047340306766445  Validation cost:  0.6142089697781502\n",
      "Ended iteration 950  Cost:  0.40684910279809905  Validation cost:  0.6095453715155056\n",
      "Ended iteration 1000  Cost:  0.39374229196572685  Validation cost:  0.6053911878925571\n",
      "Ended iteration 1050  Cost:  0.3811188638296315  Validation cost:  0.6017054672656885\n",
      "Ended iteration 1100  Cost:  0.3689510652633768  Validation cost:  0.5984524272546549\n",
      "Ended iteration 1150  Cost:  0.35721602636581157  Validation cost:  0.5956002776613021\n",
      "Ended iteration 1200  Cost:  0.3458946381040589  Validation cost:  0.593120404835658\n",
      "Ended iteration 1250  Cost:  0.3349706569169006  Validation cost:  0.5909867869036465\n",
      "Ended iteration 1300  Cost:  0.32442997452322586  Validation cost:  0.5891755625576998\n",
      "Ended iteration 1350  Cost:  0.3142600235537639  Validation cost:  0.5876647069721075\n",
      "Ended iteration 1400  Cost:  0.304449304212391  Validation cost:  0.5864337849940257\n",
      "Ended iteration 1450  Cost:  0.2949870216066999  Validation cost:  0.5854637603481514\n",
      "Ended iteration 1500  Cost:  0.2858628230161711  Validation cost:  0.5847368447122373\n",
      "Ended iteration 1550  Cost:  0.2770666221167407  Validation cost:  0.5842363748277716\n",
      "Ended iteration 1600  Cost:  0.26858849445336264  Validation cost:  0.5839467101258476\n",
      "Ended iteration 1650  Cost:  0.2604186262758239  Validation cost:  0.5838531471730338\n",
      "Ended iteration 1700  Cost:  0.2525472983280451  Validation cost:  0.5839418496545681\n",
      "Ended iteration 1750  Cost:  0.2449648880793359  Validation cost:  0.5841997931312972\n",
      "Ended iteration 1800  Cost:  0.23766187807353722  Validation cost:  0.5846147227839203\n",
      "Ended iteration 1850  Cost:  0.2306288634350306  Validation cost:  0.5851751207759469\n",
      "Ended iteration 1900  Cost:  0.22385655655447606  Validation cost:  0.5858701787864173\n",
      "Ended iteration 1950  Cost:  0.2173357903378485  Validation cost:  0.5866897713108595\n",
      "======================Third model trained=====================\n",
      "First model  sigmoid validation cost:  0.6165001659586908  acc_train: 0.7951   acc_validation: 0.7915 \n",
      "Second model   sigmoid validation cost:  0.6052095940966131  acc_train:0.7826   acc_validation: 0.7819 \n",
      "Third model  sigmoid validation cost:  0.5876046640138777  acc_train:0.7972   acc_validation: 0.7877 \n",
      "Average validation loss:  0.6031048080230605  Average validation accuracy:  0.7870277777777778\n"
     ]
    }
   ],
   "source": [
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu.500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.285867802875108  Validation cost:  2.251106274833747\n",
      "Ended iteration 50  Cost:  0.7555120408045355  Validation cost:  1.8293496187469034\n",
      "Ended iteration 100  Cost:  0.566071835213495  Validation cost:  2.3178235513533925\n",
      "Ended iteration 150  Cost:  0.523537404582975  Validation cost:  2.686203144285995\n",
      "Ended iteration 200  Cost:  0.41954495127642494  Validation cost:  2.8668642051846116\n",
      "Ended iteration 250  Cost:  0.3634583731512732  Validation cost:  3.000748294175635\n",
      "Ended iteration 300  Cost:  0.3180465386612152  Validation cost:  3.0938930347883584\n",
      "Ended iteration 350  Cost:  0.28108866180349995  Validation cost:  3.173810752992934\n",
      "Ended iteration 400  Cost:  0.2742046236352307  Validation cost:  3.2784662311461066\n",
      "Ended iteration 450  Cost:  0.23589741663167482  Validation cost:  3.2160353871688043\n",
      "Ended iteration 500  Cost:  0.2024393578535564  Validation cost:  3.22685335584449\n",
      "Ended iteration 550  Cost:  0.18692210173198545  Validation cost:  3.2960234826008854\n",
      "Ended iteration 600  Cost:  0.16452687006800892  Validation cost:  3.2648776884179305\n",
      "Ended iteration 650  Cost:  0.15289845289706425  Validation cost:  3.2748583081145366\n",
      "Ended iteration 700  Cost:  0.12910723091176787  Validation cost:  3.302961784161677\n",
      "Ended iteration 750  Cost:  0.11551574912650593  Validation cost:  3.3260673018122047\n",
      "Ended iteration 800  Cost:  0.1035532849750337  Validation cost:  3.3381432000191325\n",
      "Ended iteration 850  Cost:  0.09434489866447894  Validation cost:  3.3594659599228907\n",
      "Ended iteration 900  Cost:  0.08019794601564192  Validation cost:  3.375061594162494\n",
      "Ended iteration 950  Cost:  0.0723650160969108  Validation cost:  3.3962888045866286\n",
      "Ended iteration 1000  Cost:  0.06571684902621189  Validation cost:  3.4185320845070746\n",
      "Ended iteration 1050  Cost:  0.05991779548926315  Validation cost:  3.4400879692191397\n",
      "Ended iteration 1100  Cost:  0.054833598854608256  Validation cost:  3.4607465469880667\n",
      "Ended iteration 1150  Cost:  0.050365107655976175  Validation cost:  3.4805059430266003\n",
      "Ended iteration 1200  Cost:  0.04642155759091881  Validation cost:  3.4994228818819124\n",
      "Ended iteration 1250  Cost:  0.042928347210745496  Validation cost:  3.5175160943889883\n",
      "Ended iteration 1300  Cost:  0.0398199707159277  Validation cost:  3.5348466046308933\n",
      "Ended iteration 1350  Cost:  0.03704564703560896  Validation cost:  3.55145339539123\n",
      "Ended iteration 1400  Cost:  0.03456115996398112  Validation cost:  3.567366738358452\n",
      "Ended iteration 1450  Cost:  0.032330241973210626  Validation cost:  3.582621494040406\n",
      "Ended iteration 1500  Cost:  0.030320439998057537  Validation cost:  3.597261072201097\n",
      "Ended iteration 1550  Cost:  0.028504098283844086  Validation cost:  3.61131961555794\n",
      "Ended iteration 1600  Cost:  0.026857673839922568  Validation cost:  3.6248406907797603\n",
      "Ended iteration 1650  Cost:  0.025361110548745052  Validation cost:  3.63786267017725\n",
      "Ended iteration 1700  Cost:  0.023995748715065702  Validation cost:  3.650417891186092\n",
      "Ended iteration 1750  Cost:  0.022747651377045798  Validation cost:  3.6625313083715665\n",
      "Ended iteration 1800  Cost:  0.021603413790164647  Validation cost:  3.6742382693584683\n",
      "Ended iteration 1850  Cost:  0.0205520056843087  Validation cost:  3.6855516459630375\n",
      "Ended iteration 1900  Cost:  0.019583807770428324  Validation cost:  3.6964915185737834\n",
      "Ended iteration 1950  Cost:  0.01869006911149538  Validation cost:  3.7070725459310627\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3080853322611743  Validation cost:  2.261264597937089\n",
      "Ended iteration 50  Cost:  0.7790184212147461  Validation cost:  1.6933167442638148\n",
      "Ended iteration 100  Cost:  0.5846631611283176  Validation cost:  1.85208565784058\n",
      "Ended iteration 150  Cost:  0.4795273396186386  Validation cost:  1.9984211428327023\n",
      "Ended iteration 200  Cost:  0.43481409912587027  Validation cost:  2.067937193052587\n",
      "Ended iteration 250  Cost:  0.3772671142218087  Validation cost:  2.0833146149527964\n",
      "Ended iteration 300  Cost:  0.3369588036357131  Validation cost:  2.055563101913902\n",
      "Ended iteration 350  Cost:  0.29750283530773364  Validation cost:  2.0376683603848553\n",
      "Ended iteration 400  Cost:  0.2730179260695712  Validation cost:  2.022383795516216\n",
      "Ended iteration 450  Cost:  0.26023363324305904  Validation cost:  1.9909410272238368\n",
      "Ended iteration 500  Cost:  0.23752836782016534  Validation cost:  1.9763995041233127\n",
      "Ended iteration 550  Cost:  0.20220999085568528  Validation cost:  1.944250775703172\n",
      "Ended iteration 600  Cost:  0.19601179524803725  Validation cost:  1.9144324092680047\n",
      "Ended iteration 650  Cost:  0.18303458378388562  Validation cost:  1.9006859392697348\n",
      "Ended iteration 700  Cost:  0.16005665721326  Validation cost:  1.886999379175038\n",
      "Ended iteration 750  Cost:  0.1430359968181197  Validation cost:  1.8783063751392284\n",
      "Ended iteration 800  Cost:  0.1522137228088938  Validation cost:  1.8500857120773107\n",
      "Ended iteration 850  Cost:  0.11856077085247278  Validation cost:  1.8363094473346881\n",
      "Ended iteration 900  Cost:  0.1480751434018413  Validation cost:  1.8536814238681751\n",
      "Ended iteration 950  Cost:  0.09878973648058853  Validation cost:  1.8148544552573491\n",
      "Ended iteration 1000  Cost:  0.15038530518575124  Validation cost:  1.8322259947189126\n",
      "Ended iteration 1050  Cost:  0.08225328445682091  Validation cost:  1.808036781265487\n",
      "Ended iteration 1100  Cost:  0.0743720247460569  Validation cost:  1.8084023348356264\n",
      "Ended iteration 1150  Cost:  0.06761754805508516  Validation cost:  1.8114079993559729\n",
      "Ended iteration 1200  Cost:  0.06172689622351039  Validation cost:  1.8155050143179845\n",
      "Ended iteration 1250  Cost:  0.056561532242952926  Validation cost:  1.8201436660054084\n",
      "Ended iteration 1300  Cost:  0.05199994140947711  Validation cost:  1.8250712384186658\n",
      "Ended iteration 1350  Cost:  0.04796268942696931  Validation cost:  1.8301515022386678\n",
      "Ended iteration 1400  Cost:  0.04437665544868172  Validation cost:  1.835297596637086\n",
      "Ended iteration 1450  Cost:  0.041180233627679176  Validation cost:  1.8404615180147799\n",
      "Ended iteration 1500  Cost:  0.038322819259956314  Validation cost:  1.845605397625702\n",
      "Ended iteration 1550  Cost:  0.035756361083884344  Validation cost:  1.8507027049304976\n",
      "Ended iteration 1600  Cost:  0.03344626167166902  Validation cost:  1.855728984440645\n",
      "Ended iteration 1650  Cost:  0.031362494630226084  Validation cost:  1.8606724725952177\n",
      "Ended iteration 1700  Cost:  0.02947818241360107  Validation cost:  1.8655332532227291\n",
      "Ended iteration 1750  Cost:  0.027770236141846847  Validation cost:  1.8703013817547787\n",
      "Ended iteration 1800  Cost:  0.02621539589117884  Validation cost:  1.8749753938909377\n",
      "Ended iteration 1850  Cost:  0.024796329380616763  Validation cost:  1.8795562078139179\n",
      "Ended iteration 1900  Cost:  0.023497917347251752  Validation cost:  1.8840430760577738\n",
      "Ended iteration 1950  Cost:  0.022308162137821063  Validation cost:  1.888441899103948\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3739989059129014  Validation cost:  2.26777698031783\n",
      "Ended iteration 50  Cost:  0.7297481226979816  Validation cost:  1.7661102785722602\n",
      "Ended iteration 100  Cost:  0.5398174569660978  Validation cost:  2.1039428836809138\n",
      "Ended iteration 150  Cost:  0.43763705498246414  Validation cost:  2.404125776545397\n",
      "Ended iteration 200  Cost:  0.3664473145174307  Validation cost:  2.6236921033070835\n",
      "Ended iteration 250  Cost:  0.31244559114014353  Validation cost:  2.7846364692990306\n",
      "Ended iteration 300  Cost:  0.2941149379464654  Validation cost:  2.851602859570568\n",
      "Ended iteration 350  Cost:  0.26016742312747143  Validation cost:  2.8980995325178633\n",
      "Ended iteration 400  Cost:  0.23223883854332356  Validation cost:  2.9361529300400036\n",
      "Ended iteration 450  Cost:  0.20844974823838736  Validation cost:  2.965169849696018\n",
      "Ended iteration 500  Cost:  0.1873937504577859  Validation cost:  2.9875277378569236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 550  Cost:  0.16847179229479328  Validation cost:  3.005690248787712\n",
      "Ended iteration 600  Cost:  0.1513955366801076  Validation cost:  3.0212705514401446\n",
      "Ended iteration 650  Cost:  0.13568603102177537  Validation cost:  3.035383944359366\n",
      "Ended iteration 700  Cost:  0.12143393392433971  Validation cost:  3.0490874217964437\n",
      "Ended iteration 750  Cost:  0.10813880424272014  Validation cost:  3.062829376579991\n",
      "Ended iteration 800  Cost:  0.0960954483385508  Validation cost:  3.077013182132618\n",
      "Ended iteration 850  Cost:  0.08540911850796502  Validation cost:  3.09154449007318\n",
      "Ended iteration 900  Cost:  0.07645193380166708  Validation cost:  3.10638372994163\n",
      "Ended iteration 950  Cost:  0.06935137990008686  Validation cost:  3.1223673276056023\n",
      "Ended iteration 1000  Cost:  0.06323804841646946  Validation cost:  3.1387930177890655\n",
      "Ended iteration 1050  Cost:  0.05782404945176374  Validation cost:  3.154579807043119\n",
      "Ended iteration 1100  Cost:  0.05303051588450811  Validation cost:  3.1695153923420354\n",
      "Ended iteration 1150  Cost:  0.04878318423943031  Validation cost:  3.1836222683566806\n",
      "Ended iteration 1200  Cost:  0.04501355650319727  Validation cost:  3.1969238572361847\n",
      "Ended iteration 1250  Cost:  0.04165951386446132  Validation cost:  3.209474250633284\n",
      "Ended iteration 1300  Cost:  0.03867391961074667  Validation cost:  3.2213076897976642\n",
      "Ended iteration 1350  Cost:  0.036006908404592745  Validation cost:  3.2325383747236223\n",
      "Ended iteration 1400  Cost:  0.033614785317832366  Validation cost:  3.2432234043280315\n",
      "Ended iteration 1450  Cost:  0.03146333951225049  Validation cost:  3.2533915893395244\n",
      "Ended iteration 1500  Cost:  0.029523253479743897  Validation cost:  3.2630824954419175\n",
      "Ended iteration 1550  Cost:  0.02776797713968359  Validation cost:  3.272330051385316\n",
      "Ended iteration 1600  Cost:  0.026174796080151753  Validation cost:  3.2811629862931277\n",
      "Ended iteration 1650  Cost:  0.02472513322430151  Validation cost:  3.2896149674258917\n",
      "Ended iteration 1700  Cost:  0.023402157187700865  Validation cost:  3.2977137898907736\n",
      "Ended iteration 1750  Cost:  0.022191969786278038  Validation cost:  3.305478936670303\n",
      "Ended iteration 1800  Cost:  0.021081974256905424  Validation cost:  3.3129281185299013\n",
      "Ended iteration 1850  Cost:  0.020061796165179852  Validation cost:  3.320076761896453\n",
      "Ended iteration 1900  Cost:  0.01912106222569309  Validation cost:  3.326952381296678\n",
      "Ended iteration 1950  Cost:  0.018251990475960853  Validation cost:  3.3335713960950972\n",
      "======================Third model trained=====================\n",
      "First model  relu validation cost:  3.7171129270361876  acc_train: 0.3168   acc_validation: 0.3098 \n",
      "Second model   relu validation cost:  1.89265798486309  acc_train:0.4934   acc_validation: 0.4886 \n",
      "Third model  relu validation cost:  3.3398267650023685  acc_train:0.3627   acc_validation: 0.3565 \n",
      "Average validation loss:  2.983199225633882  Average validation accuracy:  0.3849444444444445\n"
     ]
    }
   ],
   "source": [
    "activation = \"relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Relu.500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.354094520926173  Validation cost:  2.3611244015574604\n",
      "Ended iteration 50  Cost:  0.6732472793885368  Validation cost:  2.0938394898767916\n",
      "Ended iteration 100  Cost:  0.5105147189504344  Validation cost:  2.3928588209391193\n",
      "Ended iteration 150  Cost:  0.40039316159939964  Validation cost:  2.5656836274066124\n",
      "Ended iteration 200  Cost:  0.3286369229122634  Validation cost:  2.6455891150574598\n",
      "Ended iteration 250  Cost:  0.2763058251889412  Validation cost:  2.6815404353838326\n",
      "Ended iteration 300  Cost:  0.235881515165102  Validation cost:  2.7002023293037505\n",
      "Ended iteration 350  Cost:  0.2036873846484668  Validation cost:  2.713120402383332\n",
      "Ended iteration 400  Cost:  0.1765714854042014  Validation cost:  2.7074483912596023\n",
      "Ended iteration 450  Cost:  0.15380407832152485  Validation cost:  2.741410002558635\n",
      "Ended iteration 500  Cost:  0.12746411327836177  Validation cost:  2.746343800776991\n",
      "Ended iteration 550  Cost:  0.10624510220382236  Validation cost:  2.77300234806991\n",
      "Ended iteration 600  Cost:  0.09071216280523925  Validation cost:  2.8012987577200836\n",
      "Ended iteration 650  Cost:  0.07934408991097518  Validation cost:  2.8341056754987184\n",
      "Ended iteration 700  Cost:  0.07017622096606348  Validation cost:  2.865139299703946\n",
      "Ended iteration 750  Cost:  0.06248626698448226  Validation cost:  2.894773985485003\n",
      "Ended iteration 800  Cost:  0.0559780730645484  Validation cost:  2.9225000945383326\n",
      "Ended iteration 850  Cost:  0.05042232976536277  Validation cost:  2.949090638022771\n",
      "Ended iteration 900  Cost:  0.04565499424629266  Validation cost:  2.9739777186971783\n",
      "Ended iteration 950  Cost:  0.04154137817047216  Validation cost:  2.998352593196692\n",
      "Ended iteration 1000  Cost:  0.03798004610526053  Validation cost:  3.0205946563509483\n",
      "Ended iteration 1050  Cost:  0.034873715769122356  Validation cost:  3.0418124991182776\n",
      "Ended iteration 1100  Cost:  0.032152949735512755  Validation cost:  3.061976897210421\n",
      "Ended iteration 1150  Cost:  0.02975653860881072  Validation cost:  3.0809841969633873\n",
      "Ended iteration 1200  Cost:  0.02763679369563418  Validation cost:  3.099250047609636\n",
      "Ended iteration 1250  Cost:  0.025753440755234915  Validation cost:  3.1167092621522707\n",
      "Ended iteration 1300  Cost:  0.024071872381521437  Validation cost:  3.1341011151472387\n",
      "Ended iteration 1350  Cost:  0.02256553310900994  Validation cost:  3.150428013038265\n",
      "Ended iteration 1400  Cost:  0.021210365625716585  Validation cost:  3.1660010825297045\n",
      "Ended iteration 1450  Cost:  0.019986362323716193  Validation cost:  3.1808123292604504\n",
      "Ended iteration 1500  Cost:  0.018877184802657695  Validation cost:  3.1952960366182053\n",
      "Ended iteration 1550  Cost:  0.017868666981964165  Validation cost:  3.2089682884708455\n",
      "Ended iteration 1600  Cost:  0.016948693544404925  Validation cost:  3.22231572770249\n",
      "Ended iteration 1650  Cost:  0.01610716878948901  Validation cost:  3.23523930426393\n",
      "Ended iteration 1700  Cost:  0.015334340819393106  Validation cost:  3.2474746354518422\n",
      "Ended iteration 1750  Cost:  0.014624159124362901  Validation cost:  3.2591921253861473\n",
      "Ended iteration 1800  Cost:  0.013968171574880787  Validation cost:  3.27062263983078\n",
      "Ended iteration 1850  Cost:  0.013361850972485746  Validation cost:  3.2816797869217176\n",
      "Ended iteration 1900  Cost:  0.012800111553409101  Validation cost:  3.2922603393444114\n",
      "Ended iteration 1950  Cost:  0.012278206259497158  Validation cost:  3.3027528168122013\n",
      "======================First model trained=====================\n",
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.353358878510204  Validation cost:  2.323705223764556\n",
      "Ended iteration 50  Cost:  0.7382428324845886  Validation cost:  2.096038419040185\n",
      "Ended iteration 100  Cost:  0.5736888846653295  Validation cost:  2.4248851011358394\n",
      "Ended iteration 150  Cost:  0.4623479969899436  Validation cost:  2.6615488406499397\n",
      "Ended iteration 200  Cost:  0.38227482226788984  Validation cost:  2.8312392531528494\n",
      "Ended iteration 250  Cost:  0.3304370692803719  Validation cost:  2.9765671190167025\n",
      "Ended iteration 300  Cost:  0.2756609166619418  Validation cost:  3.084732559735694\n",
      "Ended iteration 350  Cost:  0.23737591680507886  Validation cost:  3.1908853485058244\n",
      "Ended iteration 400  Cost:  0.20959913600596788  Validation cost:  3.2889193192516397\n",
      "Ended iteration 450  Cost:  0.17510323431220967  Validation cost:  3.3652641639534626\n",
      "Ended iteration 500  Cost:  0.15455752227163563  Validation cost:  3.4500581560352255\n",
      "Ended iteration 550  Cost:  0.12702570253673987  Validation cost:  3.5227731709924544\n",
      "Ended iteration 600  Cost:  0.19640839416701528  Validation cost:  3.6008121573106067\n",
      "Ended iteration 650  Cost:  0.09308069521994136  Validation cost:  3.639675897812068\n",
      "Ended iteration 700  Cost:  0.08207103054758408  Validation cost:  3.703995686910358\n",
      "Ended iteration 750  Cost:  0.0728533846349134  Validation cost:  3.76863295237095\n",
      "Ended iteration 800  Cost:  0.06508249103111455  Validation cost:  3.8291607300850434\n",
      "Ended iteration 850  Cost:  0.05847685691228217  Validation cost:  3.8849728960856185\n",
      "Ended iteration 900  Cost:  0.0528414863828065  Validation cost:  3.9364272571926424\n",
      "Ended iteration 950  Cost:  0.0480041664797265  Validation cost:  3.984177350710966\n",
      "Ended iteration 1000  Cost:  0.043821098697465095  Validation cost:  4.0300417337952945\n",
      "Ended iteration 1050  Cost:  0.04018408046475089  Validation cost:  4.072706527581368\n",
      "Ended iteration 1100  Cost:  0.037007195820929664  Validation cost:  4.112285563802723\n",
      "Ended iteration 1150  Cost:  0.03421417794311122  Validation cost:  4.150548292494985\n",
      "Ended iteration 1200  Cost:  0.03174172705476616  Validation cost:  4.186381225849541\n",
      "Ended iteration 1250  Cost:  0.02955391716585216  Validation cost:  4.2201146394429\n",
      "Ended iteration 1300  Cost:  0.027602172566749062  Validation cost:  4.252612085591703\n",
      "Ended iteration 1350  Cost:  0.02585521084220512  Validation cost:  4.283484467321416\n",
      "Ended iteration 1400  Cost:  0.024285290833791235  Validation cost:  4.313027260140752\n",
      "Ended iteration 1450  Cost:  0.022868953142464794  Validation cost:  4.341191851024941\n",
      "Ended iteration 1500  Cost:  0.02158385760265815  Validation cost:  4.368182275457069\n",
      "Ended iteration 1550  Cost:  0.02041816363330136  Validation cost:  4.394253885008768\n",
      "Ended iteration 1600  Cost:  0.019355107835765356  Validation cost:  4.418723523403019\n",
      "Ended iteration 1650  Cost:  0.018382163252286903  Validation cost:  4.442349399632149\n",
      "Ended iteration 1700  Cost:  0.01749069223637252  Validation cost:  4.464822639270015\n",
      "Ended iteration 1750  Cost:  0.016670851316423197  Validation cost:  4.486750834334518\n",
      "Ended iteration 1800  Cost:  0.015914361724819623  Validation cost:  4.507580687862684\n",
      "Ended iteration 1850  Cost:  0.015216111183528586  Validation cost:  4.5278438418887905\n",
      "Ended iteration 1900  Cost:  0.014569235329223842  Validation cost:  4.547609194069107\n",
      "Ended iteration 1950  Cost:  0.013969130933622727  Validation cost:  4.566673689672391\n",
      "======================Second model trained=====================\n",
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.375767116491265  Validation cost:  2.286057246413849\n",
      "Ended iteration 50  Cost:  0.7791427550492829  Validation cost:  2.090610836309986\n",
      "Ended iteration 100  Cost:  0.6237444087253192  Validation cost:  2.569833976138131\n",
      "Ended iteration 150  Cost:  0.505246650489941  Validation cost:  2.965217209429063\n",
      "Ended iteration 200  Cost:  0.4580678011867194  Validation cost:  3.2263606794663815\n",
      "Ended iteration 250  Cost:  0.38810421251608573  Validation cost:  3.469866314926585\n",
      "Ended iteration 300  Cost:  0.336508144684418  Validation cost:  3.6183452537829677\n",
      "Ended iteration 350  Cost:  0.2957901496970748  Validation cost:  3.6912542573376266\n",
      "Ended iteration 400  Cost:  0.24286134420475103  Validation cost:  3.750940723979169\n",
      "Ended iteration 450  Cost:  0.23838784357921147  Validation cost:  3.841039496888794\n",
      "Ended iteration 500  Cost:  0.20196384089239003  Validation cost:  3.8974410867868463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 550  Cost:  0.18216471284191427  Validation cost:  3.916081888530625\n",
      "Ended iteration 600  Cost:  0.14774618748250448  Validation cost:  3.9274820378934603\n",
      "Ended iteration 650  Cost:  0.123053520767613  Validation cost:  3.9908349129956253\n",
      "Ended iteration 700  Cost:  0.10920414269932008  Validation cost:  4.0412521286527\n",
      "Ended iteration 750  Cost:  0.13958007412177798  Validation cost:  4.105008468393131\n",
      "Ended iteration 800  Cost:  0.0803653856090949  Validation cost:  4.1064826358961755\n",
      "Ended iteration 850  Cost:  0.07227612031126898  Validation cost:  4.152692438968041\n",
      "Ended iteration 900  Cost:  0.06511870968929237  Validation cost:  4.197681756775598\n",
      "Ended iteration 950  Cost:  0.058989207093251894  Validation cost:  4.242205034258431\n",
      "Ended iteration 1000  Cost:  0.05370611681269295  Validation cost:  4.285626847145082\n",
      "Ended iteration 1050  Cost:  0.04912436454084663  Validation cost:  4.326604402741142\n",
      "Ended iteration 1100  Cost:  0.04513729983067884  Validation cost:  4.366397381784418\n",
      "Ended iteration 1150  Cost:  0.0416289309816179  Validation cost:  4.403797241266408\n",
      "Ended iteration 1200  Cost:  0.038540004143182524  Validation cost:  4.439800206164871\n",
      "Ended iteration 1250  Cost:  0.03580060174548479  Validation cost:  4.474038180352201\n",
      "Ended iteration 1300  Cost:  0.0333698663218309  Validation cost:  4.507158672177836\n",
      "Ended iteration 1350  Cost:  0.03119012514608645  Validation cost:  4.538097312807143\n",
      "Ended iteration 1400  Cost:  0.029235526878122777  Validation cost:  4.567728844440076\n",
      "Ended iteration 1450  Cost:  0.027472885489489642  Validation cost:  4.596181946739677\n",
      "Ended iteration 1500  Cost:  0.025881205599491464  Validation cost:  4.623727673748573\n",
      "Ended iteration 1550  Cost:  0.024438000095251638  Validation cost:  4.649856898518684\n",
      "Ended iteration 1600  Cost:  0.023123657911752086  Validation cost:  4.675088617611893\n",
      "Ended iteration 1650  Cost:  0.021924113721500296  Validation cost:  4.699382751774483\n",
      "Ended iteration 1700  Cost:  0.020826770510248813  Validation cost:  4.722822772043344\n",
      "Ended iteration 1750  Cost:  0.019818096599020237  Validation cost:  4.745271776354934\n",
      "Ended iteration 1800  Cost:  0.018891273029779523  Validation cost:  4.766842763980454\n",
      "Ended iteration 1850  Cost:  0.018034647845159343  Validation cost:  4.787856675438433\n",
      "Ended iteration 1900  Cost:  0.017242434063212155  Validation cost:  4.808232512896269\n",
      "Ended iteration 1950  Cost:  0.016508192355321034  Validation cost:  4.827940285456862\n",
      "======================Third model trained=====================\n",
      "First model  leaky_relu validation cost:  3.3125515152683476  acc_train: 0.1850   acc_validation: 0.1777 \n",
      "Second model   leaky_relu validation cost:  4.585011316707724  acc_train:0.1217   acc_validation: 0.1145 \n",
      "Third model  leaky_relu validation cost:  4.846091007173893  acc_train:0.1246   acc_validation: 0.1187 \n",
      "Average validation loss:  4.247884613049988  Average validation accuracy:  0.137\n"
     ]
    }
   ],
   "source": [
    "activation = \"leaky_relu\"\n",
    "evaluate_neural_network_1hl(hidden_layer_1_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for two hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've tested many possibilities for one hidden layer. So right now we'll try to add more complexity to our model by adding an additional hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to proccess done previously, we'll experiment with different number of neurons for each hidden layer, and trying with different activation functions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1_neurons = 50\n",
    "hidden_layer_2_neurons = 50\n",
    "epochs = 2000\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid.50.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-fe08e78606ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-278-ac2b7fd59425>\u001b[0m in \u001b[0;36mevaluate_neural_network_2hl\u001b[0;34m(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel_2hl_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"======================First model trained=====================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel_2hl_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-319-4c2c93a27352>\u001b[0m in \u001b[0;36mtrain_neural_network_2hl\u001b[0;34m(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, trainParams, trainTarget, learning_rate, regularization_rate, activation)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralNetworkCostFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiBatchTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mvalidation_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashionValidationParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mvalidation_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralNetworkCostFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionValidationTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ended iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" Cost: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" Validation cost: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36mforward_prop_2hl\u001b[0;34m(x, neural_data, activation)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-241-315a7734311b>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mderivative_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu.50.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.2687286017487622  Validation cost:  2.3535397996251906\n",
      "Ended iteration 50  Cost:  0.679235185093714  Validation cost:  2.0506281905465884\n",
      "Ended iteration 100  Cost:  0.4206143164577436  Validation cost:  2.076417059632718\n",
      "Ended iteration 150  Cost:  0.23487308469263865  Validation cost:  2.0531358308813115\n",
      "Ended iteration 200  Cost:  0.4447015261223381  Validation cost:  2.060451616860988\n",
      "Ended iteration 250  Cost:  0.20834096624192255  Validation cost:  2.0413991231778184\n",
      "Ended iteration 300  Cost:  0.18310420815952416  Validation cost:  1.9956985549494426\n",
      "Ended iteration 350  Cost:  0.08433081823124193  Validation cost:  2.0037937667776453\n",
      "Ended iteration 400  Cost:  0.2275553867676305  Validation cost:  2.083040254123355\n",
      "Ended iteration 450  Cost:  0.16804518521370654  Validation cost:  1.7491771678481327\n",
      "Ended iteration 500  Cost:  0.14607685482339386  Validation cost:  1.8263863001353982\n",
      "Ended iteration 550  Cost:  0.10486750495128132  Validation cost:  1.748628759384239\n",
      "Ended iteration 600  Cost:  0.2958743489616582  Validation cost:  1.758539164591027\n",
      "Ended iteration 650  Cost:  0.05683343678545279  Validation cost:  1.7239837984793824\n",
      "Ended iteration 700  Cost:  0.022984294617981207  Validation cost:  1.7303727800529098\n",
      "Ended iteration 750  Cost:  0.00948822963834271  Validation cost:  1.7387386955084003\n",
      "Ended iteration 800  Cost:  0.007463463899310625  Validation cost:  1.7509026541843542\n",
      "Ended iteration 850  Cost:  0.0067538363685835665  Validation cost:  1.7634869000536206\n",
      "Ended iteration 900  Cost:  0.005451917279743489  Validation cost:  1.7543443259568006\n",
      "Ended iteration 950  Cost:  0.4506277089588442  Validation cost:  1.7105485534689402\n",
      "Ended iteration 1000  Cost:  0.2020201981854768  Validation cost:  1.496578725738659\n",
      "Ended iteration 1050  Cost:  0.06224393156763059  Validation cost:  1.4697255576319839\n",
      "Ended iteration 1100  Cost:  0.030472488882782745  Validation cost:  1.4667031506596668\n",
      "Ended iteration 1150  Cost:  0.23646743367901338  Validation cost:  1.4940973811779985\n",
      "Ended iteration 1200  Cost:  0.2921194592144401  Validation cost:  1.5151969269425523\n",
      "Ended iteration 1250  Cost:  0.047152593109167806  Validation cost:  1.5062319651895644\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-322-d3f705ff6db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-278-ac2b7fd59425>\u001b[0m in \u001b[0;36mevaluate_neural_network_2hl\u001b[0;34m(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel_2hl_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"======================First model trained=====================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel_2hl_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-319-4c2c93a27352>\u001b[0m in \u001b[0;36mtrain_neural_network_2hl\u001b[0;34m(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, trainParams, trainTarget, learning_rate, regularization_rate, activation)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralNetworkCostFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiBatchTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mvalidation_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfashionValidationParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mvalidation_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralNetworkCostFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionValidationTarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ended iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" Cost: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" Validation cost: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36mforward_prop_2hl\u001b[0;34m(x, neural_data, activation)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-241-315a7734311b>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mderivative_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activation = \"relu\"\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Relu.50.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with 2000 epochs, 50 neurons (1st layer) 50 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.298928492627872  Validation cost:  2.545005117291657\n",
      "Ended iteration 50  Cost:  0.850490757393525  Validation cost:  2.3080570543404084\n",
      "Ended iteration 100  Cost:  0.6256890178426208  Validation cost:  2.2681462698271826\n",
      "Ended iteration 150  Cost:  0.5236785081913394  Validation cost:  2.2469759798322855\n",
      "Ended iteration 200  Cost:  0.46379281586277993  Validation cost:  2.202677245990259\n",
      "Ended iteration 250  Cost:  0.4232928033383241  Validation cost:  2.1826249645959477\n",
      "Ended iteration 300  Cost:  0.36863268156473455  Validation cost:  2.1641735707778333\n",
      "Ended iteration 350  Cost:  0.32698648267455555  Validation cost:  2.1473067292388746\n",
      "Ended iteration 400  Cost:  0.27959147871225615  Validation cost:  2.1388076271298155\n",
      "Ended iteration 450  Cost:  0.2589524069223697  Validation cost:  2.1266667050506\n",
      "Ended iteration 500  Cost:  0.23325376317615767  Validation cost:  2.131561682552155\n",
      "Ended iteration 550  Cost:  0.1789039432637051  Validation cost:  2.152651884385525\n",
      "Ended iteration 600  Cost:  0.40725258265550557  Validation cost:  2.134627171697995\n",
      "Ended iteration 650  Cost:  0.23928991138460404  Validation cost:  2.095262608248443\n",
      "Ended iteration 700  Cost:  0.16371518279574535  Validation cost:  2.105433241353603\n",
      "Ended iteration 750  Cost:  0.11533886950787581  Validation cost:  2.0970894862988225\n",
      "Ended iteration 800  Cost:  0.09391004601771322  Validation cost:  2.0979678816809937\n",
      "Ended iteration 850  Cost:  0.35012334984777804  Validation cost:  2.0915813539919665\n",
      "Ended iteration 900  Cost:  0.34097836511148233  Validation cost:  2.1255241344087312\n",
      "Ended iteration 950  Cost:  0.06482529219024248  Validation cost:  2.086346205301479\n",
      "Ended iteration 1000  Cost:  0.06750967418833774  Validation cost:  2.080058408722032\n",
      "Ended iteration 1050  Cost:  0.05411023616173286  Validation cost:  2.1052546034072965\n",
      "Ended iteration 1100  Cost:  0.04085446183892119  Validation cost:  2.1136311889817168\n",
      "Ended iteration 1150  Cost:  0.061168303151497225  Validation cost:  2.1381511621065226\n",
      "Ended iteration 1200  Cost:  0.23391558911417482  Validation cost:  2.0663532786504395\n",
      "Ended iteration 1250  Cost:  0.07614806659061157  Validation cost:  2.035503781798653\n",
      "Ended iteration 1300  Cost:  0.0385243851232149  Validation cost:  2.070297010628497\n",
      "Ended iteration 1350  Cost:  0.026104479978712097  Validation cost:  2.094283384563582\n",
      "Ended iteration 1400  Cost:  0.02202588012179144  Validation cost:  2.100940070863213\n",
      "Ended iteration 1450  Cost:  0.019457307979057547  Validation cost:  2.104127432086236\n",
      "Ended iteration 1500  Cost:  0.017154146678129003  Validation cost:  2.112160136152861\n",
      "Ended iteration 1550  Cost:  0.01683343330149443  Validation cost:  2.115347506690348\n",
      "Ended iteration 1600  Cost:  0.02194850232694578  Validation cost:  2.1292375516681066\n",
      "Ended iteration 1650  Cost:  0.016477456212918594  Validation cost:  2.1321803225885936\n",
      "Ended iteration 1700  Cost:  0.01429431173035198  Validation cost:  2.14299323554548\n",
      "Ended iteration 1750  Cost:  1.7599673840502812  Validation cost:  2.1021986898723104\n",
      "Ended iteration 1800  Cost:  0.7314595891368869  Validation cost:  2.001349180304184\n",
      "Ended iteration 1850  Cost:  0.041130204999126556  Validation cost:  1.9927671065732075\n",
      "Ended iteration 1900  Cost:  0.020291736861689502  Validation cost:  2.0318944599491484\n",
      "Ended iteration 1950  Cost:  0.014286149210367366  Validation cost:  2.0626781771763176\n",
      "======================First model trained=====================\n",
      "Beginning training with 2000 epochs, 50 neurons (1st layer) 50 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.307141690724953  Validation cost:  2.447588419064357\n",
      "Ended iteration 50  Cost:  0.8467175064120505  Validation cost:  2.243201350900115\n",
      "Ended iteration 100  Cost:  0.5726741640618704  Validation cost:  2.1942419778046998\n",
      "Ended iteration 150  Cost:  0.46370664389509025  Validation cost:  2.183151445966974\n",
      "Ended iteration 200  Cost:  0.40598779262570467  Validation cost:  2.165823571966313\n",
      "Ended iteration 250  Cost:  0.38999018683507436  Validation cost:  2.1518738784469043\n",
      "Ended iteration 300  Cost:  0.360031057438299  Validation cost:  2.1668406527996957\n",
      "Ended iteration 350  Cost:  0.3140751080760358  Validation cost:  2.184120610362198\n",
      "Ended iteration 400  Cost:  0.247471735526448  Validation cost:  2.189585459767262\n",
      "Ended iteration 450  Cost:  0.273458029453549  Validation cost:  2.1933219510801867\n",
      "Ended iteration 500  Cost:  0.2724516332256814  Validation cost:  2.189580006396337\n",
      "Ended iteration 550  Cost:  0.2662645458927756  Validation cost:  2.193970683785372\n",
      "Ended iteration 600  Cost:  0.34919094716877935  Validation cost:  2.1650957635788197\n",
      "Ended iteration 650  Cost:  0.19284450594153568  Validation cost:  2.1918368100317784\n",
      "Ended iteration 700  Cost:  0.1450418467278726  Validation cost:  2.1816458533033205\n",
      "Ended iteration 750  Cost:  0.09401353828147077  Validation cost:  2.1926805544733208\n",
      "Ended iteration 800  Cost:  0.10153667593755225  Validation cost:  2.1600042535124966\n",
      "Ended iteration 850  Cost:  0.07835190779480887  Validation cost:  2.1577615630865403\n",
      "Ended iteration 900  Cost:  0.7373383906807666  Validation cost:  2.0871890334413203\n",
      "Ended iteration 950  Cost:  0.22045154475536435  Validation cost:  2.149568000011916\n",
      "Ended iteration 1000  Cost:  0.13293868540109902  Validation cost:  2.1569687202915033\n",
      "Ended iteration 1050  Cost:  0.09821092244534742  Validation cost:  2.139103200569305\n",
      "Ended iteration 1100  Cost:  0.1595106306846423  Validation cost:  2.112372642381013\n",
      "Ended iteration 1150  Cost:  0.10935492937404978  Validation cost:  2.1616338600452902\n",
      "Ended iteration 1200  Cost:  0.2218048057589606  Validation cost:  2.1041719625276465\n",
      "Ended iteration 1250  Cost:  0.14535244893712562  Validation cost:  2.1559256926845696\n",
      "Ended iteration 1300  Cost:  0.0471566006198303  Validation cost:  2.133863112152513\n",
      "Ended iteration 1350  Cost:  0.03336973701503704  Validation cost:  2.125891706577902\n",
      "Ended iteration 1400  Cost:  0.023138028471299123  Validation cost:  2.1063600810850986\n",
      "Ended iteration 1450  Cost:  0.022920848763899618  Validation cost:  2.099153006377474\n",
      "Ended iteration 1500  Cost:  0.17515726171631224  Validation cost:  1.9961807261079623\n",
      "Ended iteration 1550  Cost:  0.028753757931932983  Validation cost:  2.0686257702330932\n",
      "Ended iteration 1600  Cost:  0.021774426449773863  Validation cost:  2.0723728768323095\n",
      "Ended iteration 1650  Cost:  0.1311070952147745  Validation cost:  2.046275377319192\n",
      "Ended iteration 1700  Cost:  0.06355319051817336  Validation cost:  2.088152432811646\n",
      "Ended iteration 1750  Cost:  0.0615866894209334  Validation cost:  2.091010739592087\n",
      "Ended iteration 1800  Cost:  0.1350765171921387  Validation cost:  2.117777860518234\n",
      "Ended iteration 1850  Cost:  0.03424932912490913  Validation cost:  2.137756062556479\n",
      "Ended iteration 1900  Cost:  0.02026754197847307  Validation cost:  2.131973535186542\n",
      "Ended iteration 1950  Cost:  0.013735207033416354  Validation cost:  2.1311820674288025\n",
      "======================Second model trained=====================\n",
      "Beginning training with 2000 epochs, 50 neurons (1st layer) 50 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.333918270711159  Validation cost:  2.467688612573833\n",
      "Ended iteration 50  Cost:  0.9035849288303885  Validation cost:  2.2359029527613092\n",
      "Ended iteration 100  Cost:  0.6273248177289696  Validation cost:  2.203818728154758\n",
      "Ended iteration 150  Cost:  0.5399205238464923  Validation cost:  2.197596591138592\n",
      "Ended iteration 200  Cost:  0.4385368491295125  Validation cost:  2.1989539342286446\n",
      "Ended iteration 250  Cost:  0.40320820503245514  Validation cost:  2.2097131421430816\n",
      "Ended iteration 300  Cost:  0.36142377751992794  Validation cost:  2.199826367811345\n",
      "Ended iteration 350  Cost:  0.3495706033758939  Validation cost:  2.18955158949273\n",
      "Ended iteration 400  Cost:  0.3049809875234908  Validation cost:  2.2021172169450347\n",
      "Ended iteration 450  Cost:  0.295000236787348  Validation cost:  2.236737834823895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 500  Cost:  0.2688538974852244  Validation cost:  2.2466567378341917\n",
      "Ended iteration 550  Cost:  0.25327958181612475  Validation cost:  2.2957186815719424\n",
      "Ended iteration 600  Cost:  0.5695517747422975  Validation cost:  2.268868755952722\n",
      "Ended iteration 650  Cost:  0.2481069835574419  Validation cost:  2.2955225428535324\n",
      "Ended iteration 700  Cost:  0.17906728150986018  Validation cost:  2.276368427335762\n",
      "Ended iteration 750  Cost:  0.19890564808299602  Validation cost:  2.3133329310437523\n",
      "Ended iteration 800  Cost:  0.11677642309712832  Validation cost:  2.2941386092575646\n",
      "Ended iteration 850  Cost:  0.07499906069290488  Validation cost:  2.2910402702343657\n",
      "Ended iteration 900  Cost:  0.08038644405521743  Validation cost:  2.299560676982784\n",
      "Ended iteration 950  Cost:  0.08726790125029922  Validation cost:  2.313635829864952\n",
      "Ended iteration 1000  Cost:  0.19791456594435242  Validation cost:  2.302178137785097\n",
      "Ended iteration 1050  Cost:  0.1514163461885321  Validation cost:  2.333035310117591\n",
      "Ended iteration 1100  Cost:  0.08430555669089031  Validation cost:  2.405834777494567\n",
      "Ended iteration 1150  Cost:  0.07542185335433212  Validation cost:  2.4647434741456076\n",
      "Ended iteration 1200  Cost:  0.4024113171323368  Validation cost:  2.413857406363514\n",
      "Ended iteration 1250  Cost:  0.1288655144226589  Validation cost:  2.343593799457065\n",
      "Ended iteration 1300  Cost:  0.05908689691948486  Validation cost:  2.357765657630353\n",
      "Ended iteration 1350  Cost:  0.04183557429363418  Validation cost:  2.3689294931612936\n",
      "Ended iteration 1400  Cost:  0.027564357588476595  Validation cost:  2.385582759867218\n",
      "Ended iteration 1450  Cost:  0.021117030389048358  Validation cost:  2.386431865023984\n",
      "Ended iteration 1500  Cost:  0.02692857968770739  Validation cost:  2.3832896264433043\n",
      "Ended iteration 1550  Cost:  0.025639038018652353  Validation cost:  2.403872219378609\n",
      "Ended iteration 1600  Cost:  0.03044189789082412  Validation cost:  2.4183887860072115\n",
      "Ended iteration 1650  Cost:  0.23851952979719906  Validation cost:  2.277935310277156\n",
      "Ended iteration 1700  Cost:  0.05017179839915831  Validation cost:  2.3217591929862214\n",
      "Ended iteration 1750  Cost:  0.039027860451355006  Validation cost:  2.407356771384239\n",
      "Ended iteration 1800  Cost:  0.5623521137101462  Validation cost:  2.243092983734588\n",
      "Ended iteration 1850  Cost:  0.05853978148213543  Validation cost:  2.4080691855407257\n",
      "Ended iteration 1900  Cost:  0.028091770417952015  Validation cost:  2.4249609716439173\n",
      "Ended iteration 1950  Cost:  0.01709117861642786  Validation cost:  2.438768006915189\n",
      "======================Third model trained=====================\n",
      "First model  leaky_relu validation cost:  2.0809209458364553  acc_train: 0.2959   acc_validation: 0.2870 \n",
      "Second model   leaky_relu validation cost:  2.129368943207386  acc_train:0.1353   acc_validation: 0.1408 \n",
      "Third model  leaky_relu validation cost:  2.4531514462029094  acc_train:0.1469   acc_validation: 0.1502 \n",
      "Average validation loss:  2.2211471117489165  Average validation accuracy:  0.19269444444444442\n"
     ]
    }
   ],
   "source": [
    "activation = \"leaky_relu\"\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1_neurons = 300\n",
    "hidden_layer_2_neurons = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid.300.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "[[ 0.26983761  0.16238625 -1.59434205 ... -0.43984695 -2.06239805\n",
      "  -0.4719023 ]\n",
      " [-1.60754322 -0.81579097 -1.04036327 ...  0.50308106 -1.67073445\n",
      "  -0.02778651]\n",
      " [ 1.36162409 -0.99414746 -0.20564067 ...  1.50946234 -1.58177584\n",
      "   0.27925043]\n",
      " ...\n",
      " [-0.50577558 -0.46066772  0.13750424 ... -0.18905299 -0.09514519\n",
      "   0.12460211]\n",
      " [-1.72625585  1.26505764 -0.53738858 ... -2.29878714 -0.95999469\n",
      "  -1.91881162]\n",
      " [-0.06572883  0.87396181 -0.52427227 ...  0.64302363  0.43359024\n",
      "   0.80912879]]\n",
      "[[-0.04775898 -1.32359362 -0.01330956 ...  1.16476138  0.25804786\n",
      "   0.22165842]\n",
      " [ 0.54766561  0.27563297 -0.28015877 ... -0.08284414 -0.27742385\n",
      "   1.23578733]\n",
      " [ 1.11378827 -0.66713116  1.0357024  ...  1.42014527 -1.21995926\n",
      "  -0.06914371]\n",
      " ...\n",
      " [ 0.82660465  0.1982049  -2.76164565 ...  0.66763665 -0.63434863\n",
      "   0.16341093]\n",
      " [ 1.46351417 -0.2187261  -1.70912165 ...  0.16489435  1.1477964\n",
      "  -0.35386467]\n",
      " [-1.05051825  1.48986461  0.01729046 ...  1.65137737 -0.8304659\n",
      "   1.38190047]]\n",
      "[[ 1.83664793e+00  1.37441605e+00  1.14946584e-01 -5.91999701e-01\n",
      "  -2.04963580e+00 -1.36651135e+00 -2.92570319e-01  8.03773076e-01\n",
      "   1.04512346e+00 -5.36101845e-01]\n",
      " [ 6.96843237e-02  2.02799848e+00 -1.23708325e+00  4.01924869e-02\n",
      "  -1.57369494e+00 -3.87468480e-01 -5.65991630e-01 -3.68679769e-01\n",
      "  -1.44789348e+00 -6.61356912e-01]\n",
      " [-6.14067679e-01 -5.95238960e-01  2.71889135e+00  8.08373111e-01\n",
      "   2.06584565e+00  4.72056329e-01 -4.99341363e-01  1.11943321e+00\n",
      "  -3.24395513e-01 -3.45709571e-01]\n",
      " [ 1.25838627e-01 -8.03221371e-01 -3.00742297e-01  3.60276834e-02\n",
      "  -7.13335692e-02 -4.73391014e-01  1.93670545e-01 -3.78749048e-02\n",
      "   7.61724476e-03  1.82477234e-02]\n",
      " [-1.77814389e+00 -1.05186904e+00 -1.11584390e+00  3.15726841e-01\n",
      "   5.50265020e-01  4.66353357e-02 -7.18556146e-02 -4.30247075e-01\n",
      "  -7.93742310e-01  8.73314386e-01]\n",
      " [-1.07085516e+00 -2.72368058e+00  1.78485924e+00  3.12730491e-02\n",
      "   1.42398340e+00 -1.32358981e+00  5.75225676e-01  1.70965320e+00\n",
      "   3.18516477e-01 -1.56289743e+00]\n",
      " [ 7.42440331e-02 -3.76166857e-01  1.18647965e+00  7.41061512e-01\n",
      "   7.80046028e-01  7.08636731e-01  5.46135500e-01  7.22832807e-01\n",
      "  -3.04913863e-01 -3.32286027e-01]\n",
      " [-7.20019573e-01  1.16264537e+00  1.05167614e+00 -7.48733819e-01\n",
      "   1.64255341e+00  3.17616431e-01  1.03382049e+00  7.00518932e-01\n",
      "   1.56949505e-01 -2.02701822e-01]\n",
      " [ 1.03867980e-01  4.76848013e-01 -5.41075384e-01 -4.40763363e-02\n",
      "  -1.25079423e+00 -1.05696431e+00 -9.32374858e-01 -2.57934143e-01\n",
      "   2.85600605e-02  1.01912661e+00]\n",
      " [-1.47927551e-01 -1.02512006e-01 -8.84838305e-01 -6.16630718e-01\n",
      "   1.00025798e+00 -9.93277941e-01  2.19138210e-01  6.94378562e-01\n",
      "  -9.24667006e-01  3.70185648e-02]\n",
      " [-6.95567452e-01  4.37261962e-01  7.70941657e-01  6.68321329e-01\n",
      "   8.94330158e-02 -7.42608762e-01 -1.16588771e+00 -1.22308506e+00\n",
      "   6.81694639e-01 -2.10856421e-01]\n",
      " [ 1.07289853e+00 -1.13618414e+00  6.59559724e-01  5.02912073e-01\n",
      "  -5.92863637e-01 -9.08467429e-02  8.94033601e-02 -3.89814980e-01\n",
      "   4.19974811e-01  4.03169495e-01]\n",
      " [-2.54609234e-01  6.24334538e-02 -3.59992673e-01 -1.08961283e+00\n",
      "   4.04831555e-01  2.91403786e-01 -1.91779492e-01  2.44089882e-01\n",
      "  -3.49881737e-01  7.42809306e-01]\n",
      " [ 1.02956271e+00 -3.21315288e-01  1.06598083e+00 -6.17690199e-01\n",
      "  -9.43958577e-01  6.03656044e-01  1.10974020e+00  3.76264731e-01\n",
      "   1.09270515e-01  8.21938076e-02]\n",
      " [ 3.53984019e-01 -1.63083598e-01  8.34750708e-01  4.60865714e-01\n",
      "  -1.63007755e+00 -2.00855161e-01  6.30661206e-01 -6.70345448e-02\n",
      "  -1.31355191e+00  1.58381610e+00]\n",
      " [ 3.19723782e-02 -7.47529672e-01 -1.74847232e+00 -4.61426104e-01\n",
      "  -1.40659229e+00 -9.89037132e-01  2.06345056e+00 -1.19145861e-01\n",
      "  -1.19988466e+00 -4.19410478e-01]\n",
      " [ 2.19774310e-01  1.12830121e+00 -7.38585258e-01  1.24212761e+00\n",
      "  -3.70798430e-01  9.53820797e-01 -3.74073800e-01  4.13690545e-01\n",
      "   1.67074019e+00  4.38395578e-01]\n",
      " [-6.49433334e-01  2.20229390e-01 -4.86429162e-01 -3.81527385e-01\n",
      "   1.88339314e-01 -9.69005618e-01 -1.22293702e+00  1.04708216e+00\n",
      "  -5.73214500e-02 -9.05408162e-01]\n",
      " [ 5.16774928e-02 -1.48225118e+00 -1.07054725e+00 -1.76148618e+00\n",
      "  -4.64195154e-01 -3.36155651e-01 -1.09967060e+00 -8.94472098e-01\n",
      "   8.12045779e-01  4.01255225e-01]\n",
      " [ 1.93616887e+00 -4.61105945e-02 -1.25853528e+00  6.58000754e-02\n",
      "  -1.62504541e+00  2.05541907e-01 -7.22078793e-01 -5.65046667e-01\n",
      "  -6.19423153e-01 -1.17507898e+00]\n",
      " [-1.78892809e+00 -2.02747508e-01  4.24827133e-01  4.17173146e-01\n",
      "  -1.60362908e+00  5.65480578e-01 -6.34981251e-01 -2.09539400e+00\n",
      "   3.27888745e-01  1.70614852e-02]\n",
      " [ 3.37568744e-01 -1.00739692e+00  1.83640579e+00 -1.58014078e-01\n",
      "  -3.27354925e-01  5.81314573e-01 -3.57773029e-01  7.59893525e-01\n",
      "   5.74969599e-01 -8.96138477e-01]\n",
      " [-7.74281309e-01 -1.21231325e+00  1.29471337e+00  6.38112496e-01\n",
      "   4.52474412e-01 -1.47485865e+00  3.54701007e-01 -4.06464533e-01\n",
      "  -3.57724736e-01 -6.56778354e-01]\n",
      " [-6.50082193e-01 -8.61851435e-02 -1.34384203e-01  1.34582712e+00\n",
      "  -1.93011096e+00  4.77960945e-01  1.67457586e+00  3.41292219e-01\n",
      "   4.57022286e-01 -2.33200555e-01]\n",
      " [-1.28219922e-03 -2.73763561e-01  7.75755706e-01 -1.30891430e+00\n",
      "  -8.90366047e-01  1.15287215e+00  3.86885022e-01  1.14513984e+00\n",
      "  -9.74064294e-01 -2.29527511e+00]\n",
      " [ 3.05649895e-01  2.37676174e-01 -4.40087476e-01 -9.93009342e-01\n",
      "   1.05628043e+00  1.29190606e-01  1.40136422e+00  1.16675418e+00\n",
      "   5.77181333e-01  5.97815888e-01]\n",
      " [ 1.65773771e+00  9.27481483e-01 -2.26961837e-01  3.79460423e-01\n",
      "   2.43214198e+00  2.13234806e-01  5.39396516e-01  2.51234324e-01\n",
      "   1.15936750e+00 -9.60564524e-01]\n",
      " [-1.07566479e+00 -4.05995271e-01  4.45934033e-01 -4.23147312e-02\n",
      "   1.80227606e-01  7.57493850e-02 -1.27430329e+00  2.70215465e-02\n",
      "   1.11683264e+00  4.85863977e-01]\n",
      " [-2.08247336e+00 -1.34503101e+00  8.27173545e-01 -2.36400640e-01\n",
      "   8.88317624e-01  1.75382730e-01  6.15044396e-01 -6.12832116e-01\n",
      "   1.71289724e+00  1.34770886e+00]\n",
      " [-1.36354088e+00 -3.00114359e-01  1.83200591e+00 -6.32285644e-01\n",
      "   3.53494505e-01 -2.05459877e+00  4.33375995e-02 -2.48436663e-01\n",
      "  -1.77124982e+00  3.16770802e-01]\n",
      " [-8.68486635e-01 -1.55113047e-01  2.71190605e-01  1.59436366e+00\n",
      "  -2.28434231e+00  8.41620524e-01  1.03657075e+00  1.44399289e+00\n",
      "   7.74481901e-01  7.36905490e-01]\n",
      " [ 3.32260536e-01  6.42003869e-01 -1.01410563e+00 -1.76624196e+00\n",
      "   2.06966262e+00 -4.11241734e-01 -1.02247204e+00 -6.92564124e-01\n",
      "   6.47255233e-01  8.02197647e-01]\n",
      " [-6.39782701e-02  1.44708608e+00 -9.18759637e-02  6.02379441e-01\n",
      "   6.21137392e-01 -1.92504847e-01  1.27971290e-02  4.08971069e-01\n",
      "   2.00568228e-01  2.25366217e-01]\n",
      " [ 3.23598572e-01  2.47560159e-01  1.60178151e+00  9.21038438e-01\n",
      "   1.00398886e+00  3.18833342e-01 -1.88200076e+00  5.33957672e-01\n",
      "   8.80476021e-01  3.36076272e-01]\n",
      " [-1.25253433e+00  1.17010093e+00  6.22962355e-02 -1.29957932e+00\n",
      "   6.96093068e-01  9.86236622e-02 -3.87957768e-02 -1.11434617e-01\n",
      "   2.59161968e-01 -1.39030343e+00]\n",
      " [ 1.11626933e+00 -1.24183425e+00 -1.42090900e-01 -6.60359617e-01\n",
      "   4.19313542e-01  1.13590730e+00 -1.06629365e+00 -8.92730720e-01\n",
      "  -1.06450105e+00  6.14784555e-01]\n",
      " [-1.45571799e+00 -5.73479071e-01  1.08161783e-01 -6.13731419e-01\n",
      "  -1.23628563e+00 -2.03963047e+00 -8.02767879e-01  4.74623177e-01\n",
      "  -1.22296247e+00 -1.13997519e+00]\n",
      " [-1.33526452e-01 -4.64890971e-01  2.27692657e-01 -1.38164980e-01\n",
      "  -4.33770710e-01 -1.96625200e-01 -7.95011530e-01  7.59954987e-02\n",
      "   2.29167430e+00  7.79306036e-01]\n",
      " [-7.58745402e-01  4.24741128e-01  4.89124505e-01  6.16599176e-02\n",
      "   9.91909598e-01 -4.20037191e-01  5.87116006e-01 -4.79682005e-01\n",
      "   3.28201490e-01 -5.43171129e-01]\n",
      " [ 2.12042027e-01  9.06513007e-01  9.97725974e-01 -1.08444820e+00\n",
      "  -1.98453054e+00  3.43319508e-01  1.86290684e-01 -1.79656629e+00\n",
      "  -1.78383004e+00  9.16675586e-01]\n",
      " [ 1.57491260e+00  5.76244161e-01 -1.25067490e+00 -2.72902826e-01\n",
      "   7.15932637e-01  1.72642801e-01 -1.59556972e+00 -4.32666744e-01\n",
      "  -5.17188862e-01  2.14445062e+00]\n",
      " [ 2.81222601e+00  9.18029614e-02 -1.66142349e+00  1.51505362e+00\n",
      "   1.88634302e+00 -1.45636360e+00 -1.20101397e+00  1.64667790e+00\n",
      "   4.00942942e-01  1.05797842e-01]\n",
      " [ 1.98458959e+00 -2.17588810e-02  6.72529879e-02  7.59749188e-01\n",
      "   4.24860281e-01 -7.54755766e-01  1.12766307e+00  2.15715670e+00\n",
      "  -1.47526486e+00 -1.14672834e+00]\n",
      " [-6.51071365e-02 -6.61701350e-01  3.67482867e-01  2.68249296e-01\n",
      "  -6.23136707e-01  1.37431090e+00 -2.58999181e-01 -1.85816573e+00\n",
      "  -1.13194790e+00 -4.56012790e-01]\n",
      " [-1.70053521e-01 -1.57538180e-01  1.25877096e+00  1.53375194e-01\n",
      "  -2.10905255e+00  1.23825296e+00 -1.38244832e+00  2.37228955e-01\n",
      "   3.20727023e-01 -1.06198167e+00]\n",
      " [ 1.16424497e-01  2.63960783e-01 -5.42160600e-01  1.60491572e+00\n",
      "   8.37938097e-01  9.95532050e-01  2.18473551e-01 -7.75598881e-01\n",
      "   4.92196462e-01 -1.31804759e+00]\n",
      " [-1.91832354e-01  1.11955676e+00  1.19818541e+00 -1.80522899e+00\n",
      "  -1.35303026e+00 -7.70253403e-01  8.65488284e-01 -1.24223504e+00\n",
      "  -1.79760720e+00  4.23267725e-01]\n",
      " [-1.13514945e+00  1.22441907e+00  6.28153033e-01 -2.07098430e+00\n",
      "  -5.72119847e-01 -6.60894929e-01 -1.14689435e-01 -3.64804110e-01\n",
      "  -2.14913690e+00 -3.53942694e-01]\n",
      " [ 4.97124036e-01 -7.34484690e-01  1.32488590e+00 -1.35983368e+00\n",
      "  -4.53840740e-01  9.32417009e-01 -1.28884615e+00  8.25763324e-01\n",
      "  -2.16631550e+00 -5.82178536e-01]\n",
      " [ 3.37091035e-01  1.55411541e+00 -4.42953483e-01 -1.49550622e+00\n",
      "   1.89421355e-01 -4.79891804e-01 -5.93995003e-01  3.01917654e-01\n",
      "   2.08757699e-01  2.09775621e+00]\n",
      " [ 2.03410388e+00  2.11193798e+00 -9.34818084e-01  1.78090632e-01\n",
      "   9.69671753e-01  1.43894736e+00  1.59216862e+00  2.04331908e-01\n",
      "   1.15493089e+00 -9.36203751e-01]\n",
      " [ 8.77947231e-01  2.66150728e+00 -1.18628267e-01  9.78962117e-01\n",
      "   5.92831976e-01 -9.87481840e-02  1.22297400e+00  4.47996087e-01\n",
      "   1.71624530e+00  6.89575670e-01]\n",
      " [ 3.18858016e-01 -7.21160209e-01  1.78145946e-01 -1.20740192e+00\n",
      "   4.53024426e-01 -2.07909627e-01 -1.57455977e+00 -1.15557970e+00\n",
      "   3.45456958e-01 -3.10865923e-01]\n",
      " [ 2.44600348e-01  7.30376967e-02 -1.38156119e+00  5.93648626e-02\n",
      "  -1.29486056e-01  3.78312800e-01 -1.94583706e+00 -7.11044682e-01\n",
      "   1.27806486e+00  1.11728567e-01]\n",
      " [ 1.31093363e+00 -5.34244021e-01 -1.44202335e-01 -1.34851129e+00\n",
      "  -1.43826825e+00 -1.09745002e+00 -8.75976003e-01 -8.30701125e-01\n",
      "   3.57409138e-02 -1.81925631e-01]\n",
      " [ 3.35035645e-01  3.12890392e-01 -5.56825394e-01 -4.25677156e-01\n",
      "   5.47262934e-01  5.75624841e-01 -1.15769548e-01  7.71222881e-01\n",
      "  -6.85374303e-01  9.06195143e-01]\n",
      " [-7.84805447e-01  5.71932463e-01 -1.42861771e+00 -1.53027427e+00\n",
      "   1.78687715e+00 -4.78847581e-01 -2.97166047e-01  3.78504725e-01\n",
      "  -7.20217015e-01  7.10750634e-02]\n",
      " [-3.64112687e-01  1.23494182e+00 -4.50192513e-01  1.98669712e+00\n",
      "  -1.00991476e+00  2.01275322e+00  1.58598613e+00 -3.89697037e-01\n",
      "  -6.51328488e-01 -1.18497411e-02]\n",
      " [ 1.17780646e+00 -1.07387040e+00  1.17439297e+00  1.16878686e+00\n",
      "   1.71708507e+00 -2.80959088e+00  5.41134598e-01 -5.72662519e-01\n",
      "  -1.71905971e+00 -4.38161787e-01]\n",
      " [ 1.03203757e+00 -1.05170524e+00  1.11699650e+00 -1.59981087e-01\n",
      "  -1.06773196e+00 -4.88316746e-01  2.45175413e-01  1.83110270e+00\n",
      "  -2.35790848e-01  5.19643302e-01]\n",
      " [ 7.59846656e-01  1.22588564e+00 -4.77518505e-01 -2.05548003e-01\n",
      "   7.92384642e-01 -9.10524743e-02 -7.67613794e-01  5.97762321e-01\n",
      "   3.03703566e-01 -9.36285209e-01]\n",
      " [-7.53586983e-01 -1.18389219e+00  1.15619342e+00  8.68162147e-01\n",
      "  -9.68224094e-01 -1.55874424e+00  3.55416677e-01  8.31546246e-01\n",
      "  -9.98814590e-01  9.67720178e-01]\n",
      " [-1.78293185e+00 -2.39266022e-01  7.57892555e-01  6.09541630e-01\n",
      "  -5.24129039e-01 -1.07686430e+00 -1.40185645e+00 -7.20321303e-01\n",
      "   2.14903227e-03  3.54748312e-01]\n",
      " [ 5.52459006e-01 -5.54336274e-01 -2.74218159e-01 -1.98301662e+00\n",
      "   2.84296015e-01  2.25018624e-01  1.57760063e+00 -1.55798189e+00\n",
      "  -1.28500129e+00 -1.05138399e-01]\n",
      " [-3.40844224e-01 -9.40200082e-01 -1.58863616e-01  8.29949759e-01\n",
      "   1.06261378e-01 -8.81614791e-01  5.32697751e-01 -6.38141523e-01\n",
      "   1.93474694e+00  7.58888134e-01]\n",
      " [ 1.28426311e+00  8.36866302e-02  6.30487158e-01  1.20347283e+00\n",
      "   6.56279912e-01  2.58897743e-02  6.25260491e-01 -1.55216645e+00\n",
      "  -8.66462422e-01 -8.79100860e-01]\n",
      " [-1.88606197e-01 -6.71551838e-01  1.47900512e+00 -3.63522685e-01\n",
      "   4.71158763e-04 -1.14276557e+00  2.28982091e+00  7.06865134e-01\n",
      "   6.99439415e-01 -2.98197097e-01]\n",
      " [ 7.28991140e-01 -2.57968445e-02  1.56547391e+00  1.46008363e+00\n",
      "  -4.62062832e-02 -1.35675693e+00  7.07479118e-01 -1.30676311e+00\n",
      "  -1.36420880e+00  7.13823713e-01]\n",
      " [ 6.34397365e-01 -1.07784273e+00 -2.04212287e-01  2.81795552e-01\n",
      "  -6.94904569e-01 -5.11796835e-02 -6.11683171e-01 -9.53799823e-01\n",
      "  -2.42416877e-01  1.32614186e+00]\n",
      " [ 9.73911816e-01  1.68531014e-02  7.77235635e-01  1.70780014e+00\n",
      "  -4.62131487e-01  2.87297534e-01 -4.13186424e-02 -6.83295479e-01\n",
      "  -9.45728303e-02 -1.12116095e+00]\n",
      " [ 2.48818910e-01  6.15792589e-01  1.02111212e-01  9.20573714e-02\n",
      "   2.64732588e-01  4.30577681e-01 -9.92156998e-01 -9.71039837e-01\n",
      "   2.16933308e-01 -1.46549681e-01]\n",
      " [ 8.95864972e-01  8.71941682e-01 -9.57894366e-01  9.81030293e-02\n",
      "  -9.31379954e-01 -9.08549396e-01  1.10293796e-01 -9.00310409e-01\n",
      "   5.77884184e-01  2.00439954e+00]\n",
      " [-6.16732660e-02  6.29935644e-01  4.98018412e-01  2.98062325e-01\n",
      "  -8.87496987e-01  3.97194634e-01  6.01454156e-01  1.27154364e+00\n",
      "   1.85663724e+00 -8.49406712e-01]\n",
      " [ 2.11570789e+00  4.04622047e-01  5.69929819e-02  5.37834255e-01\n",
      "  -1.81809416e-01  1.78211619e+00  5.42409736e-02  2.30745818e+00\n",
      "  -1.30057714e+00  2.48850720e+00]\n",
      " [ 2.65327088e-02  4.04705907e-01 -1.18468692e+00 -6.59839048e-01\n",
      "  -1.05424631e+00  3.38123892e-01 -2.49066209e-01 -6.98090937e-01\n",
      "   1.18780100e+00  1.90834836e+00]\n",
      " [ 2.06754007e-01 -8.11214045e-01  8.04677623e-02 -1.92025419e-01\n",
      "  -1.74807426e+00 -1.65785637e+00  5.57605161e-01  8.55400611e-01\n",
      "  -4.35421026e-02 -1.88729432e+00]\n",
      " [-5.67774780e-01  1.63694196e+00  1.21807629e+00  2.78242530e-01\n",
      "   8.74446379e-01  1.25628733e-01  1.24546270e-01  2.70486480e-02\n",
      "  -3.75580017e-01  3.25892989e-02]\n",
      " [-1.35445206e+00 -5.17288129e-01 -2.08826898e+00  1.39271309e+00\n",
      "  -9.84882762e-01  1.77773647e+00 -9.24792100e-01  1.24577207e+00\n",
      "   1.91644666e+00 -5.52391152e-01]\n",
      " [-1.67309653e-01 -1.85443847e-01 -2.12013218e-01  5.55947408e-01\n",
      "   5.77692729e-01 -2.49402946e-01  6.50973324e-01  1.22273184e+00\n",
      "   9.29961415e-01 -2.43812165e+00]\n",
      " [ 7.21481597e-01  4.45818364e-01 -2.32963604e-01  2.89900436e-01\n",
      "  -7.66692172e-01 -7.72668107e-01  7.84953831e-02  1.48963966e+00\n",
      "  -8.29833591e-01 -1.25306759e-01]\n",
      " [-8.76598537e-01  6.10219048e-01  5.82742438e-01 -8.66029104e-01\n",
      "  -2.20714760e+00 -7.82366612e-01  2.30361392e+00 -4.33401464e-01\n",
      "   4.04905915e-01  1.59628248e+00]\n",
      " [ 8.32845818e-01  1.09466906e-01 -4.89255868e-01  1.18514809e+00\n",
      "  -1.48084504e+00  2.73970267e+00 -9.01629632e-01 -3.35472392e-01\n",
      "   2.35852652e-01  1.47665839e+00]\n",
      " [-1.37261274e+00  2.35923058e+00 -1.45032292e+00  1.76203212e-01\n",
      "  -2.91092597e-01 -1.22992599e-02  2.44284850e-01  6.95966418e-01\n",
      "   6.22383553e-01 -1.70832541e-01]\n",
      " [-6.95732813e-01  2.67198146e-01 -6.79691850e-02 -4.06855437e-01\n",
      "   8.80916554e-01 -8.67080781e-01 -1.66807334e+00  1.91873794e+00\n",
      "   2.41808503e-01  6.74690581e-01]\n",
      " [ 4.24228135e-01 -1.64173580e-01  1.02407507e+00  5.04595372e-02\n",
      "   1.01622489e+00  2.91993277e-01  1.94723457e+00  4.70278740e-01\n",
      "  -5.64526003e-01  8.71944508e-01]\n",
      " [ 1.04558108e+00 -5.30016699e-01 -2.21569189e-01 -1.82923391e-01\n",
      "   1.66172935e+00  1.52274249e+00 -6.80259530e-01  3.80427810e-01\n",
      "  -3.57675524e-01  1.02876000e-01]\n",
      " [-1.15360407e+00 -1.95506362e-02  2.59165852e-01 -4.72665369e-01\n",
      "  -2.20743196e-02  2.10233821e+00  5.55260322e-01 -1.50945327e+00\n",
      "  -4.66747990e-02 -2.56650867e-03]\n",
      " [ 1.05404347e+00 -1.08859890e+00 -1.11027207e+00  9.11074441e-01\n",
      "  -1.16014002e-01  1.91420401e+00 -2.73749573e-01  9.27737009e-01\n",
      "   8.75078518e-03 -8.24905591e-01]\n",
      " [-4.96876864e-01 -6.75857906e-01  3.83773071e-01 -8.17969650e-01\n",
      "   8.37144947e-01 -4.37843868e-01  2.42503536e+00  1.05161881e+00\n",
      "   3.79507798e-02  7.39204658e-01]\n",
      " [ 1.27844503e-01  9.45461010e-01 -6.58718942e-02  1.36866160e+00\n",
      "   2.17393399e+00  5.94283251e-01 -7.85337706e-01 -1.91433404e+00\n",
      "  -3.24344405e-01 -4.39296179e-01]\n",
      " [-6.36140927e-01  1.23658282e+00  1.24729666e+00 -3.63372314e-01\n",
      "  -1.29396502e+00 -1.25013963e+00  1.08732486e+00 -3.90933978e-01\n",
      "   9.09095868e-01 -1.00476774e+00]\n",
      " [-9.49486235e-01 -9.46372331e-01 -7.95417344e-01 -4.08999145e-01\n",
      "  -9.97891181e-01 -3.53392404e-01 -1.58012394e+00  1.74716618e+00\n",
      "  -2.29016199e+00 -3.01955523e-01]\n",
      " [ 6.78086935e-01 -1.05236593e+00  8.07944348e-01  7.79161788e-02\n",
      "  -1.12840099e+00 -5.89015214e-01 -8.38699930e-01 -3.67379125e-01\n",
      "  -1.46888867e+00  3.13819579e-01]\n",
      " [-8.33588217e-01 -8.25909346e-01  2.17060617e+00  6.48725515e-01\n",
      "   8.08263137e-02 -9.96111294e-01 -6.89241047e-02  6.33626473e-01\n",
      "  -5.57718559e-01 -6.25615172e-01]\n",
      " [-4.43722342e-01  3.29493607e+00  7.63340727e-01 -1.27112343e+00\n",
      "   4.97314806e-01  1.47211033e+00 -7.90603551e-01  1.28018649e-03\n",
      "  -1.06947370e+00 -4.89514389e-01]\n",
      " [-8.33068903e-02 -1.59681694e+00 -1.29816078e+00  2.55000841e-01\n",
      "   2.84608836e-01  4.01306653e-01 -4.78307721e-01 -1.10143787e+00\n",
      "  -1.30697937e+00 -6.65990508e-01]\n",
      " [-2.48980437e-01  9.22969805e-01  4.49726737e-01 -5.34363888e-01\n",
      "   4.11182082e-01 -3.28185921e-01 -3.98024141e-01 -8.13074769e-01\n",
      "  -5.89654677e-01  4.15438915e-02]\n",
      " [ 8.87041071e-01  7.50545866e-01  1.82447702e-01  9.63118194e-02\n",
      "  -1.76337270e-01  6.57146602e-01 -2.84343126e-01 -1.53638782e+00\n",
      "  -3.85109767e-01 -1.69511857e+00]\n",
      " [-1.42776355e+00 -6.46623087e-01 -1.07074454e+00  1.58818173e+00\n",
      "  -3.48659795e-01  1.51699508e+00 -2.09327083e+00 -7.98089975e-02\n",
      "   1.34395776e+00 -1.25727249e+00]\n",
      " [-1.68888903e+00 -1.77259525e+00  8.74438109e-01 -1.34555275e+00\n",
      "   1.44224101e+00  1.31727360e+00  4.32626683e-01  2.63380606e-01\n",
      "  -9.90654023e-01  8.64467495e-01]]\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.25119401e-07 3.31150133e-06 9.71231620e-01 2.65818160e-08\n",
      "  9.96449772e-09 6.56643106e-09 2.88925867e-08 1.48614922e-05\n",
      "  6.94350447e-11 2.87500100e-02]\n",
      " [7.95241290e-05 3.86534405e-02 9.57264836e-01 7.04012921e-09\n",
      "  4.89327354e-07 2.65423170e-04 8.07847386e-06 3.49016630e-03\n",
      "  1.40242818e-10 2.38035033e-04]\n",
      " [1.06784743e-07 1.05405141e-05 9.99934691e-01 8.21141611e-09\n",
      "  1.84698420e-09 1.86947820e-08 7.98637387e-10 5.41832832e-05\n",
      "  1.29112269e-12 4.48666193e-07]\n",
      " [6.83081968e-08 1.36666396e-05 9.99679160e-01 1.29891479e-07\n",
      "  5.33964895e-10 9.69895684e-08 7.58015308e-11 1.69858929e-04\n",
      "  8.31317205e-09 1.37010692e-04]\n",
      " [3.53274084e-06 2.15572514e-02 9.76669527e-01 2.41866358e-08\n",
      "  1.71945327e-06 8.83711106e-06 4.13523665e-06 1.17692667e-04\n",
      "  1.57883551e-09 1.63727880e-03]]\n",
      "[[1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0]]\n",
      "Ended iteration 0  Cost:  11.764101551180609  Validation cost:  11.125691719882969\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-294-fe08e78606ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-278-ac2b7fd59425>\u001b[0m in \u001b[0;36mevaluate_neural_network_2hl\u001b[0;34m(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel_2hl_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"======================First model trained=====================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel_2hl_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-291-82c5c5a2ca55>\u001b[0m in \u001b[0;36mtrain_neural_network_2hl\u001b[0;34m(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, trainParams, trainTarget, learning_rate, regularization_rate, activation)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mminiBatchTarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         Performs Forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         Performs Backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-293-0075b5ee4553>\u001b[0m in \u001b[0;36mforward_prop_2hl\u001b[0;34m(x, neural_data, activation)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-293-0075b5ee4553>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-293-0075b5ee4553>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Output of hidden layer with activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-241-315a7734311b>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mderivative_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu.300.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3864051072012034  Validation cost:  2.4116259826032866\n",
      "Ended iteration 50  Cost:  0.821666245392131  Validation cost:  2.2101837942763436\n",
      "Ended iteration 100  Cost:  0.6092624432487515  Validation cost:  2.2237955031243044\n",
      "Ended iteration 150  Cost:  0.4992799055064407  Validation cost:  2.2304797354633337\n",
      "Ended iteration 200  Cost:  0.4007449376528482  Validation cost:  2.262533232818289\n",
      "Ended iteration 250  Cost:  0.3534688616602495  Validation cost:  2.2953720628139878\n",
      "Ended iteration 300  Cost:  0.29105093898267803  Validation cost:  2.2956193455901874\n",
      "Ended iteration 350  Cost:  0.2704222151311323  Validation cost:  2.299283376645753\n",
      "Ended iteration 400  Cost:  0.2856509011164307  Validation cost:  2.3856725977307742\n",
      "Ended iteration 450  Cost:  0.23171967206667693  Validation cost:  2.2857982783440765\n",
      "Ended iteration 500  Cost:  0.23899934826837685  Validation cost:  2.385676150975771\n",
      "Ended iteration 550  Cost:  0.17129582398120174  Validation cost:  2.3036165515497435\n",
      "Ended iteration 600  Cost:  0.4015392673229339  Validation cost:  2.416478730673681\n",
      "Ended iteration 650  Cost:  0.2031105334164286  Validation cost:  2.2753128119972743\n",
      "Ended iteration 700  Cost:  0.15056213501164295  Validation cost:  2.392567977630448\n",
      "Ended iteration 750  Cost:  0.11459567332221042  Validation cost:  2.333422580235515\n",
      "Ended iteration 800  Cost:  0.07331028561210383  Validation cost:  2.3641334489677854\n",
      "Ended iteration 850  Cost:  0.049519272969092566  Validation cost:  2.3910390620599578\n",
      "Ended iteration 900  Cost:  0.04425796319023946  Validation cost:  2.3984483802167076\n",
      "Ended iteration 950  Cost:  0.03644373768832544  Validation cost:  2.3712027204148076\n",
      "Ended iteration 1000  Cost:  0.04406451356112216  Validation cost:  2.393857122365428\n",
      "Ended iteration 1050  Cost:  0.09668286748410089  Validation cost:  2.4061788414854828\n",
      "Ended iteration 1100  Cost:  0.04275867768846334  Validation cost:  2.4158120210263756\n",
      "Ended iteration 1150  Cost:  0.038225245596846646  Validation cost:  2.4530138361676666\n",
      "Ended iteration 1200  Cost:  0.20300326233447596  Validation cost:  2.38892540593041\n",
      "Ended iteration 1250  Cost:  0.09535890688916594  Validation cost:  2.364065876055234\n",
      "Ended iteration 1300  Cost:  0.0404856506276759  Validation cost:  2.3736197047164347\n",
      "Ended iteration 1350  Cost:  0.025283561158118764  Validation cost:  2.3993261128984784\n",
      "Ended iteration 1400  Cost:  0.018214808084013823  Validation cost:  2.4068468938978884\n",
      "Ended iteration 1450  Cost:  0.013608359700207628  Validation cost:  2.412918365416907\n",
      "Ended iteration 1500  Cost:  0.01250899014256014  Validation cost:  2.4129508881907915\n",
      "Ended iteration 1550  Cost:  0.01099626367213866  Validation cost:  2.396932487301288\n",
      "Ended iteration 1600  Cost:  0.013470604343134409  Validation cost:  2.4125255768266047\n",
      "Ended iteration 1650  Cost:  0.013756777463034865  Validation cost:  2.4037764590320183\n",
      "Ended iteration 1700  Cost:  0.014666339703420054  Validation cost:  2.411458090986898\n",
      "Ended iteration 1750  Cost:  0.015585088802688935  Validation cost:  2.441501688131155\n",
      "Ended iteration 1800  Cost:  0.13731052263216562  Validation cost:  2.4169440807644063\n",
      "Ended iteration 1850  Cost:  0.033527222490344816  Validation cost:  2.3932693688737867\n",
      "Ended iteration 1900  Cost:  0.016459493379475623  Validation cost:  2.387039415925459\n",
      "Ended iteration 1950  Cost:  0.012164171686391377  Validation cost:  2.3909770872185807\n",
      "======================First model trained=====================\n",
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3057357940674583  Validation cost:  2.4215047786526807\n",
      "Ended iteration 50  Cost:  0.9061020472756373  Validation cost:  2.396682751991609\n",
      "Ended iteration 100  Cost:  0.6441210349710459  Validation cost:  2.5396769419366994\n",
      "Ended iteration 150  Cost:  0.5068640025655236  Validation cost:  2.6223200592298017\n",
      "Ended iteration 200  Cost:  0.4096068125411332  Validation cost:  2.704355889275428\n",
      "Ended iteration 250  Cost:  0.3518302423298683  Validation cost:  2.743064189051688\n",
      "Ended iteration 300  Cost:  0.3215474842070779  Validation cost:  2.7979144039191355\n",
      "Ended iteration 350  Cost:  0.488587141841578  Validation cost:  2.7809280830766983\n",
      "Ended iteration 400  Cost:  0.2745979310501551  Validation cost:  2.7845712700417917\n",
      "Ended iteration 450  Cost:  0.23567503943493198  Validation cost:  2.7693628495846774\n",
      "Ended iteration 500  Cost:  0.24141308508899986  Validation cost:  2.7909714325822423\n",
      "Ended iteration 550  Cost:  0.2413470977124345  Validation cost:  2.7890493965949905\n",
      "Ended iteration 600  Cost:  0.3499833852006174  Validation cost:  2.745167218055774\n",
      "Ended iteration 650  Cost:  0.18165088674955618  Validation cost:  2.83066763361621\n",
      "Ended iteration 700  Cost:  0.1133766995955115  Validation cost:  2.8154629883007316\n",
      "Ended iteration 750  Cost:  0.11554429676387933  Validation cost:  2.851530795334085\n",
      "Ended iteration 800  Cost:  0.06229420779822498  Validation cost:  2.830118405229521\n",
      "Ended iteration 850  Cost:  0.050985842540466224  Validation cost:  2.8479386465463126\n",
      "Ended iteration 900  Cost:  0.12990101500921583  Validation cost:  2.8106431987345117\n",
      "Ended iteration 950  Cost:  0.050277189354763566  Validation cost:  2.875680489024634\n",
      "Ended iteration 1000  Cost:  0.05761106235060998  Validation cost:  2.870267338522564\n",
      "Ended iteration 1050  Cost:  0.0639884272621437  Validation cost:  2.8528353268498017\n",
      "Ended iteration 1100  Cost:  0.06715938715324296  Validation cost:  2.8545951016438695\n",
      "Ended iteration 1150  Cost:  0.06884446341790977  Validation cost:  2.840176171190204\n",
      "Ended iteration 1200  Cost:  0.1745360702887087  Validation cost:  2.8559165466485927\n",
      "Ended iteration 1250  Cost:  0.055893147163984955  Validation cost:  2.850103881024222\n",
      "Ended iteration 1300  Cost:  0.03083099212622639  Validation cost:  2.873093026307094\n",
      "Ended iteration 1350  Cost:  0.02055624780041716  Validation cost:  2.8774468255273207\n",
      "Ended iteration 1400  Cost:  0.017529859341272217  Validation cost:  2.8888001319599703\n",
      "Ended iteration 1450  Cost:  0.01522227143852909  Validation cost:  2.8944394232010593\n",
      "Ended iteration 1500  Cost:  0.013803955816651033  Validation cost:  2.9079145990708337\n",
      "Ended iteration 1550  Cost:  0.015111136495300125  Validation cost:  2.9325507350408917\n",
      "Ended iteration 1600  Cost:  0.015942791166934416  Validation cost:  2.9353238537935624\n",
      "Ended iteration 1650  Cost:  0.016113263121604448  Validation cost:  2.944305557451633\n",
      "Ended iteration 1700  Cost:  0.019791875802264894  Validation cost:  2.96032239852871\n",
      "Ended iteration 1750  Cost:  0.10307360109658842  Validation cost:  2.7348225587110724\n",
      "Ended iteration 1800  Cost:  0.11719720242869752  Validation cost:  2.840627711559324\n",
      "Ended iteration 1850  Cost:  0.028158059044793227  Validation cost:  2.8548277042627377\n",
      "Ended iteration 1900  Cost:  0.017112204451298126  Validation cost:  2.877048949452949\n",
      "Ended iteration 1950  Cost:  0.011569987124680959  Validation cost:  2.8809107463183357\n",
      "======================Second model trained=====================\n",
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.321580214374032  Validation cost:  2.3720664303836254\n",
      "Ended iteration 50  Cost:  0.8281787515598474  Validation cost:  2.2303894826786848\n",
      "Ended iteration 100  Cost:  0.5740318621044193  Validation cost:  2.217803493105569\n",
      "Ended iteration 150  Cost:  0.42073444217734096  Validation cost:  2.1770364864587375\n",
      "Ended iteration 200  Cost:  0.32893359618597046  Validation cost:  2.1920906726306844\n",
      "Ended iteration 250  Cost:  0.31184344936962033  Validation cost:  2.182075501853157\n",
      "Ended iteration 300  Cost:  0.2735236456406978  Validation cost:  2.1808502455688994\n",
      "Ended iteration 350  Cost:  0.268462540846532  Validation cost:  2.2198380705183265\n",
      "Ended iteration 400  Cost:  0.3309733857415311  Validation cost:  2.2021447019920517\n",
      "Ended iteration 450  Cost:  0.1804686287367706  Validation cost:  2.230259262710964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 500  Cost:  0.18329599220754147  Validation cost:  2.23003480881589\n",
      "Ended iteration 550  Cost:  0.1758053454156528  Validation cost:  2.241828698690652\n",
      "Ended iteration 600  Cost:  0.2675383470684906  Validation cost:  2.2520411665317908\n",
      "Ended iteration 650  Cost:  0.13479015810833003  Validation cost:  2.2667202986006294\n",
      "Ended iteration 700  Cost:  0.07655198149775104  Validation cost:  2.277391799554831\n",
      "Ended iteration 750  Cost:  0.043980541823972236  Validation cost:  2.2620788406145698\n",
      "Ended iteration 800  Cost:  0.035259254690075965  Validation cost:  2.2617595498514227\n",
      "Ended iteration 850  Cost:  0.06389056070057937  Validation cost:  2.157462681375806\n",
      "Ended iteration 900  Cost:  0.03115277296736181  Validation cost:  2.240040697999623\n",
      "Ended iteration 950  Cost:  0.026071066612899537  Validation cost:  2.267897166191547\n",
      "Ended iteration 1000  Cost:  0.02210633327288129  Validation cost:  2.2693127576053214\n",
      "Ended iteration 1050  Cost:  0.0250451597809862  Validation cost:  2.2812197817648614\n",
      "Ended iteration 1100  Cost:  0.035435650263294975  Validation cost:  2.298485292584034\n",
      "Ended iteration 1150  Cost:  0.05128223160706558  Validation cost:  2.2331056081493226\n",
      "Ended iteration 1200  Cost:  0.17135333576641018  Validation cost:  2.2611100446695813\n",
      "Ended iteration 1250  Cost:  0.04730435134070995  Validation cost:  2.283118512514559\n",
      "Ended iteration 1300  Cost:  0.025242787660156453  Validation cost:  2.2935949377941403\n",
      "Ended iteration 1350  Cost:  0.013431355150678368  Validation cost:  2.2771655043973182\n",
      "Ended iteration 1400  Cost:  0.010518593002726916  Validation cost:  2.2730290393894834\n",
      "Ended iteration 1450  Cost:  0.011497166812691027  Validation cost:  2.2665403914431024\n",
      "Ended iteration 1500  Cost:  0.008785851588319496  Validation cost:  2.27875104599163\n",
      "Ended iteration 1550  Cost:  0.008158977220175492  Validation cost:  2.287622199672713\n",
      "Ended iteration 1600  Cost:  0.00765460251761047  Validation cost:  2.2869143674147687\n",
      "Ended iteration 1650  Cost:  0.009172785401763065  Validation cost:  2.2924898510018377\n",
      "Ended iteration 1700  Cost:  0.011896927989121193  Validation cost:  2.304296873452144\n",
      "Ended iteration 1750  Cost:  0.016663026789227955  Validation cost:  2.2999460627111974\n",
      "Ended iteration 1800  Cost:  0.12032488395977561  Validation cost:  2.301238516141045\n",
      "Ended iteration 1850  Cost:  0.033787852129875895  Validation cost:  2.273980253265269\n",
      "Ended iteration 1900  Cost:  0.016535661554822247  Validation cost:  2.2960040765136407\n",
      "Ended iteration 1950  Cost:  0.008751387024194264  Validation cost:  2.28109088541232\n",
      "======================Third model trained=====================\n",
      "First model  relu validation cost:  2.393826815847741  acc_train: 0.1260   acc_validation: 0.1288 \n",
      "Second model   relu validation cost:  2.8876717218414267  acc_train:0.1873   acc_validation: 0.1846 \n",
      "Third model  relu validation cost:  2.279828695533638  acc_train:0.3223   acc_validation: 0.3199 \n",
      "Average validation loss:  2.5204424110742685  Average validation accuracy:  0.2111111111111111\n"
     ]
    }
   ],
   "source": [
    "activation = \"relu\"\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Relu.300.100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.2728287369647764  Validation cost:  2.34349077765117\n",
      "Ended iteration 50  Cost:  0.8168484532593815  Validation cost:  2.2000867617752964\n",
      "Ended iteration 100  Cost:  0.6336933044223657  Validation cost:  2.1865180006550538\n",
      "Ended iteration 150  Cost:  0.510937307822785  Validation cost:  2.206836798233028\n",
      "Ended iteration 200  Cost:  0.40786948245382104  Validation cost:  2.197083473700934\n",
      "Ended iteration 250  Cost:  0.4245267299813025  Validation cost:  2.2325149668506583\n",
      "Ended iteration 300  Cost:  0.33001564147193874  Validation cost:  2.202452973329842\n",
      "Ended iteration 350  Cost:  0.2841736892173489  Validation cost:  2.2211851789716324\n",
      "Ended iteration 400  Cost:  0.26415530212795746  Validation cost:  2.2307895209673423\n",
      "Ended iteration 450  Cost:  0.31127951163536677  Validation cost:  2.2135604793758743\n",
      "Ended iteration 500  Cost:  0.21962562629967206  Validation cost:  2.2594159160861738\n",
      "Ended iteration 550  Cost:  0.21010595489605402  Validation cost:  2.271520402149215\n",
      "Ended iteration 600  Cost:  0.42423448865310054  Validation cost:  2.288603455619522\n",
      "Ended iteration 650  Cost:  0.18959389067323418  Validation cost:  2.268092064091697\n",
      "Ended iteration 700  Cost:  0.11901192507520633  Validation cost:  2.237564377024657\n",
      "Ended iteration 750  Cost:  0.1724388491729017  Validation cost:  2.24942169627429\n",
      "Ended iteration 800  Cost:  0.08904005848318063  Validation cost:  2.2239839227198277\n",
      "Ended iteration 850  Cost:  0.06506568924924774  Validation cost:  2.215444190950481\n",
      "Ended iteration 900  Cost:  0.06342492393438323  Validation cost:  2.2250607040626647\n",
      "Ended iteration 950  Cost:  0.04979849480112791  Validation cost:  2.2327631709515297\n",
      "Ended iteration 1000  Cost:  0.05308899497954673  Validation cost:  2.2133804667283568\n",
      "Ended iteration 1050  Cost:  0.17719953847057274  Validation cost:  2.1986053678822377\n",
      "Ended iteration 1100  Cost:  0.046650612137201654  Validation cost:  2.221352225927552\n",
      "Ended iteration 1150  Cost:  0.05926903041004537  Validation cost:  2.231862779124695\n",
      "Ended iteration 1200  Cost:  0.2105965690365397  Validation cost:  2.2495299565065454\n",
      "Ended iteration 1250  Cost:  0.08351485475193803  Validation cost:  2.2040109895018687\n",
      "Ended iteration 1300  Cost:  0.034316113875961396  Validation cost:  2.2026055603021226\n",
      "Ended iteration 1350  Cost:  0.024508802341041816  Validation cost:  2.203194460187536\n",
      "Ended iteration 1400  Cost:  0.0199320793374466  Validation cost:  2.2121470965412056\n",
      "Ended iteration 1450  Cost:  0.01595738084328157  Validation cost:  2.226140144522005\n",
      "Ended iteration 1500  Cost:  0.019590202739206024  Validation cost:  2.2252456348218863\n",
      "Ended iteration 1550  Cost:  0.014184572234564067  Validation cost:  2.2374341825729704\n",
      "Ended iteration 1600  Cost:  0.014299187209918358  Validation cost:  2.235978193036106\n",
      "Ended iteration 1650  Cost:  0.01613579616457124  Validation cost:  2.2452086367613036\n",
      "Ended iteration 1700  Cost:  0.015303391700144603  Validation cost:  2.253950259725596\n",
      "Ended iteration 1750  Cost:  1.779092847050628  Validation cost:  2.136095772798833\n",
      "Ended iteration 1800  Cost:  0.7139696441710303  Validation cost:  2.1990354914247483\n",
      "Ended iteration 1850  Cost:  0.031177504777928522  Validation cost:  2.1691051916605906\n",
      "Ended iteration 1900  Cost:  0.017770217918447614  Validation cost:  2.173293880454655\n",
      "Ended iteration 1950  Cost:  0.013084532059867053  Validation cost:  2.171963706802153\n",
      "======================First model trained=====================\n",
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.2977870494659025  Validation cost:  2.3599412693969564\n",
      "Ended iteration 50  Cost:  0.7397643620672414  Validation cost:  2.268938951572672\n",
      "Ended iteration 100  Cost:  0.5714267576821158  Validation cost:  2.2873008417242144\n",
      "Ended iteration 150  Cost:  0.526723837962424  Validation cost:  2.330831580048507\n",
      "Ended iteration 200  Cost:  0.393267383564246  Validation cost:  2.3620523762827856\n",
      "Ended iteration 250  Cost:  0.40832662192086644  Validation cost:  2.3179013307373078\n",
      "Ended iteration 300  Cost:  0.2758236978723714  Validation cost:  2.371113440736193\n",
      "Ended iteration 350  Cost:  0.2646435368390636  Validation cost:  2.3709864637984\n",
      "Ended iteration 400  Cost:  0.23752311245826946  Validation cost:  2.292479476940055\n",
      "Ended iteration 450  Cost:  0.2979150803547456  Validation cost:  2.2930078258961775\n",
      "Ended iteration 500  Cost:  0.20158935217886736  Validation cost:  2.2883787266844817\n",
      "Ended iteration 550  Cost:  0.18101417966467456  Validation cost:  2.3288296487455513\n",
      "Ended iteration 600  Cost:  0.31946495848973494  Validation cost:  2.2782851814275795\n",
      "Ended iteration 650  Cost:  0.14727849668734455  Validation cost:  2.339646771120159\n",
      "Ended iteration 700  Cost:  0.10070011103447059  Validation cost:  2.3375909958363184\n",
      "Ended iteration 750  Cost:  0.07828720942967891  Validation cost:  2.3745950723576486\n",
      "Ended iteration 800  Cost:  0.052610716769168835  Validation cost:  2.376123268420868\n",
      "Ended iteration 850  Cost:  0.491587834346829  Validation cost:  2.2460565091489935\n",
      "Ended iteration 900  Cost:  0.038305274365161256  Validation cost:  2.4010583257954\n",
      "Ended iteration 950  Cost:  0.031312234515391626  Validation cost:  2.3929992663159325\n",
      "Ended iteration 1000  Cost:  0.04076593095430537  Validation cost:  2.4031330313309773\n",
      "Ended iteration 1050  Cost:  0.06278493526259969  Validation cost:  2.305963298847062\n",
      "Ended iteration 1100  Cost:  0.12949493040683882  Validation cost:  2.358858616682244\n",
      "Ended iteration 1150  Cost:  0.1887764474370485  Validation cost:  2.3235985840631734\n",
      "Ended iteration 1200  Cost:  0.3596137305549851  Validation cost:  2.3281807313919045\n",
      "Ended iteration 1250  Cost:  0.05902245292956415  Validation cost:  2.336479831131758\n",
      "Ended iteration 1300  Cost:  0.02882291667692855  Validation cost:  2.3287300249153136\n",
      "Ended iteration 1350  Cost:  0.021750849162735602  Validation cost:  2.33462336367771\n",
      "Ended iteration 1400  Cost:  0.014372175304631245  Validation cost:  2.3499831283904\n",
      "Ended iteration 1450  Cost:  0.013527581603109731  Validation cost:  2.364830676210399\n",
      "Ended iteration 1500  Cost:  0.011125966393652454  Validation cost:  2.3785933115519855\n",
      "Ended iteration 1550  Cost:  0.009785036950277725  Validation cost:  2.381360641732139\n",
      "Ended iteration 1600  Cost:  0.013921085522886836  Validation cost:  2.3967760548955668\n",
      "Ended iteration 1650  Cost:  0.018016355086813256  Validation cost:  2.3633674721475697\n",
      "Ended iteration 1700  Cost:  0.01995380344563872  Validation cost:  2.3456321834102742\n",
      "Ended iteration 1750  Cost:  0.05186802653181132  Validation cost:  2.1900857441115837\n",
      "Ended iteration 1800  Cost:  0.13093918252194514  Validation cost:  2.2715049674450043\n",
      "Ended iteration 1850  Cost:  0.03280615009003971  Validation cost:  2.2976708405397632\n",
      "Ended iteration 1900  Cost:  0.014173153795143648  Validation cost:  2.299517865399971\n",
      "Ended iteration 1950  Cost:  0.011043722382913845  Validation cost:  2.3033273954288487\n",
      "======================Second model trained=====================\n",
      "Beginning training with 2000 epochs, 300 neurons (1st layer) 100 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.319070184072773  Validation cost:  2.4073588306750873\n",
      "Ended iteration 50  Cost:  0.7736235864107321  Validation cost:  2.2515933549191676\n",
      "Ended iteration 100  Cost:  0.571713306468148  Validation cost:  2.251077564419023\n",
      "Ended iteration 150  Cost:  0.47363870645187606  Validation cost:  2.2713416610579427\n",
      "Ended iteration 200  Cost:  0.36376821722574587  Validation cost:  2.2735449500606686\n",
      "Ended iteration 250  Cost:  0.3281807663305824  Validation cost:  2.267836530828144\n",
      "Ended iteration 300  Cost:  0.3231264039447714  Validation cost:  2.256894263483599\n",
      "Ended iteration 350  Cost:  0.29269036785259095  Validation cost:  2.2986575134133798\n",
      "Ended iteration 400  Cost:  0.25489580411240575  Validation cost:  2.360947858885371\n",
      "Ended iteration 450  Cost:  0.2559457926483908  Validation cost:  2.3281998187339052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended iteration 500  Cost:  0.22257366563136982  Validation cost:  2.3905564670011774\n",
      "Ended iteration 550  Cost:  0.20350169377359137  Validation cost:  2.446320315998636\n",
      "Ended iteration 600  Cost:  0.3554630949016934  Validation cost:  2.4606086464837325\n",
      "Ended iteration 650  Cost:  0.1720656580565312  Validation cost:  2.406999815100992\n",
      "Ended iteration 700  Cost:  0.14152923268060286  Validation cost:  2.400849142284032\n",
      "Ended iteration 750  Cost:  0.09269155431387496  Validation cost:  2.3992248458081313\n",
      "Ended iteration 800  Cost:  0.06338547203727461  Validation cost:  2.406325265142734\n",
      "Ended iteration 850  Cost:  0.049052589532699274  Validation cost:  2.39456897924934\n",
      "Ended iteration 900  Cost:  0.05539426692419303  Validation cost:  2.369177257120201\n",
      "Ended iteration 950  Cost:  0.05329379454302604  Validation cost:  2.3748266861858265\n",
      "Ended iteration 1000  Cost:  0.20726723643113626  Validation cost:  2.2171844215674543\n",
      "Ended iteration 1050  Cost:  0.07251831459953584  Validation cost:  2.3223630996397677\n",
      "Ended iteration 1100  Cost:  0.06237629485050325  Validation cost:  2.3556545288114266\n",
      "Ended iteration 1150  Cost:  0.07573955638054931  Validation cost:  2.3510841560228304\n",
      "Ended iteration 1200  Cost:  0.180771805437606  Validation cost:  2.3445704035306796\n",
      "Ended iteration 1250  Cost:  0.056226003014929304  Validation cost:  2.3292309868416488\n",
      "Ended iteration 1300  Cost:  0.03575475447100303  Validation cost:  2.3430482555317225\n",
      "Ended iteration 1350  Cost:  0.02408762553734019  Validation cost:  2.3460771989939335\n",
      "Ended iteration 1400  Cost:  0.01720367580042518  Validation cost:  2.35420436042386\n",
      "Ended iteration 1450  Cost:  0.013917655849157828  Validation cost:  2.348013031270656\n",
      "Ended iteration 1500  Cost:  0.014782491091136801  Validation cost:  2.3444315919081395\n",
      "Ended iteration 1550  Cost:  0.01263947317224771  Validation cost:  2.350001643591664\n",
      "Ended iteration 1600  Cost:  0.013634836864746678  Validation cost:  2.3502090722835565\n",
      "Ended iteration 1650  Cost:  0.013842649448217675  Validation cost:  2.373855535769516\n",
      "Ended iteration 1700  Cost:  0.04349296086904922  Validation cost:  2.299231154404593\n",
      "Ended iteration 1750  Cost:  0.03554541021700065  Validation cost:  2.3376947885742667\n",
      "Ended iteration 1800  Cost:  0.11926047465323798  Validation cost:  2.339523156348616\n",
      "Ended iteration 1850  Cost:  0.02471655991461769  Validation cost:  2.3306911558131436\n",
      "Ended iteration 1900  Cost:  0.01619425397886614  Validation cost:  2.349073464534687\n",
      "Ended iteration 1950  Cost:  0.01116223975181834  Validation cost:  2.3573475578444922\n",
      "======================Third model trained=====================\n",
      "First model  leaky_relu validation cost:  2.1804415547212463  acc_train: 0.2520   acc_validation: 0.2462 \n",
      "Second model   leaky_relu validation cost:  2.312061568875175  acc_train:0.2055   acc_validation: 0.2025 \n",
      "Third model  leaky_relu validation cost:  2.3674862331524102  acc_train:0.1633   acc_validation: 0.1655 \n",
      "Average validation loss:  2.286663118916277  Average validation accuracy:  0.20475\n"
     ]
    }
   ],
   "source": [
    "activation = \"leaky_relu\"\n",
    "learning_rate=0.1\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1_neurons = 500\n",
    "hidden_layer_2_neurons = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid.500.250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with 2000 epochs, 500 neurons (1st layer) 250 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.5060392174924924  Validation cost:  2.3222700203825317\n",
      "Ended iteration 50  Cost:  2.1963213023855643  Validation cost:  2.213606606489974\n",
      "Ended iteration 100  Cost:  2.0259479022905458  Validation cost:  2.0513768422547844\n",
      "Ended iteration 150  Cost:  1.7469371714794049  Validation cost:  1.779189637344452\n",
      "Ended iteration 200  Cost:  1.4862820216339523  Validation cost:  1.5255935615004819\n",
      "Ended iteration 250  Cost:  1.3109347358780963  Validation cost:  1.3475511767620574\n",
      "Ended iteration 300  Cost:  1.2044598588133828  Validation cost:  1.2174683095542582\n",
      "Ended iteration 350  Cost:  1.1170981800022852  Validation cost:  1.126886847757941\n",
      "Ended iteration 400  Cost:  1.0527373272121416  Validation cost:  1.054226767146927\n",
      "Ended iteration 450  Cost:  1.010226265458643  Validation cost:  0.9941326998038151\n",
      "Ended iteration 500  Cost:  0.9576333288568046  Validation cost:  0.9444041113352717\n",
      "Ended iteration 550  Cost:  0.9090941544037544  Validation cost:  0.9015055298838276\n",
      "Ended iteration 600  Cost:  0.8152355825301236  Validation cost:  0.8609180007581008\n",
      "Ended iteration 650  Cost:  0.7709499010697684  Validation cost:  0.8335454224117769\n",
      "Ended iteration 700  Cost:  0.7408247913449867  Validation cost:  0.8095236706404392\n",
      "Ended iteration 750  Cost:  0.7191026972605572  Validation cost:  0.790537436484626\n",
      "Ended iteration 800  Cost:  0.691097286918861  Validation cost:  0.7715173785006721\n",
      "Ended iteration 850  Cost:  0.673656932582355  Validation cost:  0.7563271085358103\n",
      "Ended iteration 900  Cost:  0.6576884337310547  Validation cost:  0.735778448714113\n",
      "Ended iteration 950  Cost:  0.6505930656532402  Validation cost:  0.7220977636355495\n",
      "Ended iteration 1000  Cost:  0.6437571236450422  Validation cost:  0.7094290084530368\n",
      "Ended iteration 1050  Cost:  0.6572618415871623  Validation cost:  0.6996691734105868\n",
      "Ended iteration 1100  Cost:  0.6590027686724771  Validation cost:  0.6899378747509478\n",
      "Ended iteration 1150  Cost:  0.6486723675284424  Validation cost:  0.6826752702401088\n",
      "Ended iteration 1200  Cost:  0.6067110811460832  Validation cost:  0.6714462444287432\n",
      "Ended iteration 1250  Cost:  0.5866768125017378  Validation cost:  0.6704483290159969\n",
      "Ended iteration 1300  Cost:  0.5732303974555731  Validation cost:  0.6683030932804809\n",
      "Ended iteration 1350  Cost:  0.5658602531534771  Validation cost:  0.6683966619536735\n",
      "Ended iteration 1400  Cost:  0.5438161018847425  Validation cost:  0.6642605887483061\n",
      "Ended iteration 1450  Cost:  0.5297598815025987  Validation cost:  0.6624905463184936\n",
      "Ended iteration 1500  Cost:  0.5243106941751027  Validation cost:  0.6533953562676411\n",
      "Ended iteration 1550  Cost:  0.5194971678066987  Validation cost:  0.6491103921386168\n",
      "Ended iteration 1600  Cost:  0.5218853284212611  Validation cost:  0.64514546226396\n",
      "Ended iteration 1650  Cost:  0.545559239424245  Validation cost:  0.6419730278259318\n",
      "Ended iteration 1700  Cost:  0.5554995296382632  Validation cost:  0.6365771312899545\n",
      "Ended iteration 1750  Cost:  0.5496047638084615  Validation cost:  0.6332876724979697\n",
      "Ended iteration 1800  Cost:  0.5358725783237107  Validation cost:  0.623483379450318\n",
      "Ended iteration 1850  Cost:  0.5074611296271829  Validation cost:  0.6241721715309871\n",
      "Ended iteration 1900  Cost:  0.48716828495341685  Validation cost:  0.6240608881648304\n",
      "Ended iteration 1950  Cost:  0.4776251483891236  Validation cost:  0.6258144068533011\n",
      "======================First model trained=====================\n",
      "Beginning training with 2000 epochs, 500 neurons (1st layer) 250 neurons (2nd layer)\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.35638827137814  Validation cost:  2.3192388620593265\n",
      "Ended iteration 50  Cost:  2.192057260337666  Validation cost:  2.2089781184170265\n",
      "Ended iteration 100  Cost:  2.025359063495335  Validation cost:  2.040775278723158\n",
      "Ended iteration 150  Cost:  1.7504352346660066  Validation cost:  1.7647541622851686\n",
      "Ended iteration 200  Cost:  1.5070628986514107  Validation cost:  1.5155288326986005\n",
      "Ended iteration 250  Cost:  1.3323680306233285  Validation cost:  1.3394744538073429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-328-610bd0c6cb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-278-ac2b7fd59425>\u001b[0m in \u001b[0;36mevaluate_neural_network_2hl\u001b[0;34m(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel_2hl_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"======================First model trained=====================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmodel_2hl_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"======================Second model trained=====================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmodel_2hl_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_1_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_2_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashionTrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-319-4c2c93a27352>\u001b[0m in \u001b[0;36mtrain_neural_network_2hl\u001b[0;34m(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, trainParams, trainTarget, learning_rate, regularization_rate, activation)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mminiBatchTarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         Performs Forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_prop_2hl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneural_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         Performs Backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36mforward_prop_2hl\u001b[0;34m(x, neural_data, activation)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-853d4cf3f55e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-241-315a7734311b>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mderivative_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activation = \"sigmoid\"\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu.500.250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"relu\"\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky Relu.500.250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"leaky_relu\"\n",
    "evaluate_neural_network_2hl(hidden_layer_1_neurons, hidden_layer_2_neurons, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using test data\n",
    "Right now we'll see how our model handles the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training with  2000  epochs and  500  hidden neurons.\n",
      "Initialized weights\n",
      "Prepared for mini-batch.\n",
      "Ended iteration 0  Cost:  2.3991860136685728  Validation cost:  2.3316026716316345\n",
      "Ended iteration 50  Cost:  1.5644331754905838  Validation cost:  1.571128223576728\n",
      "Ended iteration 100  Cost:  1.1539204601947681  Validation cost:  1.172093827959\n",
      "Ended iteration 150  Cost:  0.9568701770049237  Validation cost:  0.9876451768169804\n",
      "Ended iteration 200  Cost:  0.8411868709500163  Validation cost:  0.8845913860204307\n",
      "Ended iteration 250  Cost:  0.7637288277711356  Validation cost:  0.8196016581084586\n",
      "Ended iteration 300  Cost:  0.7070624230514607  Validation cost:  0.7752689352649349\n",
      "Ended iteration 350  Cost:  0.6627047565406443  Validation cost:  0.7431396357072231\n",
      "Ended iteration 400  Cost:  0.626085104168689  Validation cost:  0.7186531053100139\n",
      "Ended iteration 450  Cost:  0.5946070622057511  Validation cost:  0.6992136889175222\n",
      "Ended iteration 500  Cost:  0.5667522917347436  Validation cost:  0.6832956616649746\n",
      "Ended iteration 550  Cost:  0.5416116532960538  Validation cost:  0.6699747863697929\n",
      "Ended iteration 600  Cost:  0.5186232269708798  Validation cost:  0.6586694542274689\n",
      "Ended iteration 650  Cost:  0.4974223493872262  Validation cost:  0.6489949539748009\n",
      "Ended iteration 700  Cost:  0.47775604073876005  Validation cost:  0.6406813550099759\n",
      "Ended iteration 750  Cost:  0.4594351471542462  Validation cost:  0.6335275525857503\n",
      "Ended iteration 800  Cost:  0.4423083442346721  Validation cost:  0.6273757252311005\n",
      "Ended iteration 850  Cost:  0.4262484619475239  Validation cost:  0.6220971357161093\n",
      "Ended iteration 900  Cost:  0.41114549145269874  Validation cost:  0.6175841223784\n",
      "Ended iteration 950  Cost:  0.3969030363091811  Validation cost:  0.6137454015478644\n",
      "Ended iteration 1000  Cost:  0.3834364123910789  Validation cost:  0.610503098990903\n",
      "Ended iteration 1050  Cost:  0.3706714478099702  Validation cost:  0.6077906605988513\n",
      "Ended iteration 1100  Cost:  0.3585435223004611  Validation cost:  0.6055512041994034\n",
      "Ended iteration 1150  Cost:  0.3469966562413453  Validation cost:  0.6037361032111948\n",
      "Ended iteration 1200  Cost:  0.33598259694021093  Validation cost:  0.60230371548969\n",
      "Ended iteration 1250  Cost:  0.3254599078289541  Validation cost:  0.6012182310899497\n",
      "Ended iteration 1300  Cost:  0.3153930812008653  Validation cost:  0.6004486377179772\n",
      "Ended iteration 1350  Cost:  0.30575169111126965  Validation cost:  0.5999678095334505\n",
      "Ended iteration 1400  Cost:  0.2965095946113238  Validation cost:  0.5997517242606447\n",
      "Ended iteration 1450  Cost:  0.28764418421765914  Validation cost:  0.5997788108349068\n",
      "Ended iteration 1500  Cost:  0.2791356951856802  Validation cost:  0.6000294269928684\n",
      "Ended iteration 1550  Cost:  0.27096657677310815  Validation cost:  0.6004854629946705\n",
      "Ended iteration 1600  Cost:  0.2631209433692209  Validation cost:  0.60113006299732\n",
      "Ended iteration 1650  Cost:  0.2555841239437338  Validation cost:  0.6019474491672928\n",
      "Ended iteration 1700  Cost:  0.248342323086052  Validation cost:  0.6029228267592177\n",
      "Ended iteration 1750  Cost:  0.24138239449886878  Validation cost:  0.6040423437328274\n",
      "Ended iteration 1800  Cost:  0.2346917130524209  Validation cost:  0.6052930783878377\n",
      "Ended iteration 1850  Cost:  0.22825812058597483  Validation cost:  0.6066630333630137\n",
      "Ended iteration 1900  Cost:  0.22206991722223154  Validation cost:  0.6081411222806189\n",
      "Ended iteration 1950  Cost:  0.2161158735789017  Validation cost:  0.6097171434007779\n"
     ]
    }
   ],
   "source": [
    "fashionTestParams, fashionTestTarget = formatArray(fashionTestDataset, 0)\n",
    "fashionTestTarget = createTarget(fashionTestTarget)\n",
    "fashionTestParams = fashionTestParams/255\n",
    "\n",
    "model_1hl_1 = train_neural_network_1hl(500, epochs, fashionTrainParams, fashionTrainTarget, learning_rate, regularization_rate, activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_sigmoid1 = forward_prop_1hl(fashionTestParams, model_1hl_1)\n",
    "cost1 = neuralNetworkCostFunction(probs_sigmoid1, fashionTestTarget)\n",
    "acc1_test = accuracy(fashionTestTarget, fashionTestParams, model_1hl_1)\n",
    "print(\"Model:\", activation, \"Test cost:\", cost1, \"Test Accuracy: {0:.4f} \".format(acc1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = construct_confusion_matrix(fashionTestTarget, model_1hl_1, fashionTestParams)\n",
    "p_print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
